{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS4242 Group Assignment Part 1\n",
    "**November 11, 2020**\n",
    "\n",
    "## Instructions\n",
    "\n",
    "+ 2 Parts: Predictive Analytics (30 marks) & Prescriptive Analytics (10 marks)\n",
    "+ Do all required data exploration - preprocessing - feature engineering - model building and evaluation steps\n",
    "+ Submit first entry - predict on the given test data - see leaderboard position, then improve upon previous entry to improve test accuracy. Each team must have at least 2 submissions\n",
    "\n",
    "+ At least one of the submitted models:\n",
    "  + Must be a neural network implemented using PyTorch\n",
    "  + Must use automated hyperparameter tuning\n",
    "+ It is important to __explain each step__ you perform in preprocessing, feature engineering, model training. Ask yourself why you are performing the step and write the reason. While you may use any online resource, you have to cite them AND explanation should be in our own words.\n",
    "+ __50% marks - explanation, 50% marks - code__\n",
    "+ __Bonus points if your team has rank < 500__\n",
    "+ **Submission deadline: November 11, 2020; 11:59 am**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name: LECK WEI SHENG IAN\n",
    "#### NUS ID: A0168177R\n",
    "#### Name: WOO KENG THONG\n",
    "#### NUS ID: A0167991L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal is to predict the operating condition of a waterpoint for each record in the dataset. You are provided information about the waterpoints in order label them.\n",
    "\n",
    "The labels in this dataset are simple. There are three possible values:\n",
    "1. functional - the waterpoint is operational and there are no repairs needed\n",
    "2. functional needs repair - the waterpoint is operational, but needs repairs\n",
    "3. non functional - the waterpoint is not operational\n",
    "\n",
    "The format for the submission file is simply the row id and the predicted label. \n",
    "- id\tstatus_group\n",
    "- 50785\tfunctional\n",
    "- 51630\tfunctional\n",
    "\n",
    "CSV would thus look like\n",
    "- id,status_group\n",
    "- 50785,functional\n",
    "- 51630,functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing & Feature Engineering - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data, and merge data and labels together into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('training-set-labels.csv')\n",
    "df = pd.read_csv('training-set-values.csv')\n",
    "test_df = pd.read_csv('test-set-values.csv')\n",
    "\n",
    "df = pd.merge(df, labels, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59400 entries, 0 to 59399\n",
      "Data columns (total 41 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     59400 non-null  int64  \n",
      " 1   amount_tsh             59400 non-null  float64\n",
      " 2   date_recorded          59400 non-null  object \n",
      " 3   funder                 55765 non-null  object \n",
      " 4   gps_height             59400 non-null  int64  \n",
      " 5   installer              55745 non-null  object \n",
      " 6   longitude              59400 non-null  float64\n",
      " 7   latitude               59400 non-null  float64\n",
      " 8   wpt_name               59400 non-null  object \n",
      " 9   num_private            59400 non-null  int64  \n",
      " 10  basin                  59400 non-null  object \n",
      " 11  subvillage             59029 non-null  object \n",
      " 12  region                 59400 non-null  object \n",
      " 13  region_code            59400 non-null  int64  \n",
      " 14  district_code          59400 non-null  int64  \n",
      " 15  lga                    59400 non-null  object \n",
      " 16  ward                   59400 non-null  object \n",
      " 17  population             59400 non-null  int64  \n",
      " 18  public_meeting         56066 non-null  object \n",
      " 19  recorded_by            59400 non-null  object \n",
      " 20  scheme_management      55523 non-null  object \n",
      " 21  scheme_name            31234 non-null  object \n",
      " 22  permit                 56344 non-null  object \n",
      " 23  construction_year      59400 non-null  int64  \n",
      " 24  extraction_type        59400 non-null  object \n",
      " 25  extraction_type_group  59400 non-null  object \n",
      " 26  extraction_type_class  59400 non-null  object \n",
      " 27  management             59400 non-null  object \n",
      " 28  management_group       59400 non-null  object \n",
      " 29  payment                59400 non-null  object \n",
      " 30  payment_type           59400 non-null  object \n",
      " 31  water_quality          59400 non-null  object \n",
      " 32  quality_group          59400 non-null  object \n",
      " 33  quantity               59400 non-null  object \n",
      " 34  quantity_group         59400 non-null  object \n",
      " 35  source                 59400 non-null  object \n",
      " 36  source_type            59400 non-null  object \n",
      " 37  source_class           59400 non-null  object \n",
      " 38  waterpoint_type        59400 non-null  object \n",
      " 39  waterpoint_type_group  59400 non-null  object \n",
      " 40  status_group           59400 non-null  object \n",
      "dtypes: float64(3), int64(7), object(31)\n",
      "memory usage: 19.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check similar predictors and eliminate highly correlated predictors to reduce redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region         region_code\n",
       "Arusha         2              3024\n",
       "               24              326\n",
       "Dar es Salaam  7               805\n",
       "Dodoma         1              2201\n",
       "Iringa         11             5294\n",
       "Kagera         18             3316\n",
       "Kigoma         16             2816\n",
       "Kilimanjaro    3              4379\n",
       "Lindi          8               300\n",
       "               18                8\n",
       "               80             1238\n",
       "Manyara        21             1583\n",
       "Mara           20             1969\n",
       "Mbeya          12             4639\n",
       "Morogoro       5              4006\n",
       "Mtwara         9               390\n",
       "               90              917\n",
       "               99              423\n",
       "Mwanza         17               55\n",
       "               19             3047\n",
       "Pwani          6              1609\n",
       "               40                1\n",
       "               60             1025\n",
       "Rukwa          15             1808\n",
       "Ruvuma         10             2640\n",
       "Shinyanga      11                6\n",
       "               14               20\n",
       "               17             4956\n",
       "Singida        13             2093\n",
       "Tabora         14             1959\n",
       "Tanga          4              2513\n",
       "               5                34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['region','region_code']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop `region_code` as it seems to be identify regions, yet is not able to stand on its own as there are identical region codes in different regions. `drop` list is compiled for each column dropped for subsequent use with test values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop = []\n",
    "drop.append('region_code')\n",
    "\n",
    "df.drop('region_code',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extraction_type            extraction_type_group  extraction_type_class\n",
       "afridev                    afridev                handpump                  1770\n",
       "cemo                       other motorpump        motorpump                   90\n",
       "climax                     other motorpump        motorpump                   32\n",
       "gravity                    gravity                gravity                  26780\n",
       "india mark ii              india mark ii          handpump                  2400\n",
       "india mark iii             india mark iii         handpump                    98\n",
       "ksb                        submersible            submersible               1415\n",
       "mono                       mono                   motorpump                 2865\n",
       "nira/tanira                nira/tanira            handpump                  8154\n",
       "other                      other                  other                     6430\n",
       "other - mkulima/shinyanga  other handpump         handpump                     2\n",
       "other - play pump          other handpump         handpump                    85\n",
       "other - rope pump          rope pump              rope pump                  451\n",
       "other - swn 81             other handpump         handpump                   229\n",
       "submersible                submersible            submersible               4764\n",
       "swn 80                     swn 80                 handpump                  3670\n",
       "walimi                     other handpump         handpump                    48\n",
       "windmill                   wind-powered           wind-powered               117\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['extraction_type','extraction_type_group','extraction_type_class']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "management        management_group\n",
       "company           commercial            685\n",
       "other             other                 844\n",
       "other - school    other                  99\n",
       "parastatal        parastatal           1768\n",
       "private operator  commercial           1971\n",
       "trust             commercial             78\n",
       "unknown           unknown               561\n",
       "vwc               user-group          40507\n",
       "water authority   commercial            904\n",
       "water board       user-group           2933\n",
       "wua               user-group           2535\n",
       "wug               user-group           6515\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['management','management_group']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "payment                payment_type\n",
       "never pay              never pay       25348\n",
       "other                  other            1054\n",
       "pay annually           annually         3642\n",
       "pay monthly            monthly          8300\n",
       "pay per bucket         per bucket       8985\n",
       "pay when scheme fails  on failure       3914\n",
       "unknown                unknown          8157\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['payment','payment_type']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quantity      quantity_group\n",
       "dry           dry                6246\n",
       "enough        enough            33186\n",
       "insufficient  insufficient      15129\n",
       "seasonal      seasonal           4050\n",
       "unknown       unknown             789\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['quantity','quantity_group']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source                source_type           source_class\n",
       "dam                   dam                   surface           656\n",
       "hand dtw              borehole              groundwater       874\n",
       "lake                  river/lake            surface           765\n",
       "machine dbh           borehole              groundwater     11075\n",
       "other                 other                 unknown           212\n",
       "rainwater harvesting  rainwater harvesting  surface          2295\n",
       "river                 river/lake            surface          9612\n",
       "shallow well          shallow well          groundwater     16824\n",
       "spring                spring                groundwater     17021\n",
       "unknown               other                 unknown            66\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['source','source_type','source_class']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "waterpoint_type              waterpoint_type_group\n",
       "cattle trough                cattle trough              116\n",
       "communal standpipe           communal standpipe       28522\n",
       "communal standpipe multiple  communal standpipe        6103\n",
       "dam                          dam                          7\n",
       "hand pump                    hand pump                17488\n",
       "improved spring              improved spring            784\n",
       "other                        other                     6380\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['waterpoint_type','waterpoint_type_group']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above this can drop more but I didn't because I thought can use this to improve second submission besides using a different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>num_private</th>\n",
       "      <th>district_code</th>\n",
       "      <th>population</th>\n",
       "      <th>construction_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>5.940000e+04</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37115.131768</td>\n",
       "      <td>317.650385</td>\n",
       "      <td>668.297239</td>\n",
       "      <td>34.077427</td>\n",
       "      <td>-5.706033e+00</td>\n",
       "      <td>0.474141</td>\n",
       "      <td>5.629747</td>\n",
       "      <td>179.909983</td>\n",
       "      <td>1300.652475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21453.128371</td>\n",
       "      <td>2997.574558</td>\n",
       "      <td>693.116350</td>\n",
       "      <td>6.567432</td>\n",
       "      <td>2.946019e+00</td>\n",
       "      <td>12.236230</td>\n",
       "      <td>9.633649</td>\n",
       "      <td>471.482176</td>\n",
       "      <td>951.620547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.164944e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18519.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.090347</td>\n",
       "      <td>-8.540621e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37061.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>34.908743</td>\n",
       "      <td>-5.021597e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1986.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55656.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1319.250000</td>\n",
       "      <td>37.178387</td>\n",
       "      <td>-3.326156e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74247.000000</td>\n",
       "      <td>350000.000000</td>\n",
       "      <td>2770.000000</td>\n",
       "      <td>40.345193</td>\n",
       "      <td>-2.000000e-08</td>\n",
       "      <td>1776.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     amount_tsh    gps_height     longitude      latitude  \\\n",
       "count  59400.000000   59400.000000  59400.000000  59400.000000  5.940000e+04   \n",
       "mean   37115.131768     317.650385    668.297239     34.077427 -5.706033e+00   \n",
       "std    21453.128371    2997.574558    693.116350      6.567432  2.946019e+00   \n",
       "min        0.000000       0.000000    -90.000000      0.000000 -1.164944e+01   \n",
       "25%    18519.750000       0.000000      0.000000     33.090347 -8.540621e+00   \n",
       "50%    37061.500000       0.000000    369.000000     34.908743 -5.021597e+00   \n",
       "75%    55656.500000      20.000000   1319.250000     37.178387 -3.326156e+00   \n",
       "max    74247.000000  350000.000000   2770.000000     40.345193 -2.000000e-08   \n",
       "\n",
       "        num_private  district_code    population  construction_year  \n",
       "count  59400.000000   59400.000000  59400.000000       59400.000000  \n",
       "mean       0.474141       5.629747    179.909983        1300.652475  \n",
       "std       12.236230       9.633649    471.482176         951.620547  \n",
       "min        0.000000       0.000000      0.000000           0.000000  \n",
       "25%        0.000000       2.000000      0.000000           0.000000  \n",
       "50%        0.000000       3.000000     25.000000        1986.000000  \n",
       "75%        0.000000       5.000000    215.000000        2004.000000  \n",
       "max     1776.000000      80.000000  30500.000000        2013.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `num_private` as it does not seem to be meaningful - mostly zeros at 25%, 50% and 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code', 'num_private']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('num_private')\n",
    "\n",
    "df.drop('num_private',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null values in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh                   0\n",
       "date_recorded                0\n",
       "funder                    3635\n",
       "gps_height                   0\n",
       "installer                 3655\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "basin                        0\n",
       "subvillage                 371\n",
       "region                       0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population                   0\n",
       "public_meeting            3334\n",
       "recorded_by                  0\n",
       "scheme_management         3877\n",
       "scheme_name              28166\n",
       "permit                    3056\n",
       "construction_year            0\n",
       "extraction_type              0\n",
       "extraction_type_group        0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "management_group             0\n",
       "payment                      0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quality_group                0\n",
       "quantity                     0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "source_type                  0\n",
       "source_class                 0\n",
       "waterpoint_type              0\n",
       "waterpoint_type_group        0\n",
       "status_group                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### funder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Government Of Tanzania    9084\n",
       "Danida                    3114\n",
       "Hesawa                    2202\n",
       "Rwssp                     1374\n",
       "World Bank                1349\n",
       "                          ... \n",
       "John Skwese                  1\n",
       "Municipal Council            1\n",
       "Prince Medium School         1\n",
       "Wsdo                         1\n",
       "Kegocha                      1\n",
       "Name: funder, Length: 1897, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.funder.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep top 5 funders and set the rest to other, including missing values. Then, check the difference between the funders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "funder  status_group           \n",
       "bank    functional                   545\n",
       "        functional needs repair       97\n",
       "        non functional               707\n",
       "danida  functional                  1713\n",
       "        functional needs repair      159\n",
       "        non functional              1242\n",
       "gov     functional                  3720\n",
       "        functional needs repair      701\n",
       "        non functional              4663\n",
       "hesawa  functional                   936\n",
       "        functional needs repair      232\n",
       "        non functional              1034\n",
       "other   functional                 24540\n",
       "        functional needs repair     3019\n",
       "        non functional             14718\n",
       "rwssp   functional                   805\n",
       "        functional needs repair      109\n",
       "        non functional               460\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_funder(row):\n",
    "    if row['funder']=='Government Of Tanzania':\n",
    "        return 'gov'\n",
    "    elif row['funder']=='Danida':\n",
    "        return 'danida'\n",
    "    elif row['funder']=='Hesawa':\n",
    "        return 'hesawa'\n",
    "    elif row['funder']=='Rwssp':\n",
    "        return 'rwssp'\n",
    "    elif row['funder']=='World Bank':\n",
    "        return 'bank'\n",
    "    else:\n",
    "        return 'other'\n",
    "# Explain why top 5, and also include explanation for why reverting the rest to other\n",
    "df['funder'] = df.apply(lambda row: update_funder(row), axis=1)\n",
    "\n",
    "df.groupby(['funder','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the percentage of functional waterpoints by each funder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functional bank waterpoints =  40.4 %\n",
      "functional danida waterpoints =  55.01 %\n",
      "functional gov waterpoints =  40.951 %\n",
      "functional hesawa waterpoints =  42.507 %\n",
      "functional rwssp waterpoints =  58.588 %\n",
      "functional other waterpoints =  58.046 %\n"
     ]
    }
   ],
   "source": [
    "functional_fund_bank = (len(df[(df['status_group'] == 'functional') & (df['funder']=='bank')]))/(len(df[df['funder']=='bank']))*100\n",
    "functional_fund_danida = (len(df[(df['status_group'] == 'functional') & (df['funder']=='danida')]))/(len(df[df['funder']=='danida']))*100\n",
    "functional_fund_gov = (len(df[(df['status_group'] == 'functional') & (df['funder']=='gov')]))/(len(df[df['funder']=='gov']))*100\n",
    "functional_fund_hesawa = (len(df[(df['status_group'] == 'functional') & (df['funder']=='hesawa')]))/(len(df[df['funder']=='hesawa']))*100\n",
    "functional_fund_rwssp = (len(df[(df['status_group'] == 'functional') & (df['funder']=='rwssp')]))/(len(df[df['funder']=='rwssp']))*100\n",
    "functional_fund_other = (len(df[(df['status_group'] == 'functional') & (df['funder']=='other')]))/(len(df[df['funder']=='other']))*100\n",
    "\n",
    "print('functional bank waterpoints = ', round(functional_fund_bank,3),'%')\n",
    "print('functional danida waterpoints = ', round(functional_fund_danida,3),'%')\n",
    "print('functional gov waterpoints = ', round(functional_fund_gov,3),'%')\n",
    "print('functional hesawa waterpoints = ', round(functional_fund_hesawa,3),'%')\n",
    "print('functional rwssp waterpoints = ', round(functional_fund_rwssp,3),'%')\n",
    "print('functional other waterpoints = ', round(functional_fund_other,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DWE                        17402\n",
       "Government                  1825\n",
       "RWE                         1206\n",
       "Commu                       1060\n",
       "DANIDA                      1050\n",
       "                           ...  \n",
       "DWE/Ubalozi wa Marekani        1\n",
       "VICF                           1\n",
       "Schoo                          1\n",
       "DMMD                           1\n",
       "TCRS/ TASSAF                   1\n",
       "Name: installer, Length: 2145, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.installer.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep top 5 installers and set the rest to other, including missing values. Then, check the difference between the installers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "installer  status_group           \n",
       "commu      functional                   724\n",
       "           functional needs repair       32\n",
       "           non functional               304\n",
       "danida     functional                   542\n",
       "           functional needs repair       83\n",
       "           non functional               425\n",
       "dwe        functional                  9433\n",
       "           functional needs repair     1622\n",
       "           non functional              6347\n",
       "gov        functional                   535\n",
       "           functional needs repair      256\n",
       "           non functional              1034\n",
       "other      functional                 20721\n",
       "           functional needs repair     2187\n",
       "           non functional             13949\n",
       "rwe        functional                   304\n",
       "           functional needs repair      137\n",
       "           non functional               765\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_installer(row):\n",
    "    if row['installer']=='DWE':\n",
    "        return 'dwe'\n",
    "    elif row['installer']=='Government':\n",
    "        return 'gov'\n",
    "    elif row['installer']=='RWE':\n",
    "        return 'rwe'\n",
    "    elif row['installer']=='Commu':\n",
    "        return 'commu'\n",
    "    elif row['installer']=='DANIDA':\n",
    "        return 'danida'\n",
    "    else:\n",
    "        return 'other'  \n",
    "\n",
    "df['installer'] = df.apply(lambda row: update_installer(row), axis=1)\n",
    "\n",
    "df.groupby(['installer','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the percentage of functional waterpoints by each installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functional commu waterpoints =  68.302 %\n",
      "functional danida waterpoints =  51.619 %\n",
      "functional dwe waterpoints =  54.206 %\n",
      "functional gov waterpoints =  29.315 %\n",
      "functional rwe waterpoints =  25.207 %\n",
      "functional other waterpoints =  56.22 %\n"
     ]
    }
   ],
   "source": [
    "functional_install_commu = (len(df[(df['status_group'] == 'functional') & (df['installer']=='commu')]))/(len(df[df['installer']=='commu']))*100\n",
    "functional_install_danida = (len(df[(df['status_group'] == 'functional') & (df['installer']=='danida')]))/(len(df[df['installer']=='danida']))*100\n",
    "functional_install_dwe = (len(df[(df['status_group'] == 'functional') & (df['installer']=='dwe')]))/(len(df[df['installer']=='dwe']))*100\n",
    "functional_install_gov = (len(df[(df['status_group'] == 'functional') & (df['installer']=='gov')]))/(len(df[df['installer']=='gov']))*100\n",
    "functional_install_rwe = (len(df[(df['status_group'] == 'functional') & (df['installer']=='rwe')]))/(len(df[df['installer']=='rwe']))*100\n",
    "functional_install_other = (len(df[(df['status_group'] == 'functional') & (df['installer']=='other')]))/(len(df[df['installer']=='other']))*100\n",
    "\n",
    "print('functional commu waterpoints = ', round(functional_install_commu,3),'%')\n",
    "print('functional danida waterpoints = ', round(functional_install_danida,3),'%')\n",
    "print('functional dwe waterpoints = ', round(functional_install_dwe,3),'%')\n",
    "print('functional gov waterpoints = ', round(functional_install_gov,3),'%')\n",
    "print('functional rwe waterpoints = ', round(functional_install_rwe,3),'%')\n",
    "print('functional other waterpoints = ', round(functional_install_other,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are some differences between the functional waterpoints funded and installed by the same organisations - gov/danida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### subvillage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Madukani    508\n",
       "Shuleni     506\n",
       "Majengo     502\n",
       "Kati        373\n",
       "Mtakuja     262\n",
       "           ... \n",
       "Kiniha        1\n",
       "Itanga        1\n",
       "Buhanuzi      1\n",
       "Mwanya A      1\n",
       "Omoche B      1\n",
       "Name: subvillage, Length: 19287, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.subvillage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 19287 unique <code>subvillage</code>, of which the largest group is only 508. It is unlikely to be a meaningful feature, and will thus be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code', 'num_private', 'subvillage']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('subvillage')\n",
    "# Explain why 19k unique subvillage is not meaningful - eg dataset size only 50k\n",
    "df.drop('subvillage',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### public_meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     51011\n",
       "False     5055\n",
       "Name: public_meeting, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.public_meeting.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "public_meeting  status_group           \n",
       "False           functional                  2173\n",
       "                functional needs repair      442\n",
       "                non functional              2440\n",
       "True            functional                 28408\n",
       "                functional needs repair     3719\n",
       "                non functional             18884\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['public_meeting','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `public_meeting` to binary predictor and impute with median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "public_meeting  status_group           \n",
       "0.0             functional                  2173\n",
       "                functional needs repair      442\n",
       "                non functional              2440\n",
       "1.0             functional                 30086\n",
       "                functional needs repair     3875\n",
       "                non functional             20384\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_public_meeting(row):\n",
    "    if row['public_meeting']==True:\n",
    "        return 1\n",
    "    elif row['public_meeting']==False:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df['public_meeting'] = df.apply(lambda row: convert_public_meeting(row), axis=1)\n",
    "df['public_meeting'].fillna(df['public_meeting'].median(),inplace=True)\n",
    "df.groupby(['public_meeting','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### scheme_management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VWC                 36793\n",
       "WUG                  5206\n",
       "Water authority      3153\n",
       "WUA                  2883\n",
       "Water Board          2748\n",
       "Parastatal           1680\n",
       "Private operator     1063\n",
       "Company              1061\n",
       "Other                 766\n",
       "SWC                    97\n",
       "Trust                  72\n",
       "None                    1\n",
       "Name: scheme_management, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.scheme_management.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep top 5 scheme management and set the rest to other, including missing values. Then, check the difference between the scheme management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scheme_management  status_group           \n",
       "other              functional                  4627\n",
       "                   functional needs repair      513\n",
       "                   non functional              3477\n",
       "vwc                functional                 18960\n",
       "                   functional needs repair     2334\n",
       "                   non functional             15499\n",
       "water_auth         functional                  1618\n",
       "                   functional needs repair      448\n",
       "                   non functional              1087\n",
       "water_bd           functional                  2053\n",
       "                   functional needs repair      111\n",
       "                   non functional               584\n",
       "wua                functional                  1995\n",
       "                   functional needs repair      239\n",
       "                   non functional               649\n",
       "wug                functional                  3006\n",
       "                   functional needs repair      672\n",
       "                   non functional              1528\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_scheme_management(row):\n",
    "    if row['scheme_management']=='VWC':\n",
    "        return 'vwc'\n",
    "    elif row['scheme_management']=='WUG':\n",
    "        return 'wug'\n",
    "    elif row['scheme_management']=='Water authority':\n",
    "        return 'water_auth'\n",
    "    elif row['scheme_management']=='WUA':\n",
    "        return 'wua'\n",
    "    elif row['scheme_management']=='Water Board':\n",
    "        return 'water_bd'\n",
    "    else:\n",
    "        return 'other'  \n",
    "# Consider not keeping just the top 5. Might not be necessary given the limited number \n",
    "df['scheme_management'] = df.apply(lambda row: update_scheme_management(row), axis=1)\n",
    "\n",
    "df.groupby(['scheme_management','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the percentage of functional waterpoints by each scheme management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functional vwc waterpoints =  51.532 %\n",
      "functional water_auth waterpoints =  51.316 %\n",
      "functional water_bd waterpoints =  74.709 %\n",
      "functional wua waterpoints =  69.199 %\n",
      "functional wug waterpoints =  57.741 %\n",
      "functional other waterpoints =  53.696 %\n"
     ]
    }
   ],
   "source": [
    "functional_vwc = (len(df[(df['status_group'] == 'functional') & (df['scheme_management']=='vwc')]))/(len(df[df['scheme_management']=='vwc']))*100\n",
    "functional_water_auth = (len(df[(df['status_group'] == 'functional') & (df['scheme_management']=='water_auth')]))/(len(df[df['scheme_management']=='water_auth']))*100\n",
    "functional_water_bd = (len(df[(df['status_group'] == 'functional') & (df['scheme_management']=='water_bd')]))/(len(df[df['scheme_management']=='water_bd']))*100\n",
    "functional_wua = (len(df[(df['status_group'] == 'functional') & (df['scheme_management']=='wua')]))/(len(df[df['scheme_management']=='wua']))*100\n",
    "functional_wug = (len(df[(df['status_group'] == 'functional') & (df['scheme_management']=='wug')]))/(len(df[df['scheme_management']=='wug']))*100\n",
    "functional_other = (len(df[(df['status_group'] == 'functional') & (df['scheme_management']=='other')]))/(len(df[df['scheme_management']=='other']))*100\n",
    "\n",
    "print('functional vwc waterpoints = ', round(functional_vwc,3),'%')\n",
    "print('functional water_auth waterpoints = ', round(functional_water_auth,3),'%')\n",
    "print('functional water_bd waterpoints = ', round(functional_water_bd,3),'%')\n",
    "print('functional wua waterpoints = ', round(functional_wua,3),'%')\n",
    "print('functional wug waterpoints = ', round(functional_wug,3),'%')\n",
    "print('functional other waterpoints = ', round(functional_other,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### scheme_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "K                               682\n",
       "None                            644\n",
       "Borehole                        546\n",
       "Chalinze wate                   405\n",
       "M                               400\n",
       "                               ... \n",
       "Mtumbei mpopera water supply      1\n",
       "Itoo water supply                 1\n",
       "BL Siha Sec                       1\n",
       "Ihanda spring box                 1\n",
       "Mjimwema                          1\n",
       "Name: scheme_name, Length: 2696, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.scheme_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2696 unique `scheme_name`, of which the largest group is only 682. Additionally, there are 28166 null values in this column. It is unlikely for this column to yield meaningful results and we will be dropping it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code', 'num_private', 'subvillage', 'scheme_name']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('scheme_name')\n",
    "\n",
    "df.drop('scheme_name',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### permit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     38852\n",
       "False    17492\n",
       "Name: permit, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.permit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permit  status_group           \n",
       "False   functional                  9045\n",
       "        functional needs repair     1320\n",
       "        non functional              7127\n",
       "True    functional                 21541\n",
       "        functional needs repair     2697\n",
       "        non functional             14614\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['permit','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `permit` to binary predictor and impute with median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permit  status_group           \n",
       "0.0     functional                  9045\n",
       "        functional needs repair     1320\n",
       "        non functional              7127\n",
       "1.0     functional                 23214\n",
       "        functional needs repair     2997\n",
       "        non functional             15697\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_permit(row):\n",
    "    if row['permit']==True:\n",
    "        return 1\n",
    "    elif row['permit']==False:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df['permit'] = df.apply(lambda row: convert_permit(row), axis=1)\n",
    "df['permit'].fillna(df['permit'].median(),inplace=True)\n",
    "df.groupby(['permit','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having removed all null, ensure that there is no other invalid data $-$ 0 $-$ that can be immediately obvious for relevant columns such as `population`, `gps_height`, `amount_tsh` and `construction_year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh               41639\n",
       "date_recorded                0\n",
       "funder                       0\n",
       "gps_height               20438\n",
       "installer                    0\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "basin                        0\n",
       "region                       0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population               21381\n",
       "public_meeting               0\n",
       "recorded_by                  0\n",
       "scheme_management            0\n",
       "permit                       0\n",
       "construction_year        20709\n",
       "extraction_type              0\n",
       "extraction_type_group        0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "management_group             0\n",
       "payment                      0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quality_group                0\n",
       "quantity                     0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "source_type                  0\n",
       "source_class                 0\n",
       "waterpoint_type              0\n",
       "waterpoint_type_group        0\n",
       "status_group                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gps_height'].replace(0, np.nan, inplace=True)\n",
    "df['population'].replace(0, np.nan, inplace=True)\n",
    "df['amount_tsh'].replace(0, np.nan, inplace=True)\n",
    "df['construction_year'].replace(0, np.nan, inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming `water_tsh`, `gps_height` and `population` are affected by `region_code` and `district_code`, impute missing values with mean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount_tsh'].fillna(df.groupby(['region', 'district_code'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "df['amount_tsh'].fillna(df.groupby(['region'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "df['amount_tsh'].fillna(df['amount_tsh'].mean(), inplace=True)\n",
    "df['gps_height'].fillna(df.groupby(['region', 'district_code'])['gps_height'].transform('mean'), inplace=True)\n",
    "df['gps_height'].fillna(df.groupby(['region'])['gps_height'].transform('mean'), inplace=True)\n",
    "df['gps_height'].fillna(df['gps_height'].mean(), inplace=True)\n",
    "df['population'].fillna(df.groupby(['region', 'district_code'])['population'].transform('mean'), inplace=True)\n",
    "df['population'].fillna(df.groupby(['region'])['population'].transform('mean'), inplace=True)\n",
    "df['population'].fillna(df['population'].mean(), inplace=True)\n",
    "# Explain why region/district, check correlation. Explain why not using region etc for the other imputations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`construction_year` can also be imputed with mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0\n",
       "amount_tsh               0\n",
       "date_recorded            0\n",
       "funder                   0\n",
       "gps_height               0\n",
       "installer                0\n",
       "longitude                0\n",
       "latitude                 0\n",
       "wpt_name                 0\n",
       "basin                    0\n",
       "region                   0\n",
       "district_code            0\n",
       "lga                      0\n",
       "ward                     0\n",
       "population               0\n",
       "public_meeting           0\n",
       "recorded_by              0\n",
       "scheme_management        0\n",
       "permit                   0\n",
       "construction_year        0\n",
       "extraction_type          0\n",
       "extraction_type_group    0\n",
       "extraction_type_class    0\n",
       "management               0\n",
       "management_group         0\n",
       "payment                  0\n",
       "payment_type             0\n",
       "water_quality            0\n",
       "quality_group            0\n",
       "quantity                 0\n",
       "quantity_group           0\n",
       "source                   0\n",
       "source_type              0\n",
       "source_class             0\n",
       "waterpoint_type          0\n",
       "waterpoint_type_group    0\n",
       "status_group             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['construction_year'].fillna(df['construction_year'].mean(),inplace=True)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `construction_year` and `date_recorded` into the number of years the waterpoint has been in operation for, and drop both features after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
    "df['operational_years'] = df.date_recorded.dt.year - df.construction_year\n",
    "\n",
    "df.drop('date_recorded', axis=1, inplace=True)\n",
    "df.drop('construction_year', axis=1, inplace=True)\n",
    "drop.append('date_recorded')\n",
    "drop.append('construction_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take the same steps for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Government Of Tanzania         2215\n",
       "Danida                          793\n",
       "Hesawa                          580\n",
       "World Bank                      352\n",
       "Kkkt                            336\n",
       "                               ... \n",
       "Aveda                             1\n",
       "Ripat                             1\n",
       "Water Project Mbawala Chini       1\n",
       "Omari Abdallah                    1\n",
       "Nyanokwi                          1\n",
       "Name: funder, Length: 980, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.funder.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_funder_test(row):\n",
    "    if row['funder']=='Government Of Tanzania':\n",
    "        return 'gov'\n",
    "    elif row['funder']=='Danida':\n",
    "        return 'danida'\n",
    "    elif row['funder']=='Hesawa':\n",
    "        return 'hesawa'\n",
    "    elif row['funder']=='World Bank':\n",
    "        return 'bank'\n",
    "    elif row['funder']=='Kkkt':\n",
    "        return 'kkkt'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "test_df['funder'] = test_df.apply(lambda row: update_funder(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DWE                  4349\n",
       "Government            457\n",
       "RWE                   292\n",
       "Commu                 287\n",
       "DANIDA                255\n",
       "                     ... \n",
       "UNIVERSAL COMPANY       1\n",
       "Matimo Sangi            1\n",
       "Hesewa                  1\n",
       "Hadija Makame           1\n",
       "NWE                     1\n",
       "Name: installer, Length: 1091, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.installer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_installer_test(row):\n",
    "    if row['installer']=='DWE':\n",
    "        return 'dwe'\n",
    "    elif row['installer']=='Government':\n",
    "        return 'gov'\n",
    "    elif row['installer']=='RWE':\n",
    "        return 'rwe'\n",
    "    elif row['installer']=='Commu':\n",
    "        return 'commu'\n",
    "    elif row['installer']=='DANIDA':\n",
    "        return 'danida'\n",
    "    else:\n",
    "        return 'other'  \n",
    "\n",
    "test_df['installer'] = test_df.apply(lambda row: update_installer(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['public_meeting'] = test_df.apply(lambda row: convert_public_meeting(row), axis=1)\n",
    "test_df['public_meeting'].fillna(test_df['public_meeting'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VWC                 9124\n",
       "WUG                 1290\n",
       "Water authority      822\n",
       "Water Board          714\n",
       "WUA                  668\n",
       "Parastatal           444\n",
       "Company              280\n",
       "Private operator     263\n",
       "Other                230\n",
       "SWC                   26\n",
       "Trust                 20\n",
       "Name: scheme_management, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.scheme_management.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scheme_management_test(row):\n",
    "    if row['scheme_management']=='VWC':\n",
    "        return 'vwc'\n",
    "    elif row['scheme_management']=='WUG':\n",
    "        return 'wug'\n",
    "    elif row['scheme_management']=='Water authority':\n",
    "        return 'water_auth'\n",
    "    elif row['scheme_management']=='Water Board':\n",
    "        return 'water_bd'\n",
    "    elif row['scheme_management']=='WUA':\n",
    "        return 'wua'\n",
    "    else:\n",
    "        return 'other'  \n",
    "\n",
    "test_df['scheme_management'] = test_df.apply(lambda row: update_scheme_management(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['permit'] = test_df.apply(lambda row: convert_permit(row), axis=1)\n",
    "test_df['permit'].fillna(test_df['permit'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh               10410\n",
       "date_recorded                0\n",
       "funder                       0\n",
       "gps_height                5211\n",
       "installer                    0\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "num_private                  0\n",
       "basin                        0\n",
       "subvillage                  99\n",
       "region                       0\n",
       "region_code                  0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population                5453\n",
       "public_meeting               0\n",
       "recorded_by                  0\n",
       "scheme_management            0\n",
       "scheme_name               7092\n",
       "permit                       0\n",
       "construction_year         5260\n",
       "extraction_type              0\n",
       "extraction_type_group        0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "management_group             0\n",
       "payment                      0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quality_group                0\n",
       "quantity                     0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "source_type                  0\n",
       "source_class                 0\n",
       "waterpoint_type              0\n",
       "waterpoint_type_group        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['gps_height'].replace(0, np.nan, inplace=True)\n",
    "test_df['population'].replace(0, np.nan, inplace=True)\n",
    "test_df['amount_tsh'].replace(0, np.nan, inplace=True)\n",
    "test_df['construction_year'].replace(0, np.nan, inplace=True)\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['amount_tsh'].fillna(test_df.groupby(['region', 'district_code'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "test_df['amount_tsh'].fillna(test_df.groupby(['region'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "test_df['amount_tsh'].fillna(test_df['amount_tsh'].mean(), inplace=True)\n",
    "test_df['gps_height'].fillna(test_df.groupby(['region', 'district_code'])['gps_height'].transform('mean'), inplace=True)\n",
    "test_df['gps_height'].fillna(test_df.groupby(['region'])['gps_height'].transform('mean'), inplace=True)\n",
    "test_df['gps_height'].fillna(test_df['gps_height'].mean(), inplace=True)\n",
    "test_df['population'].fillna(test_df.groupby(['region', 'district_code'])['population'].transform('mean'), inplace=True)\n",
    "test_df['population'].fillna(test_df.groupby(['region'])['population'].transform('mean'), inplace=True)\n",
    "test_df['population'].fillna(test_df['population'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['construction_year'].fillna(test_df['construction_year'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['date_recorded'] = pd.to_datetime(test_df['date_recorded'])\n",
    "test_df['operational_years'] = test_df.date_recorded.dt.year - test_df.construction_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in drop:\n",
    "    test_df.drop(i, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df).to_csv(\"clean.csv\", index=False)\n",
    "pd.DataFrame(test_df).to_csv(\"clean_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building (First Submission) - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('clean.csv')\n",
    "y_train = X_train.pop('status_group')\n",
    "X_test = pd.read_csv('clean_test.csv')\n",
    "\n",
    "X_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "X_test.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 35 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     59400 non-null  int64  \n",
      " 1   amount_tsh             59400 non-null  float64\n",
      " 2   funder                 59400 non-null  object \n",
      " 3   gps_height             59400 non-null  float64\n",
      " 4   installer              59400 non-null  object \n",
      " 5   longitude              59400 non-null  float64\n",
      " 6   latitude               59400 non-null  float64\n",
      " 7   wpt_name               59400 non-null  object \n",
      " 8   basin                  59400 non-null  object \n",
      " 9   region                 59400 non-null  object \n",
      " 10  district_code          59400 non-null  int64  \n",
      " 11  lga                    59400 non-null  object \n",
      " 12  ward                   59400 non-null  object \n",
      " 13  population             59400 non-null  float64\n",
      " 14  public_meeting         59400 non-null  float64\n",
      " 15  recorded_by            59400 non-null  object \n",
      " 16  scheme_management      59400 non-null  object \n",
      " 17  permit                 59400 non-null  float64\n",
      " 18  extraction_type        59400 non-null  object \n",
      " 19  extraction_type_group  59400 non-null  object \n",
      " 20  extraction_type_class  59400 non-null  object \n",
      " 21  management             59400 non-null  object \n",
      " 22  management_group       59400 non-null  object \n",
      " 23  payment                59400 non-null  object \n",
      " 24  payment_type           59400 non-null  object \n",
      " 25  water_quality          59400 non-null  object \n",
      " 26  quality_group          59400 non-null  object \n",
      " 27  quantity               59400 non-null  object \n",
      " 28  quantity_group         59400 non-null  object \n",
      " 29  source                 59400 non-null  object \n",
      " 30  source_type            59400 non-null  object \n",
      " 31  source_class           59400 non-null  object \n",
      " 32  waterpoint_type        59400 non-null  object \n",
      " 33  waterpoint_type_group  59400 non-null  object \n",
      " 34  operational_years      59400 non-null  float64\n",
      "dtypes: float64(8), int64(2), object(25)\n",
      "memory usage: 15.9+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode labels into categorical variables\n",
    "https://stackoverflow.com/questions/40336502/want-to-know-the-diff-among-pd-factorize-pd-get-dummies-sklearn-preprocessing/40338956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "X_train['funder'] = pd.factorize(X_train['funder'])[0]\n",
    "X_train['installer'] = pd.factorize(X_train['installer'])[0]\n",
    "X_train['wpt_name'] = pd.factorize(X_train['wpt_name'])[0]\n",
    "X_train['basin'] = pd.factorize(X_train['basin'])[0]\n",
    "X_train['region'] = pd.factorize(X_train['region'])[0]\n",
    "X_train['lga'] = pd.factorize(X_train['lga'])[0]\n",
    "X_train['ward'] = pd.factorize(X_train['ward'])[0]\n",
    "X_train['recorded_by'] = pd.factorize(X_train['recorded_by'])[0]\n",
    "X_train['scheme_management'] = pd.factorize(X_train['scheme_management'])[0]\n",
    "X_train['extraction_type'] = pd.factorize(X_train['extraction_type'])[0]\n",
    "X_train['extraction_type_group'] = pd.factorize(X_train['extraction_type_group'])[0]\n",
    "X_train['extraction_type_class'] = pd.factorize(X_train['extraction_type_class'])[0]\n",
    "X_train['management'] = pd.factorize(X_train['management'])[0]\n",
    "X_train['management_group'] = pd.factorize(X_train['management_group'])[0]\n",
    "X_train['payment'] = pd.factorize(X_train['payment'])[0]\n",
    "X_train['payment_type'] = pd.factorize(X_train['payment_type'])[0]\n",
    "X_train['water_quality'] = pd.factorize(X_train['water_quality'])[0]\n",
    "X_train['quality_group'] = pd.factorize(X_train['quality_group'])[0]\n",
    "X_train['quantity'] = pd.factorize(X_train['quantity'])[0]\n",
    "X_train['quantity_group'] = pd.factorize(X_train['quantity_group'])[0]\n",
    "X_train['source'] = pd.factorize(X_train['source'])[0]\n",
    "X_train['source_type'] = pd.factorize(X_train['source_type'])[0]\n",
    "X_train['source_class'] = pd.factorize(X_train['source_class'])[0]\n",
    "X_train['waterpoint_type'] = pd.factorize(X_train['waterpoint_type'])[0]\n",
    "X_train['waterpoint_type_group'] = pd.factorize(X_train['waterpoint_type_group'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['funder'] = pd.factorize(X_test['funder'])[0]\n",
    "X_test['installer'] = pd.factorize(X_test['installer'])[0]\n",
    "X_test['wpt_name'] = pd.factorize(X_test['wpt_name'])[0]\n",
    "X_test['basin'] = pd.factorize(X_test['basin'])[0]\n",
    "X_test['region'] = pd.factorize(X_test['region'])[0]\n",
    "X_test['lga'] = pd.factorize(X_test['lga'])[0]\n",
    "X_test['ward'] = pd.factorize(X_test['ward'])[0]\n",
    "X_test['recorded_by'] = pd.factorize(X_test['recorded_by'])[0]\n",
    "X_test['scheme_management'] = pd.factorize(X_test['scheme_management'])[0]\n",
    "X_test['extraction_type'] = pd.factorize(X_test['extraction_type'])[0]\n",
    "X_test['extraction_type_group'] = pd.factorize(X_test['extraction_type_group'])[0]\n",
    "X_test['extraction_type_class'] = pd.factorize(X_test['extraction_type_class'])[0]\n",
    "X_test['management'] = pd.factorize(X_test['management'])[0]\n",
    "X_test['management_group'] = pd.factorize(X_test['management_group'])[0]\n",
    "X_test['payment'] = pd.factorize(X_test['payment'])[0]\n",
    "X_test['payment_type'] = pd.factorize(X_test['payment_type'])[0]\n",
    "X_test['water_quality'] = pd.factorize(X_test['water_quality'])[0]\n",
    "X_test['quality_group'] = pd.factorize(X_test['quality_group'])[0]\n",
    "X_test['quantity'] = pd.factorize(X_test['quantity'])[0]\n",
    "X_test['quantity_group'] = pd.factorize(X_test['quantity_group'])[0]\n",
    "X_test['source'] = pd.factorize(X_test['source'])[0]\n",
    "X_test['source_type'] = pd.factorize(X_test['source_type'])[0]\n",
    "X_test['source_class'] = pd.factorize(X_test['source_class'])[0]\n",
    "X_test['waterpoint_type'] = pd.factorize(X_test['waterpoint_type'])[0]\n",
    "X_test['waterpoint_type_group'] = pd.factorize(X_test['waterpoint_type_group'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 35 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     59400 non-null  int64  \n",
      " 1   amount_tsh             59400 non-null  float64\n",
      " 2   funder                 59400 non-null  int64  \n",
      " 3   gps_height             59400 non-null  float64\n",
      " 4   installer              59400 non-null  int64  \n",
      " 5   longitude              59400 non-null  float64\n",
      " 6   latitude               59400 non-null  float64\n",
      " 7   wpt_name               59400 non-null  int64  \n",
      " 8   basin                  59400 non-null  int64  \n",
      " 9   region                 59400 non-null  int64  \n",
      " 10  district_code          59400 non-null  int64  \n",
      " 11  lga                    59400 non-null  int64  \n",
      " 12  ward                   59400 non-null  int64  \n",
      " 13  population             59400 non-null  float64\n",
      " 14  public_meeting         59400 non-null  float64\n",
      " 15  recorded_by            59400 non-null  int64  \n",
      " 16  scheme_management      59400 non-null  int64  \n",
      " 17  permit                 59400 non-null  float64\n",
      " 18  extraction_type        59400 non-null  int64  \n",
      " 19  extraction_type_group  59400 non-null  int64  \n",
      " 20  extraction_type_class  59400 non-null  int64  \n",
      " 21  management             59400 non-null  int64  \n",
      " 22  management_group       59400 non-null  int64  \n",
      " 23  payment                59400 non-null  int64  \n",
      " 24  payment_type           59400 non-null  int64  \n",
      " 25  water_quality          59400 non-null  int64  \n",
      " 26  quality_group          59400 non-null  int64  \n",
      " 27  quantity               59400 non-null  int64  \n",
      " 28  quantity_group         59400 non-null  int64  \n",
      " 29  source                 59400 non-null  int64  \n",
      " 30  source_type            59400 non-null  int64  \n",
      " 31  source_class           59400 non-null  int64  \n",
      " 32  waterpoint_type        59400 non-null  int64  \n",
      " 33  waterpoint_type_group  59400 non-null  int64  \n",
      " 34  operational_years      59400 non-null  float64\n",
      "dtypes: float64(8), int64(27)\n",
      "memory usage: 15.9 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain why hyperparameters are chosen. Mention what trials you took. Which values you tried. If you changed from default, explain why\n",
    "https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html <br>\n",
    "Random Forest generally works well on default settings. Hence most of the features will not be touched.  <br>\n",
    "Increased `min_samples_split` to `6` to reduce over-fitting - in comparison to default 2. <br>\n",
    "Set `oob_score` to `True` to estimate accuracy <br>\n",
    "Set `random_state` to `1` to ensure performance is not affected by random initial state <br>\n",
    "https://stackoverflow.com/questions/55070918/does-setting-a-random-state-in-sklearns-randomforestclassifier-bias-your-model <br>\n",
    "Set `n_jobs` to `-1` to use all CPUs<br>\n",
    "Staggered `n_estimators` to observe which relative amount of trees is best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(min_samples_split=6,\n",
    "                                oob_score=True,\n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "param_grid = {\"n_estimators\" : [500, 750, 1000]}\n",
    "\n",
    "gs = GridSearchCV(estimator=rf,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=5,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8005892255892256\n",
      "{'n_estimators': 500}\n",
      "{'mean_fit_time': array([40.66975927, 46.07213914, 50.15852165]), 'std_fit_time': array([0.18662643, 0.09424675, 0.20301247]), 'mean_score_time': array([2.29038763, 1.56403172, 1.82366753]), 'std_score_time': array([0.11621261, 0.07472312, 0.02482247]), 'param_n_estimators': masked_array(data=[500, 750, 1000],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_estimators': 500}, {'n_estimators': 750}, {'n_estimators': 1000}], 'split0_test_score': array([0.80178451, 0.80218855, 0.80205387]), 'split1_test_score': array([0.79939394, 0.79841751, 0.79838384]), 'mean_test_score': array([0.80058923, 0.80030303, 0.80021886]), 'std_test_score': array([0.00119529, 0.00188552, 0.00183502]), 'rank_test_score': array([1, 2, 3])}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "print(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8168\n"
     ]
    }
   ],
   "source": [
    "X_train.drop('id',axis=1,inplace=True)\n",
    "rf = RandomForestClassifier(criterion='gini',\n",
    "                                min_samples_split=6,\n",
    "                                n_estimators=1000,\n",
    "                                max_features='auto',\n",
    "                                oob_score=True,\n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "                            \n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "print(\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0.091455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.089158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>quantity</td>\n",
       "      <td>0.074807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>quantity_group</td>\n",
       "      <td>0.068052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wpt_name</td>\n",
       "      <td>0.057641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>operational_years</td>\n",
       "      <td>0.053453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gps_height</td>\n",
       "      <td>0.051422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ward</td>\n",
       "      <td>0.047653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>population</td>\n",
       "      <td>0.037149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>waterpoint_type</td>\n",
       "      <td>0.032905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             variable  importance\n",
       "4           longitude    0.091455\n",
       "5            latitude    0.089158\n",
       "26           quantity    0.074807\n",
       "27     quantity_group    0.068052\n",
       "6            wpt_name    0.057641\n",
       "33  operational_years    0.053453\n",
       "2          gps_height    0.051422\n",
       "11               ward    0.047653\n",
       "12         population    0.037149\n",
       "31    waterpoint_type    0.032905"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)[:10]\n",
    "# Screenshot of submission on board at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx=X_test['id']\n",
    "X_test.drop(['id'],axis=1, inplace=True)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(y_pred)\n",
    "y_pred['id']=idx\n",
    "y_pred.columns=['status_group','id']\n",
    "y_pred=y_pred[['id','status_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).to_csv(\"submission_rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps taken to improve accuracy (Second Submission) - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('clean.csv')\n",
    "y_train = X_train.pop('status_group')\n",
    "X_test = pd.read_csv('clean_test.csv')\n",
    "\n",
    "X_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "X_test.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "X_train['funder'] = pd.factorize(X_train['funder'])[0]\n",
    "X_train['installer'] = pd.factorize(X_train['installer'])[0]\n",
    "X_train['wpt_name'] = pd.factorize(X_train['wpt_name'])[0]\n",
    "X_train['basin'] = pd.factorize(X_train['basin'])[0]\n",
    "X_train['region'] = pd.factorize(X_train['region'])[0]\n",
    "X_train['lga'] = pd.factorize(X_train['lga'])[0]\n",
    "X_train['ward'] = pd.factorize(X_train['ward'])[0]\n",
    "X_train['recorded_by'] = pd.factorize(X_train['recorded_by'])[0]\n",
    "X_train['scheme_management'] = pd.factorize(X_train['scheme_management'])[0]\n",
    "X_train['extraction_type'] = pd.factorize(X_train['extraction_type'])[0]\n",
    "X_train['extraction_type_group'] = pd.factorize(X_train['extraction_type_group'])[0]\n",
    "X_train['extraction_type_class'] = pd.factorize(X_train['extraction_type_class'])[0]\n",
    "X_train['management'] = pd.factorize(X_train['management'])[0]\n",
    "X_train['management_group'] = pd.factorize(X_train['management_group'])[0]\n",
    "X_train['payment'] = pd.factorize(X_train['payment'])[0]\n",
    "X_train['payment_type'] = pd.factorize(X_train['payment_type'])[0]\n",
    "X_train['water_quality'] = pd.factorize(X_train['water_quality'])[0]\n",
    "X_train['quality_group'] = pd.factorize(X_train['quality_group'])[0]\n",
    "X_train['quantity'] = pd.factorize(X_train['quantity'])[0]\n",
    "X_train['quantity_group'] = pd.factorize(X_train['quantity_group'])[0]\n",
    "X_train['source'] = pd.factorize(X_train['source'])[0]\n",
    "X_train['source_type'] = pd.factorize(X_train['source_type'])[0]\n",
    "X_train['source_class'] = pd.factorize(X_train['source_class'])[0]\n",
    "X_train['waterpoint_type'] = pd.factorize(X_train['waterpoint_type'])[0]\n",
    "X_train['waterpoint_type_group'] = pd.factorize(X_train['waterpoint_type_group'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['funder'] = pd.factorize(X_test['funder'])[0]\n",
    "X_test['installer'] = pd.factorize(X_test['installer'])[0]\n",
    "X_test['wpt_name'] = pd.factorize(X_test['wpt_name'])[0]\n",
    "X_test['basin'] = pd.factorize(X_test['basin'])[0]\n",
    "X_test['region'] = pd.factorize(X_test['region'])[0]\n",
    "X_test['lga'] = pd.factorize(X_test['lga'])[0]\n",
    "X_test['ward'] = pd.factorize(X_test['ward'])[0]\n",
    "X_test['recorded_by'] = pd.factorize(X_test['recorded_by'])[0]\n",
    "X_test['scheme_management'] = pd.factorize(X_test['scheme_management'])[0]\n",
    "X_test['extraction_type'] = pd.factorize(X_test['extraction_type'])[0]\n",
    "X_test['extraction_type_group'] = pd.factorize(X_test['extraction_type_group'])[0]\n",
    "X_test['extraction_type_class'] = pd.factorize(X_test['extraction_type_class'])[0]\n",
    "X_test['management'] = pd.factorize(X_test['management'])[0]\n",
    "X_test['management_group'] = pd.factorize(X_test['management_group'])[0]\n",
    "X_test['payment'] = pd.factorize(X_test['payment'])[0]\n",
    "X_test['payment_type'] = pd.factorize(X_test['payment_type'])[0]\n",
    "X_test['water_quality'] = pd.factorize(X_test['water_quality'])[0]\n",
    "X_test['quality_group'] = pd.factorize(X_test['quality_group'])[0]\n",
    "X_test['quantity'] = pd.factorize(X_test['quantity'])[0]\n",
    "X_test['quantity_group'] = pd.factorize(X_test['quantity_group'])[0]\n",
    "X_test['source'] = pd.factorize(X_test['source'])[0]\n",
    "X_test['source_type'] = pd.factorize(X_test['source_type'])[0]\n",
    "X_test['source_class'] = pd.factorize(X_test['source_class'])[0]\n",
    "X_test['waterpoint_type'] = pd.factorize(X_test['waterpoint_type'])[0]\n",
    "X_test['waterpoint_type_group'] = pd.factorize(X_test['waterpoint_type_group'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more parameters to be tuned automatically.\n",
    "`n_estimators` - number of trees in the forest.\n",
    "\n",
    "We are using `oob_score_` to optimize as it is generally unbiased, whereas $R^2$ might overfit on training data.\n",
    "https://stats.stackexchange.com/questions/288699/r2-score-vs-oob-score-random-forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_gs_score_ax(parameterization, weight=None):\n",
    "\n",
    "    p_names = ['max_features', 'min_samples_split',\n",
    "              'min_samples_leaf', 'n_estimators']\n",
    "    params = {}\n",
    "    \n",
    "    for p in p_names:\n",
    "        params[p] = parameterization.get(p)\n",
    "    \n",
    "    print(params)\n",
    "\n",
    "    rf = RandomForestClassifier(criterion='gini',\n",
    "                                max_features=params['max_features'],\n",
    "                                min_samples_split=params['min_samples_split'],\n",
    "                                min_samples_leaf=params['min_samples_leaf'],\n",
    "                                n_estimators=params['n_estimators'],\n",
    "                                oob_score=True,\n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    print(rf.oob_score_)\n",
    "    return rf.oob_score_\n",
    "\n",
    "def evaluate_rf(parameters):\n",
    "    return {\"rf_gs\": rf_gs_score_ax(parameters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters=[\n",
    "    {\n",
    "        \"name\": \"max_features\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [1, 34],\n",
    "        \"log_scale\": False,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"min_samples_split\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [2, 10],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"min_samples_leaf\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [1, 10],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"n_estimators\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [100, 1500],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-09 23:58:03] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter max_features. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 11-09 23:58:03] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter min_samples_split. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 11-09 23:58:03] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter min_samples_leaf. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 11-09 23:58:03] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter n_estimators. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 11-09 23:58:03] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials]). Iterations after 5 will take longer to generate due to  model-fitting.\n",
      "[INFO 11-09 23:58:03] ax.service.managed_loop: Started full optimization with 15 steps.\n",
      "[INFO 11-09 23:58:03] ax.service.managed_loop: Running optimization trial 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 31, 'min_samples_split': 6, 'min_samples_leaf': 10, 'n_estimators': 1285}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 00:00:15] ax.service.managed_loop: Running optimization trial 2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.804040404040404\n",
      "{'max_features': 15, 'min_samples_split': 6, 'min_samples_leaf': 5, 'n_estimators': 680}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 00:01:00] ax.service.managed_loop: Running optimization trial 3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8114478114478114\n",
      "{'max_features': 22, 'min_samples_split': 2, 'min_samples_leaf': 1, 'n_estimators': 908}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 00:02:22] ax.service.managed_loop: Running optimization trial 4...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8109090909090909\n",
      "{'max_features': 11, 'min_samples_split': 5, 'min_samples_leaf': 2, 'n_estimators': 1387}\n",
      "0.81503367003367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 00:03:36] ax.service.managed_loop: Running optimization trial 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 30, 'min_samples_split': 9, 'min_samples_leaf': 1, 'n_estimators': 1262}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 00:05:59] ax.service.managed_loop: Running optimization trial 6...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8132323232323232\n",
      "{'max_features': 15, 'min_samples_split': 7, 'min_samples_leaf': 1, 'n_estimators': 1363}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 00:07:29] ax.service.managed_loop: Running optimization trial 7...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8151851851851852\n",
      "{'max_features': 6, 'min_samples_split': 7, 'min_samples_leaf': 2, 'n_estimators': 1256}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 00:08:16] ax.service.managed_loop: Running optimization trial 8...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8146801346801347\n",
      "{'max_features': 14, 'min_samples_split': 7, 'min_samples_leaf': 2, 'n_estimators': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 00:09:45] ax.service.managed_loop: Running optimization trial 9...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8146464646464646\n",
      "{'max_features': 7, 'min_samples_split': 6, 'min_samples_leaf': 1, 'n_estimators': 1485}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 00:10:43] ax.service.managed_loop: Running optimization trial 10...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816010101010101\n",
      "{'max_features': 1, 'min_samples_split': 4, 'min_samples_leaf': 1, 'n_estimators': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 00:11:19] ax.service.managed_loop: Running optimization trial 11...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8132323232323232\n",
      "{'max_features': 11, 'min_samples_split': 6, 'min_samples_leaf': 1, 'n_estimators': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 00:12:33] ax.service.managed_loop: Running optimization trial 12...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8157239057239057\n",
      "{'max_features': 5, 'min_samples_split': 7, 'min_samples_leaf': 1, 'n_estimators': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 00:13:23] ax.service.managed_loop: Running optimization trial 13...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8156734006734007\n",
      "{'max_features': 7, 'min_samples_split': 6, 'min_samples_leaf': 1, 'n_estimators': 1359}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 00:14:15] ax.service.managed_loop: Running optimization trial 14...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8155892255892256\n",
      "{'max_features': 15, 'min_samples_split': 10, 'min_samples_leaf': 1, 'n_estimators': 1045}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 00:15:24] ax.service.managed_loop: Running optimization trial 15...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814006734006734\n",
      "{'max_features': 8, 'min_samples_split': 6, 'min_samples_leaf': 1, 'n_estimators': 1500}\n",
      "0.8155555555555556\n"
     ]
    }
   ],
   "source": [
    "from ax import optimize\n",
    "\n",
    "best_parameters, values, experiment, model = optimize(\n",
    "    parameters=parameters,\n",
    "    evaluation_function=rf_gs_score_ax,\n",
    "    objective_name='rf_gs',\n",
    "    total_trials=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 7,\n",
       " 'min_samples_split': 6,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 1485}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'rf_gs': 0.8160100950904645}, {'rf_gs': {'rf_gs': 9.21624643215365e-13}})"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8166\n"
     ]
    }
   ],
   "source": [
    "X_train.drop('id',axis=1,inplace=True)\n",
    "rf = RandomForestClassifier(criterion='gini',\n",
    "                                max_features=best_parameters['max_features'],\n",
    "                                min_samples_split=best_parameters['min_samples_split'],\n",
    "                                min_samples_leaf=best_parameters['min_samples_leaf'],\n",
    "                                n_estimators=best_parameters['n_estimators'],\n",
    "                                oob_score=True,\n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "                            \n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "print(\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=X_test['id']\n",
    "X_test.drop(['id'],axis=1, inplace=True)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(y_pred)\n",
    "y_pred['id']=idx\n",
    "y_pred.columns=['status_group','id']\n",
    "y_pred=y_pred[['id','status_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).to_csv(\"submission_rf_ax.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 - Using AX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, enable_categorical =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define objective function for hyperparameter optimization\n",
    "https://www.justintodata.com/hyperparameter-tuning-with-python-complete-step-by-step-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_cv_score_ax(parameterization, weight=None):\n",
    "    NFOLD = 7\n",
    "    NUM_BOOST_ROUND = 500\n",
    "\n",
    "    p_names = ['learning_rate', 'max_depth' 'subsample', 'min_split_loss', 'min_child_weight', 'colsample_bytree', \n",
    "              'colsample_bylevel', 'colsample_bynode', 'lambda', 'alpha']\n",
    "    params = {}\n",
    "    params['objective'] = 'reg:squarederror'\n",
    "    \n",
    "    for p in p_names:\n",
    "        params[p] = parameterization.get(p)\n",
    "    print(params)\n",
    "    # K-Fold cross validation score.\n",
    "    cv_results = xgb.cv(dtrain=dtrain,\n",
    "                        params=params,\n",
    "                        nfold=NFOLD,\n",
    "                        num_boost_round=NUM_BOOST_ROUND,\n",
    "                        metrics=\"roc_auc\", \n",
    "                        as_pandas=True,\n",
    "                        seed=987)\n",
    "    print(cv_results)\n",
    "    return roc_auc_score(cv_results)\n",
    "\n",
    "def evaluate_xgboost(parameters):\n",
    "    return {\"xgboost_cv\": xgboost_cv_score_ax(parameters)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the parameters for each hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters=[\n",
    "    {\n",
    "        \"name\": \"learning_rate\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.075, 0.7],\n",
    "        \"log_scale\": False,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"max_depth\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [6, 14],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"subsample\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.0, 1.0],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"min_split_loss\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.0, 50.0],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"min_child_weight\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.0, 50.0],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"colsample_bytree\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.0, 1.0],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"colsample_bylevel\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.0, 1.0],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"colsample_bynode\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.0, 1.0],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"lambda\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.0, 10.0],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"alpha\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [0.0, 10.0],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-09 23:41:45] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter max_features. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 11-09 23:41:45] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter min_samples_split. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 11-09 23:41:45] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter min_samples_leaf. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 11-09 23:41:45] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter n_estimators. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 11-09 23:41:45] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials]). Iterations after 5 will take longer to generate due to  model-fitting.\n",
      "[INFO 11-09 23:41:45] ax.service.managed_loop: Started full optimization with 15 steps.\n",
      "[INFO 11-09 23:41:45] ax.service.managed_loop: Running optimization trial 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'reg:squarederror', 'learning_rate': None, 'max_depthsubsample': None, 'min_split_loss': None, 'min_child_weight': None, 'colsample_bytree': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'lambda': None, 'alpha': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-09 23:43:20] ax.service.managed_loop: Running optimization trial 2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'reg:squarederror', 'learning_rate': None, 'max_depthsubsample': None, 'min_split_loss': None, 'min_child_weight': None, 'colsample_bytree': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'lambda': None, 'alpha': None}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-219-ee8c3df6f911>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0max\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m best_parameters, values, experiment, model = optimize(\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mevaluation_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ax\\service\\managed_loop.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(parameters, evaluation_function, experiment_name, objective_name, minimize, parameter_constraints, outcome_constraints, total_trials, arms_per_trial, random_seed, generation_strategy)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0mgeneration_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgeneration_strategy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     )\n\u001b[1;32m--> 237\u001b[1;33m     \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m     \u001b[0mparameterization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mparameterization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_current_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ax\\service\\managed_loop.py\u001b[0m in \u001b[0;36mfull_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mSearchSpaceExhausted\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 logger.info(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ax\\service\\managed_loop.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Invalid number of arms per trial: {arms_per_trial}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_trial\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ax\\core\\base_trial.py\u001b[0m in \u001b[0;36mfetch_data\u001b[1;34m(self, metrics, **kwargs)\u001b[0m\n\u001b[0;32m    369\u001b[0m             \u001b[0mData\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \"\"\"\n\u001b[1;32m--> 371\u001b[1;33m         return self.experiment._fetch_trial_data(\n\u001b[0m\u001b[0;32m    372\u001b[0m             \u001b[0mtrial_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ax\\core\\simple_experiment.py\u001b[0m in \u001b[0;36m_fetch_trial_data\u001b[1;34m(self, trial_index, metrics, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mMetric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     ) -> Data:\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrial_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;31m# pyre-fixme[56]: While applying decorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ax\\core\\simple_experiment.py\u001b[0m in \u001b[0;36meval_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    124\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmark_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             evaluations[not_none(trial.arm).name] = self.evaluation_function_outer(\n\u001b[0m\u001b[0;32m    127\u001b[0m                 \u001b[0mnot_none\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ax\\core\\simple_experiment.py\u001b[0m in \u001b[0;36mevaluation_function_outer\u001b[1;34m(self, parameterization, weight)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnum_evaluation_function_params\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;31m# pyre-fixme[20]: Anonymous call expects argument `$1`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m             \u001b[0mevaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluation_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameterization\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mnum_evaluation_function_params\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mevaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluation_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameterization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-218-e1a13badac95>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(parameters)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"xgboost_cv\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mxgboost_cv_score_ax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-218-e1a13badac95>\u001b[0m in \u001b[0;36mxgboost_cv_score_ax\u001b[1;34m(parameterization, weight)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# K-Fold cross validation score.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     cv_results = xgb.cv(dtrain=dtrain,\n\u001b[0m\u001b[0;32m     15\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                         \u001b[0mnfold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNFOLD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[0;32m    496\u001b[0m                            evaluation_result_list=None))\n\u001b[0;32m    497\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1159\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1160\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ax import optimize\n",
    "\n",
    "best_parameters, values, experiment, model = optimize(\n",
    "    parameters=parameters,\n",
    "    evaluation_function=evaluate,\n",
    "    objective_name='xgboost_cv',\n",
    "    total_trials=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.270311491212343,\n",
       " 'max_depth': 7,\n",
       " 'subsample': 0.5823466491431419,\n",
       " 'min_split_loss': 26.322423993172862,\n",
       " 'min_child_weight': 33.617789631982745,\n",
       " 'colsample_bytree': 0.0,\n",
       " 'colsample_bylevel': 0.9018853233320182,\n",
       " 'colsample_bynode': 0.07086578553329038,\n",
       " 'lambda': 0.5263585357863017,\n",
       " 'alpha': 7.875683627497082}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'xgboost_cv': 0.5627194686242211},\n",
       " {'xgboost_cv': {'xgboost_cv': 1.1637216544583767e-05}})"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06752759, 0.34840482, 0.19542778, ..., 0.33143944, 0.50460416,\n",
       "       0.6522131 ], dtype=float32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "xgb_model = xgb.train(params=best_parameters, dtrain=dtrain, num_boost_round=500)\n",
    "\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "xgb_test_pred = xgb_model.predict(dtest)\n",
    "xgb_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_for_submission(features, target, test):\n",
    "#     if __name__ == '__main__':\n",
    "\n",
    "#          best_params = {'learning_rate': [0.075],\n",
    "#                         'max_depth': [14],\n",
    "#                         'min_samples_leaf': [16],\n",
    "#                         'max_features': [1.0],\n",
    "#                         'n_estimators': [100]}                      \n",
    "\n",
    "#          estimator = GridSearchCV(estimator=GradientBoostingClassifier(),\n",
    "#                                  param_grid=best_params,\n",
    "#                                  n_jobs=-1)\n",
    "\n",
    "#          estimator.fit(features, target)     \n",
    "\n",
    "#          predictions = estimator.predict(test)\n",
    "\n",
    "#          data = {'id': a, 'status_group': predictions}\n",
    "\n",
    "#          submit = pd.DataFrame(data=data)\n",
    "\n",
    "#          vals_to_replace = {2:'functional', 1:'functional needs repair',\n",
    "#                            0:'non functional'}\n",
    "\n",
    "#          submit.status_group = submit.status_group.replace(vals_to_replace)        \n",
    "\n",
    "#          submit=submit[['id','status_group']]\n",
    "         \n",
    "#          pd.DataFrame(submit).to_csv(\"submission_xg.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model for submission.\n",
    "\n",
    "# model_for_submission(features, target, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN with AX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
