{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS4242 Group Assignment\n",
    "**October 15, 2020**\n",
    "\n",
    "## Instructions\n",
    "\n",
    "+ Rename this file to `<your nusnetid>.ipynb`. For example, `e0321286.ipynb`. Also add your full name and ID in the first cell below.\n",
    "+ 2 Parts: Predictive Analytics (30 marks) & Prescriptive Analytics (10 marks)\n",
    "+ Do all required data exploration - preprocessing - feature engineering - model building and evaluation steps\n",
    "+ Submit first entry - predict on the given test data - see leaderboard position, then improve upon previous entry to improve test accuracy. Each team must have at least 2 submissions\n",
    "\n",
    "+ At least one of the submitted models:\n",
    "  + Must be a neural network implemented using PyTorch\n",
    "  + Must use automated hyperparameter tuning\n",
    "+ It is important to __explain each step__ you perform in preprocessing, feature engineering, model training. Ask yourself why you are performing the step and write the reason. While you may use any online resource, you have to cite them AND explanation should be in our own words.\n",
    "+ __50% marks - explanation, 50% marks - code__\n",
    "+ __Bonus points if your team has rank < 500__\n",
    "+ **Submission deadline: November 1, 2020; 11:59 am**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name: LECK WEI SHENG IAN\n",
    "#### NUS ID: A0168177R\n",
    "#### Name: WOO KENG THONG\n",
    "#### NUS ID: A0167991L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal is to predict the operating condition of a waterpoint for each record in the dataset. You are provided information about the waterpoints in order label them.\n",
    "\n",
    "The labels in this dataset are simple. There are three possible values:\n",
    "1. functional - the waterpoint is operational and there are no repairs needed\n",
    "2. functional needs repair - the waterpoint is operational, but needs repairs\n",
    "3. non functional - the waterpoint is not operational\n",
    "\n",
    "The format for the submission file is simply the row id and the predicted label. \n",
    "- id\tstatus_group\n",
    "- 50785\tfunctional\n",
    "- 51630\tfunctional\n",
    "\n",
    "CSV would thus look like\n",
    "- id,status_group\n",
    "- 50785,functional\n",
    "- 51630,functional\n",
    "\n",
    "The primary evaluation metric for submission will be as follows:\n",
    "- Classification Rate =1Nâˆ‘Ni=0I(yi=yi^)\n",
    "- The metric used for this competition is the classification rate, which calculates the percentage of rows where the predicted class y^ in the submission matches the actual class, y in the test set. \n",
    "- The maximum is 1 and the minimum is 0. The goal is to maximize the classification rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing & Feature Engineering - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data, and merge data and labels together into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('training-set-labels.csv')\n",
    "df = pd.read_csv('training-set-values.csv')\n",
    "test_df = pd.read_csv('test-set-values.csv')\n",
    "\n",
    "df = pd.merge(df, labels, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59400 entries, 0 to 59399\n",
      "Data columns (total 41 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     59400 non-null  int64  \n",
      " 1   amount_tsh             59400 non-null  float64\n",
      " 2   date_recorded          59400 non-null  object \n",
      " 3   funder                 55765 non-null  object \n",
      " 4   gps_height             59400 non-null  int64  \n",
      " 5   installer              55745 non-null  object \n",
      " 6   longitude              59400 non-null  float64\n",
      " 7   latitude               59400 non-null  float64\n",
      " 8   wpt_name               59400 non-null  object \n",
      " 9   num_private            59400 non-null  int64  \n",
      " 10  basin                  59400 non-null  object \n",
      " 11  subvillage             59029 non-null  object \n",
      " 12  region                 59400 non-null  object \n",
      " 13  region_code            59400 non-null  int64  \n",
      " 14  district_code          59400 non-null  int64  \n",
      " 15  lga                    59400 non-null  object \n",
      " 16  ward                   59400 non-null  object \n",
      " 17  population             59400 non-null  int64  \n",
      " 18  public_meeting         56066 non-null  object \n",
      " 19  recorded_by            59400 non-null  object \n",
      " 20  scheme_management      55523 non-null  object \n",
      " 21  scheme_name            31234 non-null  object \n",
      " 22  permit                 56344 non-null  object \n",
      " 23  construction_year      59400 non-null  int64  \n",
      " 24  extraction_type        59400 non-null  object \n",
      " 25  extraction_type_group  59400 non-null  object \n",
      " 26  extraction_type_class  59400 non-null  object \n",
      " 27  management             59400 non-null  object \n",
      " 28  management_group       59400 non-null  object \n",
      " 29  payment                59400 non-null  object \n",
      " 30  payment_type           59400 non-null  object \n",
      " 31  water_quality          59400 non-null  object \n",
      " 32  quality_group          59400 non-null  object \n",
      " 33  quantity               59400 non-null  object \n",
      " 34  quantity_group         59400 non-null  object \n",
      " 35  source                 59400 non-null  object \n",
      " 36  source_type            59400 non-null  object \n",
      " 37  source_class           59400 non-null  object \n",
      " 38  waterpoint_type        59400 non-null  object \n",
      " 39  waterpoint_type_group  59400 non-null  object \n",
      " 40  status_group           59400 non-null  object \n",
      "dtypes: float64(3), int64(7), object(31)\n",
      "memory usage: 19.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check similar predictors and eliminate highly correlated predictors to reduce redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region         region_code\n",
       "Arusha         2              3024\n",
       "               24              326\n",
       "Dar es Salaam  7               805\n",
       "Dodoma         1              2201\n",
       "Iringa         11             5294\n",
       "Kagera         18             3316\n",
       "Kigoma         16             2816\n",
       "Kilimanjaro    3              4379\n",
       "Lindi          8               300\n",
       "               18                8\n",
       "               80             1238\n",
       "Manyara        21             1583\n",
       "Mara           20             1969\n",
       "Mbeya          12             4639\n",
       "Morogoro       5              4006\n",
       "Mtwara         9               390\n",
       "               90              917\n",
       "               99              423\n",
       "Mwanza         17               55\n",
       "               19             3047\n",
       "Pwani          6              1609\n",
       "               40                1\n",
       "               60             1025\n",
       "Rukwa          15             1808\n",
       "Ruvuma         10             2640\n",
       "Shinyanga      11                6\n",
       "               14               20\n",
       "               17             4956\n",
       "Singida        13             2093\n",
       "Tabora         14             1959\n",
       "Tanga          4              2513\n",
       "               5                34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['region','region_code']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop `region_code` as it seems to be identify regions, yet is not able to stand on its own as there are identical region codes in different regions. `drop` list is compiled for each column dropped for subsequent use with test values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop = []\n",
    "drop.append('region_code')\n",
    "\n",
    "df.drop('region_code',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extraction_type            extraction_type_group  extraction_type_class\n",
       "afridev                    afridev                handpump                  1770\n",
       "cemo                       other motorpump        motorpump                   90\n",
       "climax                     other motorpump        motorpump                   32\n",
       "gravity                    gravity                gravity                  26780\n",
       "india mark ii              india mark ii          handpump                  2400\n",
       "india mark iii             india mark iii         handpump                    98\n",
       "ksb                        submersible            submersible               1415\n",
       "mono                       mono                   motorpump                 2865\n",
       "nira/tanira                nira/tanira            handpump                  8154\n",
       "other                      other                  other                     6430\n",
       "other - mkulima/shinyanga  other handpump         handpump                     2\n",
       "other - play pump          other handpump         handpump                    85\n",
       "other - rope pump          rope pump              rope pump                  451\n",
       "other - swn 81             other handpump         handpump                   229\n",
       "submersible                submersible            submersible               4764\n",
       "swn 80                     swn 80                 handpump                  3670\n",
       "walimi                     other handpump         handpump                    48\n",
       "windmill                   wind-powered           wind-powered               117\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['extraction_type','extraction_type_group','extraction_type_class']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "management        management_group\n",
       "company           commercial            685\n",
       "other             other                 844\n",
       "other - school    other                  99\n",
       "parastatal        parastatal           1768\n",
       "private operator  commercial           1971\n",
       "trust             commercial             78\n",
       "unknown           unknown               561\n",
       "vwc               user-group          40507\n",
       "water authority   commercial            904\n",
       "water board       user-group           2933\n",
       "wua               user-group           2535\n",
       "wug               user-group           6515\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['management','management_group']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "payment                payment_type\n",
       "never pay              never pay       25348\n",
       "other                  other            1054\n",
       "pay annually           annually         3642\n",
       "pay monthly            monthly          8300\n",
       "pay per bucket         per bucket       8985\n",
       "pay when scheme fails  on failure       3914\n",
       "unknown                unknown          8157\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['payment','payment_type']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quantity      quantity_group\n",
       "dry           dry                6246\n",
       "enough        enough            33186\n",
       "insufficient  insufficient      15129\n",
       "seasonal      seasonal           4050\n",
       "unknown       unknown             789\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['quantity','quantity_group']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source                source_type           source_class\n",
       "dam                   dam                   surface           656\n",
       "hand dtw              borehole              groundwater       874\n",
       "lake                  river/lake            surface           765\n",
       "machine dbh           borehole              groundwater     11075\n",
       "other                 other                 unknown           212\n",
       "rainwater harvesting  rainwater harvesting  surface          2295\n",
       "river                 river/lake            surface          9612\n",
       "shallow well          shallow well          groundwater     16824\n",
       "spring                spring                groundwater     17021\n",
       "unknown               other                 unknown            66\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['source','source_type','source_class']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "waterpoint_type              waterpoint_type_group\n",
       "cattle trough                cattle trough              116\n",
       "communal standpipe           communal standpipe       28522\n",
       "communal standpipe multiple  communal standpipe        6103\n",
       "dam                          dam                          7\n",
       "hand pump                    hand pump                17488\n",
       "improved spring              improved spring            784\n",
       "other                        other                     6380\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['waterpoint_type','waterpoint_type_group']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above this can drop more but I didn't because I thought can use this to improve second submission besides using a different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>num_private</th>\n",
       "      <th>district_code</th>\n",
       "      <th>population</th>\n",
       "      <th>construction_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>5.940000e+04</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37115.131768</td>\n",
       "      <td>317.650385</td>\n",
       "      <td>668.297239</td>\n",
       "      <td>34.077427</td>\n",
       "      <td>-5.706033e+00</td>\n",
       "      <td>0.474141</td>\n",
       "      <td>5.629747</td>\n",
       "      <td>179.909983</td>\n",
       "      <td>1300.652475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21453.128371</td>\n",
       "      <td>2997.574558</td>\n",
       "      <td>693.116350</td>\n",
       "      <td>6.567432</td>\n",
       "      <td>2.946019e+00</td>\n",
       "      <td>12.236230</td>\n",
       "      <td>9.633649</td>\n",
       "      <td>471.482176</td>\n",
       "      <td>951.620547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.164944e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18519.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.090347</td>\n",
       "      <td>-8.540621e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37061.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>34.908743</td>\n",
       "      <td>-5.021597e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1986.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55656.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1319.250000</td>\n",
       "      <td>37.178387</td>\n",
       "      <td>-3.326156e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74247.000000</td>\n",
       "      <td>350000.000000</td>\n",
       "      <td>2770.000000</td>\n",
       "      <td>40.345193</td>\n",
       "      <td>-2.000000e-08</td>\n",
       "      <td>1776.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     amount_tsh    gps_height     longitude      latitude  \\\n",
       "count  59400.000000   59400.000000  59400.000000  59400.000000  5.940000e+04   \n",
       "mean   37115.131768     317.650385    668.297239     34.077427 -5.706033e+00   \n",
       "std    21453.128371    2997.574558    693.116350      6.567432  2.946019e+00   \n",
       "min        0.000000       0.000000    -90.000000      0.000000 -1.164944e+01   \n",
       "25%    18519.750000       0.000000      0.000000     33.090347 -8.540621e+00   \n",
       "50%    37061.500000       0.000000    369.000000     34.908743 -5.021597e+00   \n",
       "75%    55656.500000      20.000000   1319.250000     37.178387 -3.326156e+00   \n",
       "max    74247.000000  350000.000000   2770.000000     40.345193 -2.000000e-08   \n",
       "\n",
       "        num_private  district_code    population  construction_year  \n",
       "count  59400.000000   59400.000000  59400.000000       59400.000000  \n",
       "mean       0.474141       5.629747    179.909983        1300.652475  \n",
       "std       12.236230       9.633649    471.482176         951.620547  \n",
       "min        0.000000       0.000000      0.000000           0.000000  \n",
       "25%        0.000000       2.000000      0.000000           0.000000  \n",
       "50%        0.000000       3.000000     25.000000        1986.000000  \n",
       "75%        0.000000       5.000000    215.000000        2004.000000  \n",
       "max     1776.000000      80.000000  30500.000000        2013.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `num_private` as it does not seem to be meaningful - mostly zeros at 25%, 50% and 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code', 'num_private']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('num_private')\n",
    "\n",
    "df.drop('num_private',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null values in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh                   0\n",
       "date_recorded                0\n",
       "funder                    3635\n",
       "gps_height                   0\n",
       "installer                 3655\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "basin                        0\n",
       "subvillage                 371\n",
       "region                       0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population                   0\n",
       "public_meeting            3334\n",
       "recorded_by                  0\n",
       "scheme_management         3877\n",
       "scheme_name              28166\n",
       "permit                    3056\n",
       "construction_year            0\n",
       "extraction_type              0\n",
       "extraction_type_group        0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "management_group             0\n",
       "payment                      0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quality_group                0\n",
       "quantity                     0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "source_type                  0\n",
       "source_class                 0\n",
       "waterpoint_type              0\n",
       "waterpoint_type_group        0\n",
       "status_group                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### funder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Government Of Tanzania    9084\n",
       "Danida                    3114\n",
       "Hesawa                    2202\n",
       "Rwssp                     1374\n",
       "World Bank                1349\n",
       "                          ... \n",
       "Orphanage                    1\n",
       "Treedap                      1\n",
       "Natherland                   1\n",
       "Ester Ndege                  1\n",
       "Mitema                       1\n",
       "Name: funder, Length: 1897, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.funder.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep top 5 funders and set the rest to other, including missing values. Then, check the difference between the funders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "funder  status_group           \n",
       "bank    functional                   545\n",
       "        functional needs repair       97\n",
       "        non functional               707\n",
       "danida  functional                  1713\n",
       "        functional needs repair      159\n",
       "        non functional              1242\n",
       "gov     functional                  3720\n",
       "        functional needs repair      701\n",
       "        non functional              4663\n",
       "hesawa  functional                   936\n",
       "        functional needs repair      232\n",
       "        non functional              1034\n",
       "other   functional                 24540\n",
       "        functional needs repair     3019\n",
       "        non functional             14718\n",
       "rwssp   functional                   805\n",
       "        functional needs repair      109\n",
       "        non functional               460\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_funder(row):\n",
    "    if row['funder']=='Government Of Tanzania':\n",
    "        return 'gov'\n",
    "    elif row['funder']=='Danida':\n",
    "        return 'danida'\n",
    "    elif row['funder']=='Hesawa':\n",
    "        return 'hesawa'\n",
    "    elif row['funder']=='Rwssp':\n",
    "        return 'rwssp'\n",
    "    elif row['funder']=='World Bank':\n",
    "        return 'bank'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "df['funder'] = df.apply(lambda row: update_funder(row), axis=1)\n",
    "\n",
    "df.groupby(['funder','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the percentage of functional waterpoints by each funder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functional bank waterpoints =  40.4 %\n",
      "functional danida waterpoints =  55.01 %\n",
      "functional gov waterpoints =  40.951 %\n",
      "functional hesawa waterpoints =  42.507 %\n",
      "functional rwssp waterpoints =  58.588 %\n",
      "functional other waterpoints =  58.046 %\n"
     ]
    }
   ],
   "source": [
    "functional_fund_bank = (len(df[(df['status_group'] == 'functional') & (df['funder']=='bank')]))/(len(df[df['funder']=='bank']))*100\n",
    "functional_fund_danida = (len(df[(df['status_group'] == 'functional') & (df['funder']=='danida')]))/(len(df[df['funder']=='danida']))*100\n",
    "functional_fund_gov = (len(df[(df['status_group'] == 'functional') & (df['funder']=='gov')]))/(len(df[df['funder']=='gov']))*100\n",
    "functional_fund_hesawa = (len(df[(df['status_group'] == 'functional') & (df['funder']=='hesawa')]))/(len(df[df['funder']=='hesawa']))*100\n",
    "functional_fund_rwssp = (len(df[(df['status_group'] == 'functional') & (df['funder']=='rwssp')]))/(len(df[df['funder']=='rwssp']))*100\n",
    "functional_fund_other = (len(df[(df['status_group'] == 'functional') & (df['funder']=='other')]))/(len(df[df['funder']=='other']))*100\n",
    "\n",
    "print('functional bank waterpoints = ', round(functional_fund_bank,3),'%')\n",
    "print('functional danida waterpoints = ', round(functional_fund_danida,3),'%')\n",
    "print('functional gov waterpoints = ', round(functional_fund_gov,3),'%')\n",
    "print('functional hesawa waterpoints = ', round(functional_fund_hesawa,3),'%')\n",
    "print('functional rwssp waterpoints = ', round(functional_fund_rwssp,3),'%')\n",
    "print('functional other waterpoints = ', round(functional_fund_other,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DWE            17402\n",
       "Government      1825\n",
       "RWE             1206\n",
       "Commu           1060\n",
       "DANIDA          1050\n",
       "               ...  \n",
       "JANDU              1\n",
       "NYAHALE            1\n",
       "Sakwidi            1\n",
       "KAWINGA            1\n",
       "BOMA SAVING        1\n",
       "Name: installer, Length: 2145, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.installer.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep top 5 installers and set the rest to other, including missing values. Then, check the difference between the installers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "installer  status_group           \n",
       "commu      functional                   724\n",
       "           functional needs repair       32\n",
       "           non functional               304\n",
       "danida     functional                   542\n",
       "           functional needs repair       83\n",
       "           non functional               425\n",
       "dwe        functional                  9433\n",
       "           functional needs repair     1622\n",
       "           non functional              6347\n",
       "gov        functional                   535\n",
       "           functional needs repair      256\n",
       "           non functional              1034\n",
       "other      functional                 20721\n",
       "           functional needs repair     2187\n",
       "           non functional             13949\n",
       "rwe        functional                   304\n",
       "           functional needs repair      137\n",
       "           non functional               765\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_installer(row):\n",
    "    if row['installer']=='DWE':\n",
    "        return 'dwe'\n",
    "    elif row['installer']=='Government':\n",
    "        return 'gov'\n",
    "    elif row['installer']=='RWE':\n",
    "        return 'rwe'\n",
    "    elif row['installer']=='Commu':\n",
    "        return 'commu'\n",
    "    elif row['installer']=='DANIDA':\n",
    "        return 'danida'\n",
    "    else:\n",
    "        return 'other'  \n",
    "\n",
    "df['installer'] = df.apply(lambda row: update_installer(row), axis=1)\n",
    "\n",
    "df.groupby(['installer','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the percentage of functional waterpoints by each installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functional commu waterpoints =  68.302 %\n",
      "functional danida waterpoints =  51.619 %\n",
      "functional dwe waterpoints =  54.206 %\n",
      "functional gov waterpoints =  29.315 %\n",
      "functional rwe waterpoints =  25.207 %\n",
      "functional other waterpoints =  56.22 %\n"
     ]
    }
   ],
   "source": [
    "functional_install_commu = (len(df[(df['status_group'] == 'functional') & (df['installer']=='commu')]))/(len(df[df['installer']=='commu']))*100\n",
    "functional_install_danida = (len(df[(df['status_group'] == 'functional') & (df['installer']=='danida')]))/(len(df[df['installer']=='danida']))*100\n",
    "functional_install_dwe = (len(df[(df['status_group'] == 'functional') & (df['installer']=='dwe')]))/(len(df[df['installer']=='dwe']))*100\n",
    "functional_install_gov = (len(df[(df['status_group'] == 'functional') & (df['installer']=='gov')]))/(len(df[df['installer']=='gov']))*100\n",
    "functional_install_rwe = (len(df[(df['status_group'] == 'functional') & (df['installer']=='rwe')]))/(len(df[df['installer']=='rwe']))*100\n",
    "functional_install_other = (len(df[(df['status_group'] == 'functional') & (df['installer']=='other')]))/(len(df[df['installer']=='other']))*100\n",
    "\n",
    "print('functional commu waterpoints = ', round(functional_install_commu,3),'%')\n",
    "print('functional danida waterpoints = ', round(functional_install_danida,3),'%')\n",
    "print('functional dwe waterpoints = ', round(functional_install_dwe,3),'%')\n",
    "print('functional gov waterpoints = ', round(functional_install_gov,3),'%')\n",
    "print('functional rwe waterpoints = ', round(functional_install_rwe,3),'%')\n",
    "print('functional other waterpoints = ', round(functional_install_other,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are some differences between the functional waterpoints funded and installed by the same organisations - gov/danida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### subvillage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Madukani        508\n",
       "Shuleni         506\n",
       "Majengo         502\n",
       "Kati            373\n",
       "Mtakuja         262\n",
       "               ... \n",
       "Mapatano          1\n",
       "Mijohoroni        1\n",
       "Kilangalanga      1\n",
       "Galangala         1\n",
       "Sarakwa           1\n",
       "Name: subvillage, Length: 19287, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.subvillage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 19287 unique <code>subvillage</code>, of which the largest group is only 508. It is unlikely to be a meaningful feature, and will thus be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code', 'num_private', 'subvillage']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('subvillage')\n",
    "\n",
    "df.drop('subvillage',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### public_meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     51011\n",
       "False     5055\n",
       "Name: public_meeting, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.public_meeting.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "public_meeting  status_group           \n",
       "False           functional                  2173\n",
       "                functional needs repair      442\n",
       "                non functional              2440\n",
       "True            functional                 28408\n",
       "                functional needs repair     3719\n",
       "                non functional             18884\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['public_meeting','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `public_meeting` to binary predictor and impute with median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "public_meeting  status_group           \n",
       "0.0             functional                  2173\n",
       "                functional needs repair      442\n",
       "                non functional              2440\n",
       "1.0             functional                 30086\n",
       "                functional needs repair     3875\n",
       "                non functional             20384\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_public_meeting(row):\n",
    "    if row['public_meeting']==True:\n",
    "        return 1\n",
    "    elif row['public_meeting']==False:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df['public_meeting'] = df.apply(lambda row: convert_public_meeting(row), axis=1)\n",
    "df['public_meeting'].fillna(df['public_meeting'].median(),inplace=True)\n",
    "df.groupby(['public_meeting','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### scheme_management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VWC                 36793\n",
       "WUG                  5206\n",
       "Water authority      3153\n",
       "WUA                  2883\n",
       "Water Board          2748\n",
       "Parastatal           1680\n",
       "Private operator     1063\n",
       "Company              1061\n",
       "Other                 766\n",
       "SWC                    97\n",
       "Trust                  72\n",
       "None                    1\n",
       "Name: scheme_management, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.scheme_management.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep top 5 scheme management and set the rest to other, including missing values. Then, check the difference between the scheme management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scheme_management  status_group           \n",
       "other              functional                  4627\n",
       "                   functional needs repair      513\n",
       "                   non functional              3477\n",
       "vwc                functional                 18960\n",
       "                   functional needs repair     2334\n",
       "                   non functional             15499\n",
       "water_auth         functional                  1618\n",
       "                   functional needs repair      448\n",
       "                   non functional              1087\n",
       "water_bd           functional                  2053\n",
       "                   functional needs repair      111\n",
       "                   non functional               584\n",
       "wua                functional                  1995\n",
       "                   functional needs repair      239\n",
       "                   non functional               649\n",
       "wug                functional                  3006\n",
       "                   functional needs repair      672\n",
       "                   non functional              1528\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_scheme_management(row):\n",
    "    if row['scheme_management']=='VWC':\n",
    "        return 'vwc'\n",
    "    elif row['scheme_management']=='WUG':\n",
    "        return 'wug'\n",
    "    elif row['scheme_management']=='Water authority':\n",
    "        return 'water_auth'\n",
    "    elif row['scheme_management']=='WUA':\n",
    "        return 'wua'\n",
    "    elif row['scheme_management']=='Water Board':\n",
    "        return 'water_bd'\n",
    "    else:\n",
    "        return 'other'  \n",
    "\n",
    "df['scheme_management'] = df.apply(lambda row: update_scheme_management(row), axis=1)\n",
    "\n",
    "df.groupby(['scheme_management','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the percentage of functional waterpoints by each scheme management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functional vwc waterpoints =  51.532 %\n",
      "functional water_auth waterpoints =  51.316 %\n",
      "functional water_bd waterpoints =  74.709 %\n",
      "functional wua waterpoints =  69.199 %\n",
      "functional wug waterpoints =  57.741 %\n",
      "functional other waterpoints =  53.696 %\n"
     ]
    }
   ],
   "source": [
    "functional_vwc = (len(df[(df['status_group'] == 'functional') & (df['scheme_management']=='vwc')]))/(len(df[df['scheme_management']=='vwc']))*100\n",
    "functional_water_auth = (len(df[(df['status_group'] == 'functional') & (df['scheme_management']=='water_auth')]))/(len(df[df['scheme_management']=='water_auth']))*100\n",
    "functional_water_bd = (len(df[(df['status_group'] == 'functional') & (df['scheme_management']=='water_bd')]))/(len(df[df['scheme_management']=='water_bd']))*100\n",
    "functional_wua = (len(df[(df['status_group'] == 'functional') & (df['scheme_management']=='wua')]))/(len(df[df['scheme_management']=='wua']))*100\n",
    "functional_wug = (len(df[(df['status_group'] == 'functional') & (df['scheme_management']=='wug')]))/(len(df[df['scheme_management']=='wug']))*100\n",
    "functional_other = (len(df[(df['status_group'] == 'functional') & (df['scheme_management']=='other')]))/(len(df[df['scheme_management']=='other']))*100\n",
    "\n",
    "print('functional vwc waterpoints = ', round(functional_vwc,3),'%')\n",
    "print('functional water_auth waterpoints = ', round(functional_water_auth,3),'%')\n",
    "print('functional water_bd waterpoints = ', round(functional_water_bd,3),'%')\n",
    "print('functional wua waterpoints = ', round(functional_wua,3),'%')\n",
    "print('functional wug waterpoints = ', round(functional_wug,3),'%')\n",
    "print('functional other waterpoints = ', round(functional_other,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### scheme_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "K                        682\n",
       "None                     644\n",
       "Borehole                 546\n",
       "Chalinze wate            405\n",
       "M                        400\n",
       "                        ... \n",
       "Mahunguru                  1\n",
       "BRA                        1\n",
       "Miga                       1\n",
       "BL Siha Sec                1\n",
       "Kashangu water supply      1\n",
       "Name: scheme_name, Length: 2696, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.scheme_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2696 unique `scheme_name`, of which the largest group is only 682. Additionally, there are 28166 null values in this column. It is unlikely for this column to yield meaningful results and we will be dropping it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code', 'num_private', 'subvillage', 'scheme_name']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('scheme_name')\n",
    "\n",
    "df.drop('scheme_name',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### permit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     38852\n",
       "False    17492\n",
       "Name: permit, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.permit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permit  status_group           \n",
       "False   functional                  9045\n",
       "        functional needs repair     1320\n",
       "        non functional              7127\n",
       "True    functional                 21541\n",
       "        functional needs repair     2697\n",
       "        non functional             14614\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['permit','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `permit` to binary predictor and impute with median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permit  status_group           \n",
       "0.0     functional                  9045\n",
       "        functional needs repair     1320\n",
       "        non functional              7127\n",
       "1.0     functional                 23214\n",
       "        functional needs repair     2997\n",
       "        non functional             15697\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_permit(row):\n",
    "    if row['permit']==True:\n",
    "        return 1\n",
    "    elif row['permit']==False:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df['permit'] = df.apply(lambda row: convert_permit(row), axis=1)\n",
    "df['permit'].fillna(df['permit'].median(),inplace=True)\n",
    "df.groupby(['permit','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having removed all null, ensure that there is no other invalid data $-$ 0 $-$ that can be immediately obvious for relevant columns such as `population`, `gps_height`, `amount_tsh` and `construction_year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh               41639\n",
       "date_recorded                0\n",
       "funder                       0\n",
       "gps_height               20438\n",
       "installer                    0\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "basin                        0\n",
       "region                       0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population               21381\n",
       "public_meeting               0\n",
       "recorded_by                  0\n",
       "scheme_management            0\n",
       "permit                       0\n",
       "construction_year        20709\n",
       "extraction_type              0\n",
       "extraction_type_group        0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "management_group             0\n",
       "payment                      0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quality_group                0\n",
       "quantity                     0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "source_type                  0\n",
       "source_class                 0\n",
       "waterpoint_type              0\n",
       "waterpoint_type_group        0\n",
       "status_group                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gps_height'].replace(0, np.nan, inplace=True)\n",
    "df['population'].replace(0, np.nan, inplace=True)\n",
    "df['amount_tsh'].replace(0, np.nan, inplace=True)\n",
    "df['construction_year'].replace(0, np.nan, inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming `water_tsh`, `gps_height` and `population` are affected by `region_code` and `district_code`, impute missing values with mean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount_tsh'].fillna(df.groupby(['region', 'district_code'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "df['amount_tsh'].fillna(df.groupby(['region'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "df['amount_tsh'].fillna(df['amount_tsh'].mean(), inplace=True)\n",
    "df['gps_height'].fillna(df.groupby(['region', 'district_code'])['gps_height'].transform('mean'), inplace=True)\n",
    "df['gps_height'].fillna(df.groupby(['region'])['gps_height'].transform('mean'), inplace=True)\n",
    "df['gps_height'].fillna(df['gps_height'].mean(), inplace=True)\n",
    "df['population'].fillna(df.groupby(['region', 'district_code'])['population'].transform('mean'), inplace=True)\n",
    "df['population'].fillna(df.groupby(['region'])['population'].transform('mean'), inplace=True)\n",
    "df['population'].fillna(df['population'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`construction_year` can also be imputed with mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0\n",
       "amount_tsh               0\n",
       "date_recorded            0\n",
       "funder                   0\n",
       "gps_height               0\n",
       "installer                0\n",
       "longitude                0\n",
       "latitude                 0\n",
       "wpt_name                 0\n",
       "basin                    0\n",
       "region                   0\n",
       "district_code            0\n",
       "lga                      0\n",
       "ward                     0\n",
       "population               0\n",
       "public_meeting           0\n",
       "recorded_by              0\n",
       "scheme_management        0\n",
       "permit                   0\n",
       "construction_year        0\n",
       "extraction_type          0\n",
       "extraction_type_group    0\n",
       "extraction_type_class    0\n",
       "management               0\n",
       "management_group         0\n",
       "payment                  0\n",
       "payment_type             0\n",
       "water_quality            0\n",
       "quality_group            0\n",
       "quantity                 0\n",
       "quantity_group           0\n",
       "source                   0\n",
       "source_type              0\n",
       "source_class             0\n",
       "waterpoint_type          0\n",
       "waterpoint_type_group    0\n",
       "status_group             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['construction_year'].fillna(df['construction_year'].mean(),inplace=True)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `construction_year` and `date_recorded` into the number of years the waterpoint has been in operation for, and drop both features after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
    "df['operational_years'] = df.date_recorded.dt.year - df.construction_year\n",
    "\n",
    "df.drop('date_recorded', axis=1, inplace=True)\n",
    "df.drop('construction_year', axis=1, inplace=True)\n",
    "drop.append('date_recorded')\n",
    "drop.append('construction_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take the same steps for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Government Of Tanzania    2215\n",
       "Danida                     793\n",
       "Hesawa                     580\n",
       "World Bank                 352\n",
       "Kkkt                       336\n",
       "                          ... \n",
       "Parastatal                   1\n",
       "Solar Villa                  1\n",
       "Nazareth Church              1\n",
       "Heasawa                      1\n",
       "Leef Gold Mining             1\n",
       "Name: funder, Length: 980, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.funder.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_funder_test(row):\n",
    "    if row['funder']=='Government Of Tanzania':\n",
    "        return 'gov'\n",
    "    elif row['funder']=='Danida':\n",
    "        return 'danida'\n",
    "    elif row['funder']=='Hesawa':\n",
    "        return 'hesawa'\n",
    "    elif row['funder']=='World Bank':\n",
    "        return 'bank'\n",
    "    elif row['funder']=='Kkkt':\n",
    "        return 'kkkt'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "test_df['funder'] = test_df.apply(lambda row: update_funder(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DWE            4349\n",
       "Government      457\n",
       "RWE             292\n",
       "Commu           287\n",
       "DANIDA          255\n",
       "               ... \n",
       "COICA             1\n",
       "Rombo Dalta       1\n",
       "DDSA              1\n",
       "CIPRO             1\n",
       "Kalugendo         1\n",
       "Name: installer, Length: 1091, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.installer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_installer_test(row):\n",
    "    if row['installer']=='DWE':\n",
    "        return 'dwe'\n",
    "    elif row['installer']=='Government':\n",
    "        return 'gov'\n",
    "    elif row['installer']=='RWE':\n",
    "        return 'rwe'\n",
    "    elif row['installer']=='Commu':\n",
    "        return 'commu'\n",
    "    elif row['installer']=='DANIDA':\n",
    "        return 'danida'\n",
    "    else:\n",
    "        return 'other'  \n",
    "\n",
    "test_df['installer'] = test_df.apply(lambda row: update_installer(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['public_meeting'] = test_df.apply(lambda row: convert_public_meeting(row), axis=1)\n",
    "test_df['public_meeting'].fillna(test_df['public_meeting'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VWC                 9124\n",
       "WUG                 1290\n",
       "Water authority      822\n",
       "Water Board          714\n",
       "WUA                  668\n",
       "Parastatal           444\n",
       "Company              280\n",
       "Private operator     263\n",
       "Other                230\n",
       "SWC                   26\n",
       "Trust                 20\n",
       "Name: scheme_management, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.scheme_management.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scheme_management_test(row):\n",
    "    if row['scheme_management']=='VWC':\n",
    "        return 'vwc'\n",
    "    elif row['scheme_management']=='WUG':\n",
    "        return 'wug'\n",
    "    elif row['scheme_management']=='Water authority':\n",
    "        return 'water_auth'\n",
    "    elif row['scheme_management']=='Water Board':\n",
    "        return 'water_bd'\n",
    "    elif row['scheme_management']=='WUA':\n",
    "        return 'wua'\n",
    "    else:\n",
    "        return 'other'  \n",
    "\n",
    "test_df['scheme_management'] = test_df.apply(lambda row: update_scheme_management(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['permit'] = test_df.apply(lambda row: convert_permit(row), axis=1)\n",
    "test_df['permit'].fillna(test_df['permit'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh               10410\n",
       "date_recorded                0\n",
       "funder                       0\n",
       "gps_height                5211\n",
       "installer                    0\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "num_private                  0\n",
       "basin                        0\n",
       "subvillage                  99\n",
       "region                       0\n",
       "region_code                  0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population                5453\n",
       "public_meeting               0\n",
       "recorded_by                  0\n",
       "scheme_management            0\n",
       "scheme_name               7092\n",
       "permit                       0\n",
       "construction_year         5260\n",
       "extraction_type              0\n",
       "extraction_type_group        0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "management_group             0\n",
       "payment                      0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quality_group                0\n",
       "quantity                     0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "source_type                  0\n",
       "source_class                 0\n",
       "waterpoint_type              0\n",
       "waterpoint_type_group        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['gps_height'].replace(0, np.nan, inplace=True)\n",
    "test_df['population'].replace(0, np.nan, inplace=True)\n",
    "test_df['amount_tsh'].replace(0, np.nan, inplace=True)\n",
    "test_df['construction_year'].replace(0, np.nan, inplace=True)\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['amount_tsh'].fillna(test_df.groupby(['region', 'district_code'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "test_df['amount_tsh'].fillna(test_df.groupby(['region'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "test_df['amount_tsh'].fillna(test_df['amount_tsh'].mean(), inplace=True)\n",
    "test_df['gps_height'].fillna(test_df.groupby(['region', 'district_code'])['gps_height'].transform('mean'), inplace=True)\n",
    "test_df['gps_height'].fillna(test_df.groupby(['region'])['gps_height'].transform('mean'), inplace=True)\n",
    "test_df['gps_height'].fillna(test_df['gps_height'].mean(), inplace=True)\n",
    "test_df['population'].fillna(test_df.groupby(['region', 'district_code'])['population'].transform('mean'), inplace=True)\n",
    "test_df['population'].fillna(test_df.groupby(['region'])['population'].transform('mean'), inplace=True)\n",
    "test_df['population'].fillna(test_df['population'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['construction_year'].fillna(test_df['construction_year'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['date_recorded'] = pd.to_datetime(test_df['date_recorded'])\n",
    "test_df['operational_years'] = test_df.date_recorded.dt.year - test_df.construction_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in drop:\n",
    "    test_df.drop(i, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building (First Submission) - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Re-initialise' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df\n",
    "y_train = df.pop('status_group')\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59400 entries, 0 to 59399\n",
      "Data columns (total 35 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     59400 non-null  int64  \n",
      " 1   amount_tsh             59400 non-null  float64\n",
      " 2   funder                 59400 non-null  object \n",
      " 3   gps_height             59400 non-null  float64\n",
      " 4   installer              59400 non-null  object \n",
      " 5   longitude              59400 non-null  float64\n",
      " 6   latitude               59400 non-null  float64\n",
      " 7   wpt_name               59400 non-null  object \n",
      " 8   basin                  59400 non-null  object \n",
      " 9   region                 59400 non-null  object \n",
      " 10  district_code          59400 non-null  int64  \n",
      " 11  lga                    59400 non-null  object \n",
      " 12  ward                   59400 non-null  object \n",
      " 13  population             59400 non-null  float64\n",
      " 14  public_meeting         59400 non-null  float64\n",
      " 15  recorded_by            59400 non-null  object \n",
      " 16  scheme_management      59400 non-null  object \n",
      " 17  permit                 59400 non-null  float64\n",
      " 18  extraction_type        59400 non-null  object \n",
      " 19  extraction_type_group  59400 non-null  object \n",
      " 20  extraction_type_class  59400 non-null  object \n",
      " 21  management             59400 non-null  object \n",
      " 22  management_group       59400 non-null  object \n",
      " 23  payment                59400 non-null  object \n",
      " 24  payment_type           59400 non-null  object \n",
      " 25  water_quality          59400 non-null  object \n",
      " 26  quality_group          59400 non-null  object \n",
      " 27  quantity               59400 non-null  object \n",
      " 28  quantity_group         59400 non-null  object \n",
      " 29  source                 59400 non-null  object \n",
      " 30  source_type            59400 non-null  object \n",
      " 31  source_class           59400 non-null  object \n",
      " 32  waterpoint_type        59400 non-null  object \n",
      " 33  waterpoint_type_group  59400 non-null  object \n",
      " 34  operational_years      59400 non-null  float64\n",
      "dtypes: float64(8), int64(2), object(25)\n",
      "memory usage: 16.3+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode labels into categorical variables\n",
    "https://stackoverflow.com/questions/40336502/want-to-know-the-diff-among-pd-factorize-pd-get-dummies-sklearn-preprocessing/40338956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['funder'] = pd.fit_transform(X_train['funder'])\n",
    "X_train['installer'] = pd.fit_transform(X_train['installer'])\n",
    "X_train['wpt_name'] = pd.fit_transform(X_train['wpt_name'])\n",
    "X_train['basin'] = pd.fit_transform(X_train['basin'])\n",
    "X_train['region'] = pd.fit_transform(X_train['region'])\n",
    "X_train['lga'] = pd.fit_transform(X_train['lga'])\n",
    "X_train['ward'] = pd.fit_transform(X_train['ward'])\n",
    "X_train['recorded_by'] = pd.fit_transform(X_train['recorded_by'])\n",
    "X_train['scheme_management'] = pd.fit_transform(X_train['scheme_management'])\n",
    "X_train['extraction_type'] = pd.fit_transform(X_train['extraction_type'])\n",
    "X_train['extraction_type_group'] = pd.fit_transform(X_train['extraction_type_group'])\n",
    "X_train['extraction_type_class'] = pd.fit_transform(X_train['extraction_type_class'])\n",
    "X_train['management'] = pd.fit_transform(X_train['management'])\n",
    "X_train['management_group'] = pd.fit_transform(X_train['management_group'])\n",
    "X_train['payment'] = pd.fit_transform(X_train['payment'])\n",
    "X_train['payment_type'] = pd.fit_transform(X_train['payment_type'])\n",
    "X_train['water_quality'] = pd.fit_transform(X_train['water_quality'])\n",
    "X_train['quality_group'] = pd.fit_transform(X_train['quality_group'])\n",
    "X_train['quantity'] = pd.fit_transform(X_train['quantity'])\n",
    "X_train['quantity_group'] = pd.fit_transform(X_train['quantity_group'])\n",
    "X_train['source'] = pd.fit_transform(X_train['source'])\n",
    "X_train['source_type'] = pd.fit_transform(X_train['source_type'])\n",
    "X_train['source_class'] = pd.fit_transform(X_train['source_class'])\n",
    "X_train['waterpoint_type'] = pd.fit_transform(X_train['waterpoint_type'])\n",
    "X_train['waterpoint_type_group'] = pd.fit_transform(X_train['waterpoint_type_group'])\n",
    "# X_train['district_code'] = pd.fit_transform(X_train['district_code'])\n",
    "# X_train['operational_years'] = pd.fit_transform(X_train['operational_years'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['funder'] = pd.fit_transform(X_test['funder'])\n",
    "X_test['installer'] = pd.fit_transform(X_test['installer'])\n",
    "X_test['wpt_name'] = pd.fit_transform(X_test['wpt_name'])\n",
    "X_test['basin'] = pd.fit_transform(X_test['basin'])\n",
    "X_test['region'] = pd.fit_transform(X_test['region'])\n",
    "X_test['lga'] = pd.fit_transform(X_test['lga'])\n",
    "X_test['ward'] = pd.fit_transform(X_test['ward'])\n",
    "X_test['recorded_by'] = pd.fit_transform(X_test['recorded_by'])\n",
    "X_test['scheme_management'] = pd.fit_transform(X_test['scheme_management'])\n",
    "X_test['extraction_type'] = pd.fit_transform(X_test['extraction_type'])\n",
    "X_test['extraction_type_group'] = pd.fit_transform(X_test['extraction_type_group'])\n",
    "X_test['extraction_type_class'] = pd.fit_transform(X_test['extraction_type_class'])\n",
    "X_test['management'] = pd.fit_transform(X_test['management'])\n",
    "X_test['management_group'] = pd.fit_transform(X_test['management_group'])\n",
    "X_test['payment'] = pd.fit_transform(X_test['payment'])\n",
    "X_test['payment_type'] = pd.fit_transform(X_test['payment_type'])\n",
    "X_test['water_quality'] = pd.fit_transform(X_test['water_quality'])\n",
    "X_test['quality_group'] = pd.fit_transform(X_test['quality_group'])\n",
    "X_test['quantity'] = pd.fit_transform(X_test['quantity'])\n",
    "X_test['quantity_group'] = pd.fit_transform(X_test['quantity_group'])\n",
    "X_test['source'] = pd.fit_transform(X_test['source'])\n",
    "X_test['source_type'] = pd.fit_transform(X_test['source_type'])\n",
    "X_test['source_class'] = pd.fit_transform(X_test['source_class'])\n",
    "X_test['waterpoint_type'] = pd.fit_transform(X_test['waterpoint_type'])\n",
    "X_test['waterpoint_type_group'] = pd.fit_transform(X_test['waterpoint_type_group'])\n",
    "# X_test['district_code'] = pd.fit_transform(X_test['district_code'])\n",
    "# X_test['operational_years'] = pd.fit_transform(X_test['operational_years'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59400 entries, 0 to 59399\n",
      "Data columns (total 35 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     59400 non-null  int64  \n",
      " 1   amount_tsh             59400 non-null  float64\n",
      " 2   funder                 59400 non-null  int64  \n",
      " 3   gps_height             59400 non-null  float64\n",
      " 4   installer              59400 non-null  object \n",
      " 5   longitude              59400 non-null  float64\n",
      " 6   latitude               59400 non-null  float64\n",
      " 7   wpt_name               59400 non-null  int64  \n",
      " 8   basin                  59400 non-null  int64  \n",
      " 9   region                 59400 non-null  int64  \n",
      " 10  district_code          59400 non-null  int64  \n",
      " 11  lga                    59400 non-null  int64  \n",
      " 12  ward                   59400 non-null  int64  \n",
      " 13  population             59400 non-null  float64\n",
      " 14  public_meeting         59400 non-null  float64\n",
      " 15  recorded_by            59400 non-null  int64  \n",
      " 16  scheme_management      59400 non-null  int64  \n",
      " 17  permit                 59400 non-null  float64\n",
      " 18  extraction_type        59400 non-null  int64  \n",
      " 19  extraction_type_group  59400 non-null  int64  \n",
      " 20  extraction_type_class  59400 non-null  int64  \n",
      " 21  management             59400 non-null  int64  \n",
      " 22  management_group       59400 non-null  int64  \n",
      " 23  payment                59400 non-null  int64  \n",
      " 24  payment_type           59400 non-null  int64  \n",
      " 25  water_quality          59400 non-null  int64  \n",
      " 26  quality_group          59400 non-null  int64  \n",
      " 27  quantity               59400 non-null  int64  \n",
      " 28  quantity_group         59400 non-null  int64  \n",
      " 29  source                 59400 non-null  int64  \n",
      " 30  source_type            59400 non-null  int64  \n",
      " 31  source_class           59400 non-null  int64  \n",
      " 32  waterpoint_type        59400 non-null  int64  \n",
      " 33  waterpoint_type_group  59400 non-null  int64  \n",
      " 34  operational_years      59400 non-null  float64\n",
      "dtypes: float64(8), int64(26), object(1)\n",
      "memory usage: 16.3+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='gini',\n",
    "                                max_features='auto',\n",
    "                                min_samples_split=6,\n",
    "                                oob_score=True,\n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "param_grid = {\"n_estimators\" : [500, 750, 1000]}\n",
    "\n",
    "gs = GridSearchCV(estimator=rf,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=2,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8005892255892256\n",
      "{'n_estimators': 500}\n",
      "{'mean_fit_time': array([36.0084306 , 40.88002217, 44.30052972]), 'std_fit_time': array([0.0413903 , 0.01446164, 0.04238534]), 'mean_score_time': array([2.20711505, 1.39477813, 1.76477683]), 'std_score_time': array([0.057845  , 0.01097023, 0.01944816]), 'param_n_estimators': masked_array(data=[500, 750, 1000],\n",
      "             mask=[False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_estimators': 500}, {'n_estimators': 750}, {'n_estimators': 1000}], 'split0_test_score': array([0.80178451, 0.80218855, 0.80205387]), 'split1_test_score': array([0.79939394, 0.79841751, 0.79838384]), 'mean_test_score': array([0.80058923, 0.80030303, 0.80021886]), 'std_test_score': array([0.00119529, 0.00188552, 0.00183502]), 'rank_test_score': array([1, 2, 3])}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "print(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8161\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(criterion='gini',\n",
    "                                min_samples_split=6,\n",
    "                                n_estimators=1000,\n",
    "                                max_features='auto',\n",
    "                                oob_score=True,\n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "                            \n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "print(\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0.082319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.079999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>quantity</td>\n",
       "      <td>0.071692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>quantity_group</td>\n",
       "      <td>0.070118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>operational_years</td>\n",
       "      <td>0.051417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>0.050288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wpt_name</td>\n",
       "      <td>0.049774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gps_height</td>\n",
       "      <td>0.047233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ward</td>\n",
       "      <td>0.044173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>population</td>\n",
       "      <td>0.034768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             variable  importance\n",
       "5           longitude    0.082319\n",
       "6            latitude    0.079999\n",
       "27           quantity    0.071692\n",
       "28     quantity_group    0.070118\n",
       "34  operational_years    0.051417\n",
       "0                  id    0.050288\n",
       "7            wpt_name    0.049774\n",
       "3          gps_height    0.047233\n",
       "12               ward    0.044173\n",
       "13         population    0.034768"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.columns, columns = ['variable']), \n",
    "           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-e940275c93ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "a=X_test['id']\n",
    "X_test.drop(['id'],axis=1, inplace=True)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(y_pred)\n",
    "y_pred['id']=a\n",
    "y_pred.columns=['status_group','id']\n",
    "y_pred=y_pred[['id','status_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).to_csv(\"submission_rf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps taken to improve accuracy (Second Submission) - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfc = RandomForestClassifier(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(objective = 'multi:softmax', booster = 'gbtree', nrounds = 'min.error.idx', \n",
    "                      num_class = 4, maximize = False, eval_metric = 'merror', eta = .2,\n",
    "                      max_depth = 14, colsample_bytree = .4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:15:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { maximize, nrounds } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:16:06] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { maximize, nrounds } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[05:16:19] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { maximize, nrounds } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.80772727, 0.80808081, 0.75883838])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:17:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { maximize, nrounds } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.4, eta=0.2,\n",
       "              eval_metric='merror', gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.200000003,\n",
       "              max_delta_step=0, max_depth=14, maximize=False,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, nrounds='min.error.idx', num_class=4,\n",
       "              num_parallel_tree=1, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', ...)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['id', 'amount_tsh', 'funder', 'gps_height', 'installer', 'longitude', 'latitude', 'wpt_name', 'basin', 'region', 'district_code', 'lga', 'ward', 'population', 'public_meeting', 'recorded_by', 'scheme_management', 'permit', 'extraction_type', 'extraction_type_group', 'extraction_type_class', 'management', 'management_group', 'payment', 'payment_type', 'water_quality', 'quality_group', 'quantity', 'quantity_group', 'source', 'source_type', 'source_class', 'waterpoint_type', 'waterpoint_type_group', 'operational_years'] ['amount_tsh', 'funder', 'gps_height', 'installer', 'longitude', 'latitude', 'wpt_name', 'basin', 'region', 'district_code', 'lga', 'ward', 'population', 'public_meeting', 'recorded_by', 'scheme_management', 'permit', 'extraction_type', 'extraction_type_group', 'extraction_type_class', 'management', 'management_group', 'payment', 'payment_type', 'water_quality', 'quality_group', 'quantity', 'quantity_group', 'source', 'source_type', 'source_class', 'waterpoint_type', 'waterpoint_type_group', 'operational_years']\nexpected id in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-8d4cb985403d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# a=X_test['id']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# X_test.drop(['id'],axis=1, inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mntree_limit\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mntree_limit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"best_ntree_limit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m         class_probs = self.get_booster().predict(\n\u001b[0m\u001b[0;32m    895\u001b[0m             \u001b[0mtest_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m             \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training)\u001b[0m\n\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1364\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1933\u001b[0m                             ', '.join(str(s) for s in my_missing))\n\u001b[0;32m   1934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1935\u001b[1;33m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0m\u001b[0;32m   1936\u001b[0m                                             data.feature_names))\n\u001b[0;32m   1937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['id', 'amount_tsh', 'funder', 'gps_height', 'installer', 'longitude', 'latitude', 'wpt_name', 'basin', 'region', 'district_code', 'lga', 'ward', 'population', 'public_meeting', 'recorded_by', 'scheme_management', 'permit', 'extraction_type', 'extraction_type_group', 'extraction_type_class', 'management', 'management_group', 'payment', 'payment_type', 'water_quality', 'quality_group', 'quantity', 'quantity_group', 'source', 'source_type', 'source_class', 'waterpoint_type', 'waterpoint_type_group', 'operational_years'] ['amount_tsh', 'funder', 'gps_height', 'installer', 'longitude', 'latitude', 'wpt_name', 'basin', 'region', 'district_code', 'lga', 'ward', 'population', 'public_meeting', 'recorded_by', 'scheme_management', 'permit', 'extraction_type', 'extraction_type_group', 'extraction_type_class', 'management', 'management_group', 'payment', 'payment_type', 'water_quality', 'quality_group', 'quantity', 'quantity_group', 'source', 'source_type', 'source_class', 'waterpoint_type', 'waterpoint_type_group', 'operational_years']\nexpected id in input data"
     ]
    }
   ],
   "source": [
    "# a=X_test['id']\n",
    "# X_test.drop(['id'],axis=1, inplace=True)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(y_pred)\n",
    "y_pred['id']=a\n",
    "y_pred.columns=['status_group','id']\n",
    "y_pred=y_pred[['id','status_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).to_csv(\"submission_xg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, X_val, y_train, y_val, test):\n",
    "    if __name__ == '__main__':\n",
    "    \n",
    "        param_grid = {'learning_rate': [0.075, 0.7],\n",
    "                      'max_depth': [13, 14],\n",
    "                      'min_samples_leaf': [15, 16],\n",
    "                      'max_features': [1.0],\n",
    "                      'n_estimators': [100, 200]}                      \n",
    "\n",
    "        estimator = GridSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                                 param_grid=param_grid,\n",
    "                                 n_jobs=-1)\n",
    "\n",
    "        estimator.fit(X_train, y_train)\n",
    "\n",
    "        best_params = estimator.best_params_\n",
    "\n",
    "        print (best_params)\n",
    "                                 \n",
    "        validation_accuracy = estimator.score(X_val, y_val)\n",
    "        print('Validation accuracy: ', validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-e50df249013e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-87-b4e602aea69c>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(X_train, X_val, y_train, y_val, test)\u001b[0m\n\u001b[0;32m     12\u001b[0m                                  n_jobs=-1)\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model(X_train, X_val, y_train, y_val, X_test)\n",
    "# Took too long so I interrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_for_submission(features, target, test):\n",
    "    if __name__ == '__main__':\n",
    "\n",
    "         best_params = {'learning_rate': [0.075],\n",
    "                        'max_depth': [14],\n",
    "                        'min_samples_leaf': [16],\n",
    "                        'max_features': [1.0],\n",
    "                        'n_estimators': [100]}                      \n",
    "\n",
    "         estimator = GridSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                                 param_grid=best_params,\n",
    "                                 n_jobs=-1)\n",
    "\n",
    "         estimator.fit(features, target)     \n",
    "\n",
    "         predictions = estimator.predict(test)\n",
    "\n",
    "         data = {'id': a, 'status_group': predictions}\n",
    "\n",
    "         submit = pd.DataFrame(data=data)\n",
    "\n",
    "         vals_to_replace = {2:'functional', 1:'functional needs repair',\n",
    "                           0:'non functional'}\n",
    "\n",
    "         submit.status_group = submit.status_group.replace(vals_to_replace)        \n",
    "\n",
    "         submit=submit[['id','status_group']]\n",
    "         \n",
    "         pd.DataFrame(submit).to_csv(\"submission_xg.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model for submission.\n",
    "\n",
    "model_for_submission(features, target, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN with AX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
