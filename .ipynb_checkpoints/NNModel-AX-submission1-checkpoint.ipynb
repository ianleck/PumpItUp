{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "from numpy import vstack\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Import for Hyperparameter optimization using Ax\n",
    "from ax.plot.contour import plot_contour\n",
    "from ax.plot.trace import optimization_trace_single_method\n",
    "from ax import optimize\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgements\n",
    "\n",
    "\n",
    "Changing normal datatypes to tensors: \n",
    "https://towardsdatascience.com/deep-learning-on-dataframes-with-pytorch-66b21be54ef6\n",
    "https://stackoverflow.com/questions/44617871/how-to-convert-a-list-of-strings-into-a-tensor-in-pytorch\n",
    "\n",
    "pytorch nn model\n",
    "https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59400, 22)\n",
      "[2 0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#SG encoder is declared so that it can be used to inverse transform the predicted result\n",
    "sg_encoder = LabelEncoder()\n",
    "df = read_csv('clean.csv')\n",
    "\n",
    "# Label encode all predictors for the training data\n",
    "for col in df.columns:\n",
    "    if df.dtypes[col] == \"object\" and col != 'status_group':\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "    if col == 'status_group':\n",
    "        df['status_group'] = sg_encoder.fit_transform(df['status_group'])\n",
    "\n",
    "cols_at_end = ['status_group']\n",
    "df = df[[c for c in df if c not in cols_at_end] \n",
    "        + [c for c in cols_at_end if c in df]]\n",
    "\n",
    "#Store it into a temporary csv\n",
    "pd.DataFrame(df).to_csv(\"clean-kt.csv\")\n",
    "print(df.shape)\n",
    "\n",
    "print(df.status_group.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14850, 22)\n"
     ]
    }
   ],
   "source": [
    "df = read_csv('clean_test.csv')\n",
    "\n",
    "# Label encode all predictors\n",
    "for col in df.columns:\n",
    "    if df.dtypes[col] == \"object\" and col != 'status_group':\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "#Store it into a temporary csv\n",
    "print(df.shape)\n",
    "pd.DataFrame(df).to_csv(\"clean_test-kt.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        # load the csv file as a dataframe\n",
    "        df = read_csv(path)\n",
    "        \n",
    "        #Drop the unused columns. Unnamed: 0 is generated after saving the dataset.\n",
    "        df = df.drop('Unnamed: 0', axis=1)\n",
    "        df = df.drop('id', axis=1)\n",
    "        \n",
    "        #Assign x to all input values\n",
    "        self.X = df.values[:, :-1]\n",
    "        \n",
    "        #Assign y to all target values\n",
    "        self.y = df.values[:, -1]\n",
    "        \n",
    "        # ensure input data is floats\n",
    "        self.X = self.X.astype('float32')        \n",
    " \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    " \n",
    "    # get indexes for train and test rows\n",
    "    def get_splits(self, n_test=0.33):\n",
    "        # determine sizes\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        # calculate the split\n",
    "        return random_split(self, [train_size, test_size])\n",
    " \n",
    "# model definition\n",
    "class MLP(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        #Determine the input and output of each layer. Could also be passed as params for optimization\n",
    "        layers = [300,200,100]\n",
    "        total_layers = []\n",
    "        input_size = n_inputs\n",
    "        \n",
    "        for i in layers:\n",
    "            total_layers.append(nn.Linear(input_size, i))\n",
    "            total_layers.append(nn.ReLU(inplace=True))\n",
    "            total_layers.append(nn.BatchNorm1d(i))\n",
    "            total_layers.append(nn.Dropout(0.2))\n",
    "            input_size = i\n",
    "        \n",
    "        total_layers.append(nn.Linear(layers[-1], 3))\n",
    "\n",
    "        self.layers = nn.Sequential(*total_layers)\n",
    "\n",
    "\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        X = self.layers(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVTestDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        # load the csv file as a dataframe\n",
    "        df = read_csv(path)\n",
    "\n",
    "        # Drop unused columns\n",
    "        df = df.drop('id', axis=1)\n",
    "        df = df.drop('Unnamed: 0', axis=1)\n",
    "        if 'Unnamed: 0.1' in df.columns:\n",
    "            df = df.drop('Unnamed: 0.1', axis=1)\n",
    "        print('CSVTestDataset =', df.shape)\n",
    "        print(df.columns)\n",
    "        \n",
    "        #Assign x all input values\n",
    "        self.X = df.values[:, :]\n",
    "        # ensure input data is floats\n",
    "        self.X = self.X.astype('float32')\n",
    " \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx]]\n",
    " \n",
    "    # returns all inputs from test dataset\n",
    "    def get_test(self):\n",
    "        return self.X;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare the dataset\n",
    "def prepare_data(path):\n",
    "    # load the dataset\n",
    "    dataset = CSVDataset(path)\n",
    "    # calculate split\n",
    "    train, test = dataset.get_splits()\n",
    "    # prepare data loaders\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    return train_dl, test_dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = 'clean-kt.csv'\n",
    "train_dl, test_dl = prepare_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper train/fit function\n",
    "\n",
    "def train(model, parameterization, train_dl):\n",
    "    \n",
    "    #Gradient descent optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=parameterization[\"lr\"], momentum=parameterization[\"momentum\"])\n",
    "    \n",
    "    #Use cross entropy loss function\n",
    "    criterion = CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, targets) in enumerate(train_dl, 0):\n",
    "\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            \n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets.long())\n",
    "\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            \n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "    return model\n",
    "\n",
    "            \n",
    "## helper function to evaluate the accuracy for the tested model\n",
    "def evaluate(model, test_dl):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        _, predicted = torch.max(yhat, axis=1)\n",
    "\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "\n",
    "        # round to class values\n",
    "        yhat = yhat.round()\n",
    "\n",
    "        # store predictions\n",
    "        predictions.append(yhat)\n",
    "        \n",
    "        # transform 1d data and store eg. [0,1,2] => [[1,0,0] [0,1,0] [0,0,1]]\n",
    "        actual = actual.astype(int)\n",
    "        act = np.zeros((actual.size, actual.max()+1))\n",
    "        act[np.arange(actual.size),actual] = 1\n",
    "        actuals.append(act)\n",
    "\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "\n",
    "    # transform result to a numpy array of results eg. [0,1,2]\n",
    "    actuals = np.argmax(actuals, axis=1)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Determine accuracy\n",
    "    acc = np.sum(predictions == actuals) / actuals.shape[0]\n",
    "    print('Accuracy of model:' , np.sum(predictions == actuals)/ actuals.shape[0])\n",
    "\n",
    "    return acc\n",
    "\n",
    "# make a class prediction for one row of data\n",
    "def _predict(data, model):\n",
    "    predictions = list()\n",
    "    for i, inputs in enumerate(data):\n",
    "        yhat = model(inputs)\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        predictions.append(yhat)\n",
    "\n",
    "    # Get prediction numpy arr with 3 columns\n",
    "    prediction_list = vstack(predictions)\n",
    "    \n",
    "    # Get prediction results eg [0,1,2]\n",
    "    results = np.argmax(prediction_list, axis=1)\n",
    "    return results\n",
    "\n",
    "        \n",
    "## helper function train-evaluate to pass as the function to be optimized\n",
    "def train_evaluate(parameterization):\n",
    "    model = MLP(20)\n",
    "    model = train(model, parameterization, train_dl)\n",
    "    return evaluate(model, test_dl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7fd7cd01dac0>\n",
      "Accuracy of model: 0.5489745944291399\n"
     ]
    }
   ],
   "source": [
    "# The code below is to test if my model is working properly.\n",
    "model = MLP(20)\n",
    "print(model.parameters())\n",
    "trained_model = train(model, {\"lr\": 0.01, \"momentum\": 0.5}, train_dl)\n",
    "acc = evaluate(trained_model,test_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 22:01:47] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter lr. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 11-10 22:01:47] ax.service.utils.instantiation: Inferred value type of ParameterType.FLOAT for parameter momentum. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 11-10 22:01:47] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials]). Iterations after 5 will take longer to generate due to  model-fitting.\n",
      "[INFO 11-10 22:01:47] ax.service.managed_loop: Started full optimization with 15 steps.\n",
      "[INFO 11-10 22:01:47] ax.service.managed_loop: Running optimization trial 1...\n",
      "[INFO 11-10 22:02:09] ax.service.managed_loop: Running optimization trial 2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.5506070809101112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 22:02:35] ax.service.managed_loop: Running optimization trial 3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.5168860320375472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 22:02:56] ax.service.managed_loop: Running optimization trial 4...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.4463830221405979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 22:03:19] ax.service.managed_loop: Running optimization trial 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.5560146923783288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-10 22:03:39] ax.service.managed_loop: Running optimization trial 6...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.5542291602897663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kengthong/opt/anaconda3/lib/python3.8/site-packages/ax/modelbridge/torch.py:311: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "[INFO 11-10 22:04:00] ax.service.managed_loop: Running optimization trial 7...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.5535659626568717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kengthong/opt/anaconda3/lib/python3.8/site-packages/ax/modelbridge/torch.py:311: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "[INFO 11-10 22:04:20] ax.service.managed_loop: Running optimization trial 8...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.5099479644934191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kengthong/opt/anaconda3/lib/python3.8/site-packages/ax/modelbridge/torch.py:311: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "[INFO 11-10 22:04:43] ax.service.managed_loop: Running optimization trial 9...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.5447913478216508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kengthong/opt/anaconda3/lib/python3.8/site-packages/ax/modelbridge/torch.py:311: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "[INFO 11-10 22:05:08] ax.service.managed_loop: Running optimization trial 10...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.5404040404040404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kengthong/opt/anaconda3/lib/python3.8/site-packages/ax/modelbridge/torch.py:311: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "[INFO 11-10 22:05:33] ax.service.managed_loop: Running optimization trial 11...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.5585144373023161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kengthong/opt/anaconda3/lib/python3.8/site-packages/ax/modelbridge/torch.py:311: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "[INFO 11-10 22:05:54] ax.service.managed_loop: Running optimization trial 12...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.4406183042546679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kengthong/opt/anaconda3/lib/python3.8/site-packages/ax/modelbridge/torch.py:311: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "[INFO 11-10 22:06:17] ax.service.managed_loop: Running optimization trial 13...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.5543311906948271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kengthong/opt/anaconda3/lib/python3.8/site-packages/ax/modelbridge/torch.py:311: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "[INFO 11-10 22:06:38] ax.service.managed_loop: Running optimization trial 14...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.5349454137332925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kengthong/opt/anaconda3/lib/python3.8/site-packages/ax/modelbridge/torch.py:311: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "[INFO 11-10 22:07:00] ax.service.managed_loop: Running optimization trial 15...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.5417304356698296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kengthong/opt/anaconda3/lib/python3.8/site-packages/ax/modelbridge/torch.py:311: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.55331088664422\n"
     ]
    }
   ],
   "source": [
    "# The code below finds the best parameters to run the model based on the params given into the function. \n",
    "# Eventually, the best_parameters will be used to generate the model that will predict the y values for the test \n",
    "# dataset.\n",
    "best_parameters, values, experiment, model = optimize(\n",
    "    parameters=[\n",
    "        {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [1e-6, 0.4], \"log_scale\": True},\n",
    "        {\"name\": \"momentum\", \"type\": \"range\", \"bounds\": [0.0, 1.0]},\n",
    "    ],\n",
    "    evaluation_function=train_evaluate,\n",
    "    objective_name='accuracy',\n",
    "    total_trials=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.3999999999999993, 'momentum': 0.31699246915975815}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.5655545198696273},\n",
       " {'accuracy': {'accuracy': 2.9158741001568507e-10}})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7fd7ce88ea50>\n",
      "Accuracy of model: 0.555045403530252\n"
     ]
    }
   ],
   "source": [
    "# Use best params found to create model to determine the score.\n",
    "model = MLP(20)\n",
    "# test = train_evaluate(best_parameters)\n",
    "# print('test =', test)\n",
    "print(model.parameters())\n",
    "trained_model = train(model, best_parameters, train_dl)\n",
    "acc = evaluate(trained_model,test_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVTestDataset = (14850, 20)\n",
      "Index(['amount_tsh', 'funder', 'gps_height', 'installer', 'longitude',\n",
      "       'latitude', 'basin', 'region', 'district_code', 'lga', 'population',\n",
      "       'scheme_management', 'extraction_type', 'management', 'payment_type',\n",
      "       'water_quality', 'quantity', 'source', 'waterpoint_type',\n",
      "       'operational_year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get test dataset from the csv file.\n",
    "test_dataset = CSVTestDataset('clean_test-kt.csv')\n",
    "\n",
    "# Get self.x of CSVTestDataset\n",
    "test_df = test_dataset.get_test()\n",
    "\n",
    "# Pass test_df into dataloader\n",
    "test_df = DataLoader(test_df, batch_size=10, shuffle=False)\n",
    "\n",
    "# Predict results\n",
    "test_results = _predict(test_df, trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "['functional' 'functional' 'functional' ... 'functional' 'functional'\n",
      " 'functional']\n"
     ]
    }
   ],
   "source": [
    "#Check data prediction\n",
    "print(test_results)\n",
    "np.unique(test_results)\n",
    "results_numpy = sg_encoder.inverse_transform(test_results)\n",
    "print(results_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get dataframe\n",
    "test_data = pd.read_csv('clean_test-kt.csv')\n",
    "\n",
    "# Create dataframe with predictions and id\n",
    "submission_df = pd.DataFrame(results_numpy, columns=['status_group'])\n",
    "submission_df['id'] = test_data.id\n",
    "submission_df = submission_df[['id','status_group']]\n",
    "\n",
    "# Create new csv\n",
    "pd.DataFrame(submission_df).to_csv(\"nnmodel_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
