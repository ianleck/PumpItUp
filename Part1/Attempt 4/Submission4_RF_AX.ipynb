{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS4242 Group Assignment Part 1\n",
    "**November 11, 2020**\n",
    "\n",
    "## Changelog from submission 3 to submission 4\n",
    "- Filtered additional predictors to reduce redundancy\n",
    "- Reduced grouping of non-missing data to others as it might have introduced more discrepancies\n",
    "- Added AX to be used with RF\n",
    "#### Explanations at their relevant code portions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name: LECK WEI SHENG IAN\n",
    "#### NUS ID: A0168177R\n",
    "#### Name: WOO KENG THONG\n",
    "#### NUS ID: A0167991L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal is to predict the operating condition of a waterpoint for each record in the dataset. You are provided information about the waterpoints in order label them.\n",
    "\n",
    "The labels in this dataset are simple. There are three possible values:\n",
    "1. functional - the waterpoint is operational and there are no repairs needed\n",
    "2. functional needs repair - the waterpoint is operational, but needs repairs\n",
    "3. non functional - the waterpoint is not operational\n",
    "\n",
    "The format for the submission file is simply the row id and the predicted label. \n",
    "- id\tstatus_group\n",
    "- 50785\tfunctional\n",
    "- 51630\tfunctional\n",
    "\n",
    "CSV would thus look like\n",
    "- id,status_group\n",
    "- 50785,functional\n",
    "- 51630,functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data, and merge data and labels together into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('training-set-labels.csv')\n",
    "df = pd.read_csv('training-set-values.csv')\n",
    "test_df = pd.read_csv('test-set-values.csv')\n",
    "\n",
    "df = pd.merge(df, labels, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59400 entries, 0 to 59399\n",
      "Data columns (total 41 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     59400 non-null  int64  \n",
      " 1   amount_tsh             59400 non-null  float64\n",
      " 2   date_recorded          59400 non-null  object \n",
      " 3   funder                 55765 non-null  object \n",
      " 4   gps_height             59400 non-null  int64  \n",
      " 5   installer              55745 non-null  object \n",
      " 6   longitude              59400 non-null  float64\n",
      " 7   latitude               59400 non-null  float64\n",
      " 8   wpt_name               59400 non-null  object \n",
      " 9   num_private            59400 non-null  int64  \n",
      " 10  basin                  59400 non-null  object \n",
      " 11  subvillage             59029 non-null  object \n",
      " 12  region                 59400 non-null  object \n",
      " 13  region_code            59400 non-null  int64  \n",
      " 14  district_code          59400 non-null  int64  \n",
      " 15  lga                    59400 non-null  object \n",
      " 16  ward                   59400 non-null  object \n",
      " 17  population             59400 non-null  int64  \n",
      " 18  public_meeting         56066 non-null  object \n",
      " 19  recorded_by            59400 non-null  object \n",
      " 20  scheme_management      55523 non-null  object \n",
      " 21  scheme_name            31234 non-null  object \n",
      " 22  permit                 56344 non-null  object \n",
      " 23  construction_year      59400 non-null  int64  \n",
      " 24  extraction_type        59400 non-null  object \n",
      " 25  extraction_type_group  59400 non-null  object \n",
      " 26  extraction_type_class  59400 non-null  object \n",
      " 27  management             59400 non-null  object \n",
      " 28  management_group       59400 non-null  object \n",
      " 29  payment                59400 non-null  object \n",
      " 30  payment_type           59400 non-null  object \n",
      " 31  water_quality          59400 non-null  object \n",
      " 32  quality_group          59400 non-null  object \n",
      " 33  quantity               59400 non-null  object \n",
      " 34  quantity_group         59400 non-null  object \n",
      " 35  source                 59400 non-null  object \n",
      " 36  source_type            59400 non-null  object \n",
      " 37  source_class           59400 non-null  object \n",
      " 38  waterpoint_type        59400 non-null  object \n",
      " 39  waterpoint_type_group  59400 non-null  object \n",
      " 40  status_group           59400 non-null  object \n",
      "dtypes: float64(3), int64(7), object(31)\n",
      "memory usage: 19.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check similar predictors and eliminate highly correlated predictors to reduce redundancy. <br>\n",
    "Given that random forest will be used, highly correlated features might mask interactions between features and cause the accuracy to suffer. Hence, more features will be examined for correlation and subsequently removed to improve the random forest performance for the fourth submission.\n",
    "https://datascience.stackexchange.com/questions/24452/in-supervised-learning-why-is-it-bad-to-have-correlated-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region         region_code\n",
       "Arusha         2              3024\n",
       "               24              326\n",
       "Dar es Salaam  7               805\n",
       "Dodoma         1              2201\n",
       "Iringa         11             5294\n",
       "Kagera         18             3316\n",
       "Kigoma         16             2816\n",
       "Kilimanjaro    3              4379\n",
       "Lindi          8               300\n",
       "               18                8\n",
       "               80             1238\n",
       "Manyara        21             1583\n",
       "Mara           20             1969\n",
       "Mbeya          12             4639\n",
       "Morogoro       5              4006\n",
       "Mtwara         9               390\n",
       "               90              917\n",
       "               99              423\n",
       "Mwanza         17               55\n",
       "               19             3047\n",
       "Pwani          6              1609\n",
       "               40                1\n",
       "               60             1025\n",
       "Rukwa          15             1808\n",
       "Ruvuma         10             2640\n",
       "Shinyanga      11                6\n",
       "               14               20\n",
       "               17             4956\n",
       "Singida        13             2093\n",
       "Tabora         14             1959\n",
       "Tanga          4              2513\n",
       "               5                34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['region','region_code']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop `region_code` as it seems to be identify regions, yet is not able to stand on its own as there are identical region codes in different regions. `drop` list is compiled for each column dropped for subsequent use with test values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop = []\n",
    "drop.append('region_code')\n",
    "\n",
    "df.drop('region_code',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extraction_type            extraction_type_group  extraction_type_class\n",
       "afridev                    afridev                handpump                  1770\n",
       "cemo                       other motorpump        motorpump                   90\n",
       "climax                     other motorpump        motorpump                   32\n",
       "gravity                    gravity                gravity                  26780\n",
       "india mark ii              india mark ii          handpump                  2400\n",
       "india mark iii             india mark iii         handpump                    98\n",
       "ksb                        submersible            submersible               1415\n",
       "mono                       mono                   motorpump                 2865\n",
       "nira/tanira                nira/tanira            handpump                  8154\n",
       "other                      other                  other                     6430\n",
       "other - mkulima/shinyanga  other handpump         handpump                     2\n",
       "other - play pump          other handpump         handpump                    85\n",
       "other - rope pump          rope pump              rope pump                  451\n",
       "other - swn 81             other handpump         handpump                   229\n",
       "submersible                submersible            submersible               4764\n",
       "swn 80                     swn 80                 handpump                  3670\n",
       "walimi                     other handpump         handpump                    48\n",
       "windmill                   wind-powered           wind-powered               117\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['extraction_type','extraction_type_group','extraction_type_class']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop `extraction_type_group` as it seems to be a repeat of either of `extraction_type` or `extraction_type_class`. It seems to only identify differently when it is `other ...`, where `...` is `handpump` or `motorpump` for example, based on `extraction_type_class` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code', 'extraction_type_group']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('extraction_type_group')\n",
    "\n",
    "df.drop('extraction_type_group',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "management        management_group\n",
       "company           commercial            685\n",
       "other             other                 844\n",
       "other - school    other                  99\n",
       "parastatal        parastatal           1768\n",
       "private operator  commercial           1971\n",
       "trust             commercial             78\n",
       "unknown           unknown               561\n",
       "vwc               user-group          40507\n",
       "water authority   commercial            904\n",
       "water board       user-group           2933\n",
       "wua               user-group           2535\n",
       "wug               user-group           6515\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['management','management_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`management` appears to provide more specific information than `management_group`, which only appears to show the category of `management` - `commercial` for example. Hence `management_group` will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code', 'extraction_type_group', 'management_group']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('management_group')\n",
    "\n",
    "df.drop('management_group',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "payment                payment_type\n",
       "never pay              never pay       25348\n",
       "other                  other            1054\n",
       "pay annually           annually         3642\n",
       "pay monthly            monthly          8300\n",
       "pay per bucket         per bucket       8985\n",
       "pay when scheme fails  on failure       3914\n",
       "unknown                unknown          8157\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['payment','payment_type']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`payment` is highly correlated to `payment_type` $-$ which appears to categorize `payment` $-$ but does not offer more specific information. Hence it will thus be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code', 'extraction_type_group', 'management_group', 'payment']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('payment')\n",
    "\n",
    "df.drop('payment',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "water_quality       quality_group\n",
       "coloured            colored            490\n",
       "fluoride            fluoride           200\n",
       "fluoride abandoned  fluoride            17\n",
       "milky               milky              804\n",
       "salty               salty             4856\n",
       "salty abandoned     salty              339\n",
       "soft                good             50818\n",
       "unknown             unknown           1876\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['water_quality','quality_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`quality_group` is highly correlated to `water_quality`, but is less specific and provides less information. Hence, it will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code',\n",
       " 'extraction_type_group',\n",
       " 'management_group',\n",
       " 'payment',\n",
       " 'quality_group']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('quality_group')\n",
    "\n",
    "df.drop('quality_group', axis=1, inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quantity      quantity_group\n",
       "dry           dry                6246\n",
       "enough        enough            33186\n",
       "insufficient  insufficient      15129\n",
       "seasonal      seasonal           4050\n",
       "unknown       unknown             789\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['quantity','quantity_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`quantity` is highly correlated to `quantity_group` $-$ which appears to categorize `quantity` $-$ but does not offer more specific information and will thus be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code',\n",
       " 'extraction_type_group',\n",
       " 'management_group',\n",
       " 'payment',\n",
       " 'quality_group',\n",
       " 'quantity']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('quantity')\n",
    "\n",
    "df.drop('quantity',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source                source_type           source_class\n",
       "dam                   dam                   surface           656\n",
       "hand dtw              borehole              groundwater       874\n",
       "lake                  river/lake            surface           765\n",
       "machine dbh           borehole              groundwater     11075\n",
       "other                 other                 unknown           212\n",
       "rainwater harvesting  rainwater harvesting  surface          2295\n",
       "river                 river/lake            surface          9612\n",
       "shallow well          shallow well          groundwater     16824\n",
       "spring                spring                groundwater     17021\n",
       "unknown               other                 unknown            66\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['source','source_type','source_class']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`source_type` appears to be highly correlated with `source`, but is less specific. `source_class` is a further grouping of `source` into three types $-$ `surface`, `groundwater` and `unknown`. Hence, both `source_type` and `source_class` will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code',\n",
       " 'extraction_type_group',\n",
       " 'management_group',\n",
       " 'payment',\n",
       " 'quality_group',\n",
       " 'quantity',\n",
       " 'source_type',\n",
       " 'source_class']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('source_type')\n",
    "drop.append('source_class')\n",
    "\n",
    "df.drop('source_type',axis=1,inplace=True)\n",
    "df.drop('source_class',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "waterpoint_type              waterpoint_type_group\n",
       "cattle trough                cattle trough              116\n",
       "communal standpipe           communal standpipe       28522\n",
       "communal standpipe multiple  communal standpipe        6103\n",
       "dam                          dam                          7\n",
       "hand pump                    hand pump                17488\n",
       "improved spring              improved spring            784\n",
       "other                        other                     6380\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['waterpoint_type','waterpoint_type_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`waterpoint_type_group` is highly correlated to `waterpoint_type`, but is less specific and provides less information. Hence, it will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code',\n",
       " 'extraction_type_group',\n",
       " 'management_group',\n",
       " 'payment',\n",
       " 'quality_group',\n",
       " 'quantity',\n",
       " 'source_type',\n",
       " 'source_class',\n",
       " 'waterpoint_type_group']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('waterpoint_type_group')\n",
    "\n",
    "df.drop('waterpoint_type_group',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>num_private</th>\n",
       "      <th>district_code</th>\n",
       "      <th>population</th>\n",
       "      <th>construction_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>5.940000e+04</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37115.131768</td>\n",
       "      <td>317.650385</td>\n",
       "      <td>668.297239</td>\n",
       "      <td>34.077427</td>\n",
       "      <td>-5.706033e+00</td>\n",
       "      <td>0.474141</td>\n",
       "      <td>5.629747</td>\n",
       "      <td>179.909983</td>\n",
       "      <td>1300.652475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21453.128371</td>\n",
       "      <td>2997.574558</td>\n",
       "      <td>693.116350</td>\n",
       "      <td>6.567432</td>\n",
       "      <td>2.946019e+00</td>\n",
       "      <td>12.236230</td>\n",
       "      <td>9.633649</td>\n",
       "      <td>471.482176</td>\n",
       "      <td>951.620547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.164944e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18519.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.090347</td>\n",
       "      <td>-8.540621e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37061.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>34.908743</td>\n",
       "      <td>-5.021597e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1986.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55656.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1319.250000</td>\n",
       "      <td>37.178387</td>\n",
       "      <td>-3.326156e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74247.000000</td>\n",
       "      <td>350000.000000</td>\n",
       "      <td>2770.000000</td>\n",
       "      <td>40.345193</td>\n",
       "      <td>-2.000000e-08</td>\n",
       "      <td>1776.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     amount_tsh    gps_height     longitude      latitude  \\\n",
       "count  59400.000000   59400.000000  59400.000000  59400.000000  5.940000e+04   \n",
       "mean   37115.131768     317.650385    668.297239     34.077427 -5.706033e+00   \n",
       "std    21453.128371    2997.574558    693.116350      6.567432  2.946019e+00   \n",
       "min        0.000000       0.000000    -90.000000      0.000000 -1.164944e+01   \n",
       "25%    18519.750000       0.000000      0.000000     33.090347 -8.540621e+00   \n",
       "50%    37061.500000       0.000000    369.000000     34.908743 -5.021597e+00   \n",
       "75%    55656.500000      20.000000   1319.250000     37.178387 -3.326156e+00   \n",
       "max    74247.000000  350000.000000   2770.000000     40.345193 -2.000000e-08   \n",
       "\n",
       "        num_private  district_code    population  construction_year  \n",
       "count  59400.000000   59400.000000  59400.000000       59400.000000  \n",
       "mean       0.474141       5.629747    179.909983        1300.652475  \n",
       "std       12.236230       9.633649    471.482176         951.620547  \n",
       "min        0.000000       0.000000      0.000000           0.000000  \n",
       "25%        0.000000       2.000000      0.000000           0.000000  \n",
       "50%        0.000000       3.000000     25.000000        1986.000000  \n",
       "75%        0.000000       5.000000    215.000000        2004.000000  \n",
       "max     1776.000000      80.000000  30500.000000        2013.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `num_private` as it does not seem to be meaningful - mostly zeros at 25%, 50% and 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code',\n",
       " 'extraction_type_group',\n",
       " 'management_group',\n",
       " 'payment',\n",
       " 'quality_group',\n",
       " 'quantity',\n",
       " 'source_type',\n",
       " 'source_class',\n",
       " 'waterpoint_type_group',\n",
       " 'num_private']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('num_private')\n",
    "\n",
    "df.drop('num_private',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null values in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh                   0\n",
       "date_recorded                0\n",
       "funder                    3635\n",
       "gps_height                   0\n",
       "installer                 3655\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "basin                        0\n",
       "subvillage                 371\n",
       "region                       0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population                   0\n",
       "public_meeting            3334\n",
       "recorded_by                  0\n",
       "scheme_management         3877\n",
       "scheme_name              28166\n",
       "permit                    3056\n",
       "construction_year            0\n",
       "extraction_type              0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "waterpoint_type              0\n",
       "status_group                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### funder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Government Of Tanzania    9084\n",
       "Danida                    3114\n",
       "Hesawa                    2202\n",
       "Rwssp                     1374\n",
       "World Bank                1349\n",
       "Kkkt                      1287\n",
       "World Vision              1246\n",
       "Unicef                    1057\n",
       "Tasaf                      877\n",
       "District Council           843\n",
       "Dhv                        829\n",
       "Private Individual         826\n",
       "Dwsp                       811\n",
       "0                          777\n",
       "Norad                      765\n",
       "Germany Republi            610\n",
       "Tcrs                       602\n",
       "Ministry Of Water          590\n",
       "Water                      583\n",
       "Dwe                        484\n",
       "Name: funder, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['funder'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~Keep top 5 `funder` and set the rest to `other`, including missing values.<br>\n",
    "Using only the main 5 `funder` and reverting the rest to `other` is to reduce computational cost and mitigate overfitting.~ <br>\n",
    "We realised that the top 5 may not sufficiently represent all the different types of funders, and hence will only be replacing missing data with `other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['funder'].fillna('other', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DWE                   17402\n",
       "Government             1825\n",
       "RWE                    1206\n",
       "Commu                  1060\n",
       "DANIDA                 1050\n",
       "KKKT                    898\n",
       "Hesawa                  840\n",
       "0                       777\n",
       "TCRS                    707\n",
       "Central government      622\n",
       "CES                     610\n",
       "Community               553\n",
       "DANID                   552\n",
       "District Council        551\n",
       "HESAWA                  539\n",
       "LGA                     408\n",
       "World vision            408\n",
       "WEDECO                  397\n",
       "TASAF                   396\n",
       "District council        392\n",
       "Name: installer, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.installer.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~Keep top 5 `installer` and set the rest to `other`, including missing values.<br>\n",
    "Using only the main 5 `installer` and reverting the rest to `other` is to try to reduce computational cost and mitigate overfitting.~<br>\n",
    "We realised that the top 5 may not sufficiently represent all the different types of funders, and hence will only be replacing missing data with `other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['installer'].fillna('other',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### subvillage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Madukani            508\n",
       "Shuleni             506\n",
       "Majengo             502\n",
       "Kati                373\n",
       "Mtakuja             262\n",
       "                   ... \n",
       "Lugese A              1\n",
       "Mungoma Ya Chini      1\n",
       "Kalemela B Kati       1\n",
       "Murutunguru           1\n",
       "Barabara Kuu A        1\n",
       "Name: subvillage, Length: 19287, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.subvillage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 19287 unique `subvillage`, of which the largest group is only 508. As the total dataset only has around 59400 values, about a third of the data is unique. It is thus unlikely to be a meaningful feature, and will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code',\n",
       " 'extraction_type_group',\n",
       " 'management_group',\n",
       " 'payment',\n",
       " 'quality_group',\n",
       " 'quantity',\n",
       " 'source_type',\n",
       " 'source_class',\n",
       " 'waterpoint_type_group',\n",
       " 'num_private',\n",
       " 'subvillage']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('subvillage')\n",
    "df.drop('subvillage',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### public_meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     51011\n",
       "False     5055\n",
       "Name: public_meeting, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.public_meeting.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "public_meeting  status_group           \n",
       "False           functional                  2173\n",
       "                functional needs repair      442\n",
       "                non functional              2440\n",
       "True            functional                 28408\n",
       "                functional needs repair     3719\n",
       "                non functional             18884\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['public_meeting','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `public_meeting` to binary predictor and impute with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "public_meeting  status_group           \n",
       "0.0             functional                  2173\n",
       "                functional needs repair      442\n",
       "                non functional              2440\n",
       "1.0             functional                 30086\n",
       "                functional needs repair     3875\n",
       "                non functional             20384\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_public_meeting(row):\n",
    "    if row['public_meeting']==True:\n",
    "        return 1\n",
    "    elif row['public_meeting']==False:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df['public_meeting'] = df.apply(lambda row: convert_public_meeting(row), axis=1)\n",
    "df['public_meeting'].fillna(df['public_meeting'].mode().item(),inplace=True)\n",
    "df.groupby(['public_meeting','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### scheme_management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VWC                 36793\n",
       "WUG                  5206\n",
       "Water authority      3153\n",
       "WUA                  2883\n",
       "Water Board          2748\n",
       "Parastatal           1680\n",
       "Private operator     1063\n",
       "Company              1061\n",
       "Other                 766\n",
       "SWC                    97\n",
       "Trust                  72\n",
       "None                    1\n",
       "Name: scheme_management, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.scheme_management.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~Keep top 5 `scheme_management` and set the rest to `other`, including missing values.<br>\n",
    "Using only the main 5 `scheme_management` and reverting the rest to `other` is to try to reduce computational cost and mitigate overfitting.~<br>\n",
    "We realised that there is no need to reduce to 5 features, as there are only a total of 12 types of `scheme_management`. Hence, we will only be replacing missing data with `other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scheme_management'].fillna('other',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### scheme_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "K                              682\n",
       "None                           644\n",
       "Borehole                       546\n",
       "Chalinze wate                  405\n",
       "M                              400\n",
       "                              ... \n",
       "Namba 7 dam                      1\n",
       "Kaseni water supply              1\n",
       "Ikovo                            1\n",
       "Tungu windmill piped scheme      1\n",
       "Burieni water supply             1\n",
       "Name: scheme_name, Length: 2696, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.scheme_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2696 unique `scheme_name`, of which the largest group is only 682. Additionally, there are 28166 null values in this column. As the total dataset only has around 59400 values, nearly half of the data is either unique or missing. It is thus unlikely to be a meaningful feature, and will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code',\n",
       " 'extraction_type_group',\n",
       " 'management_group',\n",
       " 'payment',\n",
       " 'quality_group',\n",
       " 'quantity',\n",
       " 'source_type',\n",
       " 'source_class',\n",
       " 'waterpoint_type_group',\n",
       " 'num_private',\n",
       " 'subvillage',\n",
       " 'scheme_name']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('scheme_name')\n",
    "\n",
    "df.drop('scheme_name',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### permit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     38852\n",
       "False    17492\n",
       "Name: permit, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.permit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permit  status_group           \n",
       "False   functional                  9045\n",
       "        functional needs repair     1320\n",
       "        non functional              7127\n",
       "True    functional                 21541\n",
       "        functional needs repair     2697\n",
       "        non functional             14614\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['permit','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `permit` to binary predictor and impute with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permit  status_group           \n",
       "0.0     functional                  9045\n",
       "        functional needs repair     1320\n",
       "        non functional              7127\n",
       "1.0     functional                 23214\n",
       "        functional needs repair     2997\n",
       "        non functional             15697\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_permit(row):\n",
    "    if row['permit']==True:\n",
    "        return 1\n",
    "    elif row['permit']==False:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df['permit'] = df.apply(lambda row: convert_permit(row), axis=1)\n",
    "df['permit'].fillna(df['permit'].mode().item(),inplace=True)\n",
    "df.groupby(['permit','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having removed all null, ensure that there is no other invalid data $-$ 0 $-$ that can be immediately obvious for relevant columns such as `population`, `gps_height`, `amount_tsh` and `construction_year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh               41639\n",
       "date_recorded                0\n",
       "funder                       0\n",
       "gps_height               20438\n",
       "installer                    0\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "basin                        0\n",
       "region                       0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population               21381\n",
       "public_meeting               0\n",
       "recorded_by                  0\n",
       "scheme_management            0\n",
       "permit                       0\n",
       "construction_year        20709\n",
       "extraction_type              0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "waterpoint_type              0\n",
       "status_group                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gps_height'].replace(0, np.nan, inplace=True)\n",
    "df['population'].replace(0, np.nan, inplace=True)\n",
    "df['amount_tsh'].replace(0, np.nan, inplace=True)\n",
    "df['construction_year'].replace(0, np.nan, inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gps_height` is likely to be location-dependent as it is the height of an area is likely to be similar.<br>\n",
    "`amount_tsh` is also likely to be location-dependent as the amount of water that can be drawn in the same area is likely to be similar.<br>\n",
    "`population` is also likely to be location-dependent as communities in the same area will be subject to similar living conditions.<br>\n",
    "Holding the above assumptions, we will assume that the three predictors are affected by `region` and `district_code`, which based on the name, indicate a general area.<br>\n",
    "Hence, `region` and `district_code` will also be used when imputing missing data with mean values for `gps_height`, `amount_tsh` and `population`.<br>\n",
    "\n",
    "#### There is no clear indication whether the other predictors imputed earlier are relevant to geographic area, and hence were not imputed with `region`/`district_code`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount_tsh'].fillna(df.groupby(['region', 'district_code'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "df['amount_tsh'].fillna(df.groupby(['region'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "df['amount_tsh'].fillna(df['amount_tsh'].mean(), inplace=True)\n",
    "df['gps_height'].fillna(df.groupby(['region', 'district_code'])['gps_height'].transform('mean'), inplace=True)\n",
    "df['gps_height'].fillna(df.groupby(['region'])['gps_height'].transform('mean'), inplace=True)\n",
    "df['gps_height'].fillna(df['gps_height'].mean(), inplace=True)\n",
    "df['population'].fillna(df.groupby(['region', 'district_code'])['population'].transform('mean'), inplace=True)\n",
    "df['population'].fillna(df.groupby(['region'])['population'].transform('mean'), inplace=True)\n",
    "df['population'].fillna(df['population'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`construction_year` (as a numeric predictor) is also imputed with mean value. We assume that there is no relation between region and construction year as it is unlikely construction within each geographic area occurs in the same period due to resource constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       0\n",
       "amount_tsh               0\n",
       "date_recorded            0\n",
       "funder                   0\n",
       "gps_height               0\n",
       "installer                0\n",
       "longitude                0\n",
       "latitude                 0\n",
       "wpt_name                 0\n",
       "basin                    0\n",
       "region                   0\n",
       "district_code            0\n",
       "lga                      0\n",
       "ward                     0\n",
       "population               0\n",
       "public_meeting           0\n",
       "recorded_by              0\n",
       "scheme_management        0\n",
       "permit                   0\n",
       "construction_year        0\n",
       "extraction_type          0\n",
       "extraction_type_class    0\n",
       "management               0\n",
       "payment_type             0\n",
       "water_quality            0\n",
       "quantity_group           0\n",
       "source                   0\n",
       "waterpoint_type          0\n",
       "status_group             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['construction_year'].fillna(df['construction_year'].mean(),inplace=True)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`construction_year` provides the year that it is constructed and it is a good source for feature engineering. The longer a water point is operational, the more likely it is for the water point to be non functional or needs repair. <br> Convert `construction_year` and `date_recorded` into the number of years the waterpoint has been in operation for, and drop both features after as the `operational years` is likely to be a more useful predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
    "df['operational_years'] = df.date_recorded.dt.year - df.construction_year\n",
    "\n",
    "df.drop('date_recorded', axis=1, inplace=True)\n",
    "df.drop('construction_year', axis=1, inplace=True)\n",
    "drop.append('date_recorded')\n",
    "drop.append('construction_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take the same pre-processing steps for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                          0\n",
       "amount_tsh                  0\n",
       "date_recorded               0\n",
       "funder                    869\n",
       "gps_height                  0\n",
       "installer                 877\n",
       "longitude                   0\n",
       "latitude                    0\n",
       "wpt_name                    0\n",
       "num_private                 0\n",
       "basin                       0\n",
       "subvillage                 99\n",
       "region                      0\n",
       "region_code                 0\n",
       "district_code               0\n",
       "lga                         0\n",
       "ward                        0\n",
       "population                  0\n",
       "public_meeting            821\n",
       "recorded_by                 0\n",
       "scheme_management         969\n",
       "scheme_name              7092\n",
       "permit                    737\n",
       "construction_year           0\n",
       "extraction_type             0\n",
       "extraction_type_group       0\n",
       "extraction_type_class       0\n",
       "management                  0\n",
       "management_group            0\n",
       "payment                     0\n",
       "payment_type                0\n",
       "water_quality               0\n",
       "quality_group               0\n",
       "quantity                    0\n",
       "quantity_group              0\n",
       "source                      0\n",
       "source_type                 0\n",
       "source_class                0\n",
       "waterpoint_type             0\n",
       "waterpoint_type_group       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing data in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['funder'].fillna('other', inplace=True)\n",
    "df['installer'].fillna('other', inplace=True)\n",
    "df['scheme_management'].fillna('other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['public_meeting'] = test_df.apply(lambda row: convert_public_meeting(row), axis=1)\n",
    "test_df['public_meeting'].fillna(test_df['public_meeting'].mode().item(),inplace=True)\n",
    "\n",
    "test_df['permit'] = test_df.apply(lambda row: convert_permit(row), axis=1)\n",
    "test_df['permit'].fillna(test_df['permit'].mode().item(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having removed all null, ensure that there is no other invalid data $-$ 0 $-$ that can be immediately obvious for relevant columns such as `population`, `gps_height`, `amount_tsh` and `construction_year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh               10410\n",
       "date_recorded                0\n",
       "funder                     869\n",
       "gps_height                5211\n",
       "installer                  877\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "num_private                  0\n",
       "basin                        0\n",
       "subvillage                  99\n",
       "region                       0\n",
       "region_code                  0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population                5453\n",
       "public_meeting               0\n",
       "recorded_by                  0\n",
       "scheme_management          969\n",
       "scheme_name               7092\n",
       "permit                       0\n",
       "construction_year         5260\n",
       "extraction_type              0\n",
       "extraction_type_group        0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "management_group             0\n",
       "payment                      0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quality_group                0\n",
       "quantity                     0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "source_type                  0\n",
       "source_class                 0\n",
       "waterpoint_type              0\n",
       "waterpoint_type_group        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['gps_height'].replace(0, np.nan, inplace=True)\n",
    "test_df['population'].replace(0, np.nan, inplace=True)\n",
    "test_df['amount_tsh'].replace(0, np.nan, inplace=True)\n",
    "test_df['construction_year'].replace(0, np.nan, inplace=True)\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gps_height` is likely to be location-dependent as it is the height of an area is likely to be similar.<br>\n",
    "`amount_tsh` is also likely to be location-dependent as the amount of water that can be drawn in the same area is likely to be similar.<br>\n",
    "`population` is also likely to be location-dependent as communities in the same area will be subject to similar living conditions.<br>\n",
    "Holding the above assumptions, we will assume that the three predictors are affected by `region` and `district_code`, which based on the name, indicate a general area.<br>\n",
    "Hence, `region` and `district_code` will also be used when imputing missing data with mean values for `gps_height`, `amount_tsh` and `population`.<br>\n",
    "\n",
    "#### There is no clear indication whether the other predictors imputed earlier are relevant to geographic area, and hence were not imputed with `region`/`district_code`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['amount_tsh'].fillna(test_df.groupby(['region', 'district_code'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "test_df['amount_tsh'].fillna(test_df.groupby(['region'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "test_df['amount_tsh'].fillna(test_df['amount_tsh'].mean(), inplace=True)\n",
    "test_df['gps_height'].fillna(test_df.groupby(['region', 'district_code'])['gps_height'].transform('mean'), inplace=True)\n",
    "test_df['gps_height'].fillna(test_df.groupby(['region'])['gps_height'].transform('mean'), inplace=True)\n",
    "test_df['gps_height'].fillna(test_df['gps_height'].mean(), inplace=True)\n",
    "test_df['population'].fillna(test_df.groupby(['region', 'district_code'])['population'].transform('mean'), inplace=True)\n",
    "test_df['population'].fillna(test_df.groupby(['region'])['population'].transform('mean'), inplace=True)\n",
    "test_df['population'].fillna(test_df['population'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`construction_year` (as a numeric predictor) is also imputed with mean value. We assume that there is no relation between region and construction year as it is unlikely construction within each geographic area occurs in the same period due to resource constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['construction_year'].fillna(test_df['construction_year'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`construction_year` provides the year that it is constructed and it is a good source for feature engineering. The longer a water point is operational, the more likely it is for the water point to be non functional or needs repair. <br> Convert `construction_year` and `date_recorded` into the number of years the waterpoint has been in operation for, and drop both features after as the `operational years` is likely to be a more useful predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['date_recorded'] = pd.to_datetime(test_df['date_recorded'])\n",
    "test_df['operational_years'] = test_df.date_recorded.dt.year - test_df.construction_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in drop:\n",
    "    test_df.drop(i, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df).to_csv(\"clean.csv\", index=False)\n",
    "pd.DataFrame(test_df).to_csv(\"clean_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building (Fourth Submission) - RF with AX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('clean.csv')\n",
    "y_train = X_train.pop('status_group')\n",
    "X_test = pd.read_csv('clean_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 27 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     59400 non-null  int64  \n",
      " 1   amount_tsh             59400 non-null  float64\n",
      " 2   funder                 59400 non-null  object \n",
      " 3   gps_height             59400 non-null  float64\n",
      " 4   installer              59400 non-null  object \n",
      " 5   longitude              59400 non-null  float64\n",
      " 6   latitude               59400 non-null  float64\n",
      " 7   wpt_name               59400 non-null  object \n",
      " 8   basin                  59400 non-null  object \n",
      " 9   region                 59400 non-null  object \n",
      " 10  district_code          59400 non-null  int64  \n",
      " 11  lga                    59400 non-null  object \n",
      " 12  ward                   59400 non-null  object \n",
      " 13  population             59400 non-null  float64\n",
      " 14  public_meeting         59400 non-null  float64\n",
      " 15  recorded_by            59400 non-null  object \n",
      " 16  scheme_management      59400 non-null  object \n",
      " 17  permit                 59400 non-null  float64\n",
      " 18  extraction_type        59400 non-null  object \n",
      " 19  extraction_type_class  59400 non-null  object \n",
      " 20  management             59400 non-null  object \n",
      " 21  payment_type           59400 non-null  object \n",
      " 22  water_quality          59400 non-null  object \n",
      " 23  quantity_group         59400 non-null  object \n",
      " 24  source                 59400 non-null  object \n",
      " 25  waterpoint_type        59400 non-null  object \n",
      " 26  operational_years      59400 non-null  float64\n",
      "dtypes: float64(8), int64(2), object(17)\n",
      "memory usage: 12.2+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode labels into categorical variables\n",
    "https://stackoverflow.com/questions/40336502/want-to-know-the-diff-among-pd-factorize-pd-get-dummies-sklearn-preprocessing/40338956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['funder'] = pd.factorize(X_train['funder'])[0]\n",
    "X_train['installer'] = pd.factorize(X_train['installer'])[0]\n",
    "X_train['wpt_name'] = pd.factorize(X_train['wpt_name'])[0]\n",
    "X_train['basin'] = pd.factorize(X_train['basin'])[0]\n",
    "X_train['region'] = pd.factorize(X_train['region'])[0]\n",
    "X_train['lga'] = pd.factorize(X_train['lga'])[0]\n",
    "X_train['ward'] = pd.factorize(X_train['ward'])[0]\n",
    "X_train['recorded_by'] = pd.factorize(X_train['recorded_by'])[0]\n",
    "X_train['scheme_management'] = pd.factorize(X_train['scheme_management'])[0]\n",
    "X_train['extraction_type'] = pd.factorize(X_train['extraction_type'])[0]\n",
    "X_train['extraction_type_class'] = pd.factorize(X_train['extraction_type_class'])[0]\n",
    "X_train['management'] = pd.factorize(X_train['management'])[0]\n",
    "X_train['payment_type'] = pd.factorize(X_train['payment_type'])[0]\n",
    "X_train['water_quality'] = pd.factorize(X_train['water_quality'])[0]\n",
    "X_train['quantity_group'] = pd.factorize(X_train['quantity_group'])[0]\n",
    "X_train['source'] = pd.factorize(X_train['source'])[0]\n",
    "X_train['waterpoint_type'] = pd.factorize(X_train['waterpoint_type'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['funder'] = pd.factorize(X_test['funder'])[0]\n",
    "X_test['installer'] = pd.factorize(X_test['installer'])[0]\n",
    "X_test['wpt_name'] = pd.factorize(X_test['wpt_name'])[0]\n",
    "X_test['basin'] = pd.factorize(X_test['basin'])[0]\n",
    "X_test['region'] = pd.factorize(X_test['region'])[0]\n",
    "X_test['lga'] = pd.factorize(X_test['lga'])[0]\n",
    "X_test['ward'] = pd.factorize(X_test['ward'])[0]\n",
    "X_test['recorded_by'] = pd.factorize(X_test['recorded_by'])[0]\n",
    "X_test['scheme_management'] = pd.factorize(X_test['scheme_management'])[0]\n",
    "X_test['extraction_type'] = pd.factorize(X_test['extraction_type'])[0]\n",
    "X_test['extraction_type_class'] = pd.factorize(X_test['extraction_type_class'])[0]\n",
    "X_test['management'] = pd.factorize(X_test['management'])[0]\n",
    "X_test['payment_type'] = pd.factorize(X_test['payment_type'])[0]\n",
    "X_test['water_quality'] = pd.factorize(X_test['water_quality'])[0]\n",
    "X_test['quantity_group'] = pd.factorize(X_test['quantity_group'])[0]\n",
    "X_test['source'] = pd.factorize(X_test['source'])[0]\n",
    "X_test['waterpoint_type'] = pd.factorize(X_test['waterpoint_type'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more parameters to be tuned automatically in comparison to just `n_estimators` in the previous submission.<br>\n",
    "\n",
    "We are using `oob_score_` to optimize as it is generally unbiased, whereas $R^2$ might overfit on training data.\n",
    "https://stats.stackexchange.com/questions/288699/r2-score-vs-oob-score-random-forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_ax_score(parameterization, weight=None):\n",
    "\n",
    "    p_names = ['max_features', 'min_samples_split',\n",
    "              'min_samples_leaf', 'n_estimators']\n",
    "    params = {}\n",
    "    \n",
    "    for p in p_names:\n",
    "        params[p] = parameterization.get(p)\n",
    "    \n",
    "    print(params)\n",
    "\n",
    "    rf = RandomForestClassifier(criterion='gini',\n",
    "                                max_features=params['max_features'],\n",
    "                                min_samples_split=params['min_samples_split'],\n",
    "                                min_samples_leaf=params['min_samples_leaf'],\n",
    "                                n_estimators=params['n_estimators'],\n",
    "                                oob_score=True,\n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    print(rf.oob_score_)\n",
    "    return rf.oob_score_\n",
    "\n",
    "def evaluate_rf(parameters):\n",
    "    return {\"rf_ax\": rf_ax_score(parameters)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max_features` is no longer `auto` to allow us to find the ideal number of `max_features` during auto hyperparameter tuning.<br>\n",
    "`min_samples_split` is bound between default 2 and 10 to find the optimum amount, while mitigating over-fitting by having a potentially higher `min_samples_split`.<br>\n",
    "`min_samples_leaf` is bound between default 1 and 20, as a smaller leaf might make the forest more prone to capturing noise and 'growing' in a wrong direction.\n",
    "https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/<br>\n",
    "`n_estimators` is set between 100 and 1500, similar to the previous range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters=[\n",
    "    {\n",
    "        \"name\": \"max_features\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [1, 26],\n",
    "        \"log_scale\": False,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"min_samples_split\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [2, 10],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"min_samples_leaf\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [1, 20],\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"n_estimators\",\n",
    "        \"type\": \"range\",\n",
    "        \"bounds\": [100, 1500],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 11:52:46] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter max_features. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 11-11 11:52:46] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter min_samples_split. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 11-11 11:52:46] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter min_samples_leaf. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 11-11 11:52:46] ax.service.utils.instantiation: Inferred value type of ParameterType.INT for parameter n_estimators. If that is not the expected value type, you can explicity specify 'value_type' ('int', 'float', 'bool' or 'str') in parameter dict.\n",
      "[INFO 11-11 11:52:46] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 trials, GPEI for subsequent trials]). Iterations after 5 will take longer to generate due to  model-fitting.\n",
      "[INFO 11-11 11:52:46] ax.service.managed_loop: Started full optimization with 15 steps.\n",
      "[INFO 11-11 11:52:46] ax.service.managed_loop: Running optimization trial 1...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 26, 'min_samples_split': 7, 'min_samples_leaf': 1, 'n_estimators': 1044}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 11:54:38] ax.service.managed_loop: Running optimization trial 2...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8146969696969697\n",
      "{'max_features': 17, 'min_samples_split': 2, 'min_samples_leaf': 17, 'n_estimators': 737}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 11:55:24] ax.service.managed_loop: Running optimization trial 3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7996464646464646\n",
      "{'max_features': 3, 'min_samples_split': 2, 'min_samples_leaf': 12, 'n_estimators': 1049}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 11:55:45] ax.service.managed_loop: Running optimization trial 4...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7955555555555556\n",
      "{'max_features': 1, 'min_samples_split': 3, 'min_samples_leaf': 8, 'n_estimators': 879}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 11:55:58] ax.service.managed_loop: Running optimization trial 5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7783670033670034\n",
      "{'max_features': 12, 'min_samples_split': 8, 'min_samples_leaf': 11, 'n_estimators': 1373}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 11:57:03] ax.service.managed_loop: Running optimization trial 6...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8038383838383838\n",
      "{'max_features': 26, 'min_samples_split': 8, 'min_samples_leaf': 4, 'n_estimators': 1246}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 11:59:09] ax.service.managed_loop: Running optimization trial 7...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8132996632996633\n",
      "{'max_features': 26, 'min_samples_split': 9, 'min_samples_leaf': 1, 'n_estimators': 981}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 12:00:59] ax.service.managed_loop: Running optimization trial 8...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8141919191919192\n",
      "{'max_features': 26, 'min_samples_split': 7, 'min_samples_leaf': 4, 'n_estimators': 841}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 12:02:21] ax.service.managed_loop: Running optimization trial 9...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8137205387205387\n",
      "{'max_features': 21, 'min_samples_split': 8, 'min_samples_leaf': 2, 'n_estimators': 1015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 12:03:48] ax.service.managed_loop: Running optimization trial 10...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8149158249158249\n",
      "{'max_features': 23, 'min_samples_split': 8, 'min_samples_leaf': 1, 'n_estimators': 672}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 12:04:49] ax.service.managed_loop: Running optimization trial 11...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8142592592592592\n",
      "{'max_features': 22, 'min_samples_split': 10, 'min_samples_leaf': 5, 'n_estimators': 774}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 12:05:56] ax.service.managed_loop: Running optimization trial 12...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8116329966329966\n",
      "{'max_features': 22, 'min_samples_split': 9, 'min_samples_leaf': 1, 'n_estimators': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 12:08:17] ax.service.managed_loop: Running optimization trial 13...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8150841750841751\n",
      "{'max_features': 22, 'min_samples_split': 7, 'min_samples_leaf': 1, 'n_estimators': 1500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 12:10:36] ax.service.managed_loop: Running optimization trial 14...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8147811447811448\n",
      "{'max_features': 20, 'min_samples_split': 10, 'min_samples_leaf': 1, 'n_estimators': 1092}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 11-11 12:12:07] ax.service.managed_loop: Running optimization trial 15...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8156902356902357\n",
      "{'max_features': 16, 'min_samples_split': 10, 'min_samples_leaf': 1, 'n_estimators': 1500}\n",
      "0.8156565656565656\n"
     ]
    }
   ],
   "source": [
    "from ax import optimize\n",
    "\n",
    "best_parameters, values, experiment, model = optimize(\n",
    "    parameters=parameters,\n",
    "    evaluation_function=rf_ax_score,\n",
    "    objective_name='rf_ax',\n",
    "    total_trials=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 20,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 1092}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'rf_ax': 0.815690232858758}, {'rf_ax': {'rf_ax': 1.08241320505782e-11}})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit random forest with best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8156\n"
     ]
    }
   ],
   "source": [
    "X_train.drop('id',axis=1,inplace=True)\n",
    "rf = RandomForestClassifier(criterion='gini',\n",
    "                                max_features=best_parameters['max_features'],\n",
    "                                min_samples_split=best_parameters['min_samples_split'],\n",
    "                                min_samples_leaf=best_parameters['min_samples_leaf'],\n",
    "                                n_estimators=best_parameters['n_estimators'],\n",
    "                                oob_score=True,\n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "                            \n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "print(\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=X_test['id']\n",
    "X_test.drop(['id'],axis=1, inplace=True)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new dataframe with predictions and id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(y_pred)\n",
    "y_pred['id']=idx\n",
    "y_pred.columns=['status_group','id']\n",
    "y_pred=y_pred[['id','status_group']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred).to_csv(\"submission_rf_ax.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
