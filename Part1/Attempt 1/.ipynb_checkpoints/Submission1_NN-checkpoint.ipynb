{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS4242 Group Assignment Part 1\n",
    "**November 11, 2020**\n",
    "\n",
    "## Instructions\n",
    "\n",
    "+ 2 Parts: Predictive Analytics (30 marks) & Prescriptive Analytics (10 marks)\n",
    "+ Do all required data exploration - preprocessing - feature engineering - model building and evaluation steps\n",
    "+ Submit first entry - predict on the given test data - see leaderboard position, then improve upon previous entry to improve test accuracy. Each team must have at least 2 submissions\n",
    "\n",
    "+ At least one of the submitted models:\n",
    "  + Must be a neural network implemented using PyTorch\n",
    "  + Must use automated hyperparameter tuning\n",
    "+ It is important to __explain each step__ you perform in preprocessing, feature engineering, model training. Ask yourself why you are performing the step and write the reason. While you may use any online resource, you have to cite them AND explanation should be in our own words.\n",
    "+ __50% marks - explanation, 50% marks - code__\n",
    "+ __Bonus points if your team has rank < 500__\n",
    "+ **Submission deadline: November 11, 2020; 11:59 am**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name: LECK WEI SHENG IAN\n",
    "#### NUS ID: A0168177R\n",
    "#### Name: WOO KENG THONG\n",
    "#### NUS ID: A0167991L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal is to predict the operating condition of a waterpoint for each record in the dataset. You are provided information about the waterpoints in order label them.\n",
    "\n",
    "The labels in this dataset are simple. There are three possible values:\n",
    "1. functional - the waterpoint is operational and there are no repairs needed\n",
    "2. functional needs repair - the waterpoint is operational, but needs repairs\n",
    "3. non functional - the waterpoint is not operational\n",
    "\n",
    "The format for the submission file is simply the row id and the predicted label. \n",
    "- id\tstatus_group\n",
    "- 50785\tfunctional\n",
    "- 51630\tfunctional\n",
    "\n",
    "CSV would thus look like\n",
    "- id,status_group\n",
    "- 50785,functional\n",
    "- 51630,functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data, and merge data and labels together into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('training-set-labels.csv')\n",
    "df = pd.read_csv('training-set-values.csv')\n",
    "test_df = pd.read_csv('test-set-values.csv')\n",
    "\n",
    "df = pd.merge(df, labels, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59400 entries, 0 to 59399\n",
      "Data columns (total 41 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     59400 non-null  int64  \n",
      " 1   amount_tsh             59400 non-null  float64\n",
      " 2   date_recorded          59400 non-null  object \n",
      " 3   funder                 55765 non-null  object \n",
      " 4   gps_height             59400 non-null  int64  \n",
      " 5   installer              55745 non-null  object \n",
      " 6   longitude              59400 non-null  float64\n",
      " 7   latitude               59400 non-null  float64\n",
      " 8   wpt_name               59400 non-null  object \n",
      " 9   num_private            59400 non-null  int64  \n",
      " 10  basin                  59400 non-null  object \n",
      " 11  subvillage             59029 non-null  object \n",
      " 12  region                 59400 non-null  object \n",
      " 13  region_code            59400 non-null  int64  \n",
      " 14  district_code          59400 non-null  int64  \n",
      " 15  lga                    59400 non-null  object \n",
      " 16  ward                   59400 non-null  object \n",
      " 17  population             59400 non-null  int64  \n",
      " 18  public_meeting         56066 non-null  object \n",
      " 19  recorded_by            59400 non-null  object \n",
      " 20  scheme_management      55523 non-null  object \n",
      " 21  scheme_name            31234 non-null  object \n",
      " 22  permit                 56344 non-null  object \n",
      " 23  construction_year      59400 non-null  int64  \n",
      " 24  extraction_type        59400 non-null  object \n",
      " 25  extraction_type_group  59400 non-null  object \n",
      " 26  extraction_type_class  59400 non-null  object \n",
      " 27  management             59400 non-null  object \n",
      " 28  management_group       59400 non-null  object \n",
      " 29  payment                59400 non-null  object \n",
      " 30  payment_type           59400 non-null  object \n",
      " 31  water_quality          59400 non-null  object \n",
      " 32  quality_group          59400 non-null  object \n",
      " 33  quantity               59400 non-null  object \n",
      " 34  quantity_group         59400 non-null  object \n",
      " 35  source                 59400 non-null  object \n",
      " 36  source_type            59400 non-null  object \n",
      " 37  source_class           59400 non-null  object \n",
      " 38  waterpoint_type        59400 non-null  object \n",
      " 39  waterpoint_type_group  59400 non-null  object \n",
      " 40  status_group           59400 non-null  object \n",
      "dtypes: float64(3), int64(7), object(31)\n",
      "memory usage: 19.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check similar predictors and eliminate highly correlated predictors to reduce redundancy and reduce multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region         region_code\n",
       "Arusha         2              3024\n",
       "               24              326\n",
       "Dar es Salaam  7               805\n",
       "Dodoma         1              2201\n",
       "Iringa         11             5294\n",
       "Kagera         18             3316\n",
       "Kigoma         16             2816\n",
       "Kilimanjaro    3              4379\n",
       "Lindi          8               300\n",
       "               18                8\n",
       "               80             1238\n",
       "Manyara        21             1583\n",
       "Mara           20             1969\n",
       "Mbeya          12             4639\n",
       "Morogoro       5              4006\n",
       "Mtwara         9               390\n",
       "               90              917\n",
       "               99              423\n",
       "Mwanza         17               55\n",
       "               19             3047\n",
       "Pwani          6              1609\n",
       "               40                1\n",
       "               60             1025\n",
       "Rukwa          15             1808\n",
       "Ruvuma         10             2640\n",
       "Shinyanga      11                6\n",
       "               14               20\n",
       "               17             4956\n",
       "Singida        13             2093\n",
       "Tabora         14             1959\n",
       "Tanga          4              2513\n",
       "               5                34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['region','region_code']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop `region_code` as it seems to be identify regions, yet is not able to stand on its own as there are identical region codes in different regions. `drop` list is compiled for each column dropped for subsequent use with test values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop = []\n",
    "drop.append('region_code')\n",
    "\n",
    "df.drop('region_code',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>num_private</th>\n",
       "      <th>district_code</th>\n",
       "      <th>population</th>\n",
       "      <th>construction_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>5.940000e+04</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "      <td>59400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37115.131768</td>\n",
       "      <td>317.650385</td>\n",
       "      <td>668.297239</td>\n",
       "      <td>34.077427</td>\n",
       "      <td>-5.706033e+00</td>\n",
       "      <td>0.474141</td>\n",
       "      <td>5.629747</td>\n",
       "      <td>179.909983</td>\n",
       "      <td>1300.652475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21453.128371</td>\n",
       "      <td>2997.574558</td>\n",
       "      <td>693.116350</td>\n",
       "      <td>6.567432</td>\n",
       "      <td>2.946019e+00</td>\n",
       "      <td>12.236230</td>\n",
       "      <td>9.633649</td>\n",
       "      <td>471.482176</td>\n",
       "      <td>951.620547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.164944e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18519.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.090347</td>\n",
       "      <td>-8.540621e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37061.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>34.908743</td>\n",
       "      <td>-5.021597e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1986.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55656.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1319.250000</td>\n",
       "      <td>37.178387</td>\n",
       "      <td>-3.326156e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74247.000000</td>\n",
       "      <td>350000.000000</td>\n",
       "      <td>2770.000000</td>\n",
       "      <td>40.345193</td>\n",
       "      <td>-2.000000e-08</td>\n",
       "      <td>1776.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     amount_tsh    gps_height     longitude      latitude  \\\n",
       "count  59400.000000   59400.000000  59400.000000  59400.000000  5.940000e+04   \n",
       "mean   37115.131768     317.650385    668.297239     34.077427 -5.706033e+00   \n",
       "std    21453.128371    2997.574558    693.116350      6.567432  2.946019e+00   \n",
       "min        0.000000       0.000000    -90.000000      0.000000 -1.164944e+01   \n",
       "25%    18519.750000       0.000000      0.000000     33.090347 -8.540621e+00   \n",
       "50%    37061.500000       0.000000    369.000000     34.908743 -5.021597e+00   \n",
       "75%    55656.500000      20.000000   1319.250000     37.178387 -3.326156e+00   \n",
       "max    74247.000000  350000.000000   2770.000000     40.345193 -2.000000e-08   \n",
       "\n",
       "        num_private  district_code    population  construction_year  \n",
       "count  59400.000000   59400.000000  59400.000000       59400.000000  \n",
       "mean       0.474141       5.629747    179.909983        1300.652475  \n",
       "std       12.236230       9.633649    471.482176         951.620547  \n",
       "min        0.000000       0.000000      0.000000           0.000000  \n",
       "25%        0.000000       2.000000      0.000000           0.000000  \n",
       "50%        0.000000       3.000000     25.000000        1986.000000  \n",
       "75%        0.000000       5.000000    215.000000        2004.000000  \n",
       "max     1776.000000      80.000000  30500.000000        2013.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove `num_private` as it does not seem to be meaningful - mostly zeros at 25%, 50% and 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code', 'num_private']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('num_private')\n",
    "\n",
    "df.drop('num_private',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null values in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh                   0\n",
       "date_recorded                0\n",
       "funder                    3635\n",
       "gps_height                   0\n",
       "installer                 3655\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "basin                        0\n",
       "subvillage                 371\n",
       "region                       0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population                   0\n",
       "public_meeting            3334\n",
       "recorded_by                  0\n",
       "scheme_management         3877\n",
       "scheme_name              28166\n",
       "permit                    3056\n",
       "construction_year            0\n",
       "extraction_type              0\n",
       "extraction_type_group        0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "management_group             0\n",
       "payment                      0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quality_group                0\n",
       "quantity                     0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "source_type                  0\n",
       "source_class                 0\n",
       "waterpoint_type              0\n",
       "waterpoint_type_group        0\n",
       "status_group                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### funder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Government Of Tanzania     9084\n",
       "Danida                     3114\n",
       "Hesawa                     2202\n",
       "Rwssp                      1374\n",
       "World Bank                 1349\n",
       "                           ... \n",
       "Mzee Salum Bakari Darus       1\n",
       "Mwanamisi Ally                1\n",
       "Morad                         1\n",
       "Ndolezi                       1\n",
       "Samwel                        1\n",
       "Name: funder, Length: 1897, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['funder'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep top 5 `funder` and set the rest to `other`, including missing values.<br>\n",
    "Using only the main 5 `funder` and reverting the rest to `other` is to reduce computational cost and mitigate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "funder  status_group           \n",
       "bank    functional                   545\n",
       "        functional needs repair       97\n",
       "        non functional               707\n",
       "danida  functional                  1713\n",
       "        functional needs repair      159\n",
       "        non functional              1242\n",
       "gov     functional                  3720\n",
       "        functional needs repair      701\n",
       "        non functional              4663\n",
       "hesawa  functional                   936\n",
       "        functional needs repair      232\n",
       "        non functional              1034\n",
       "other   functional                 24540\n",
       "        functional needs repair     3019\n",
       "        non functional             14718\n",
       "rwssp   functional                   805\n",
       "        functional needs repair      109\n",
       "        non functional               460\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_funder(row):\n",
    "    if row['funder']=='Government Of Tanzania':\n",
    "        return 'gov'\n",
    "    elif row['funder']=='Danida':\n",
    "        return 'danida'\n",
    "    elif row['funder']=='Hesawa':\n",
    "        return 'hesawa'\n",
    "    elif row['funder']=='Rwssp':\n",
    "        return 'rwssp'\n",
    "    elif row['funder']=='World Bank':\n",
    "        return 'bank'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "df['funder'] = df.apply(lambda row: update_funder(row), axis=1)\n",
    "\n",
    "df.groupby(['funder','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### installer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DWE                 17402\n",
       "Government           1825\n",
       "RWE                  1206\n",
       "Commu                1060\n",
       "DANIDA               1050\n",
       "                    ...  \n",
       "Atlas                   1\n",
       "TGT                     1\n",
       "RDDC                    1\n",
       "Lindi contractor        1\n",
       "Siza Mayengo            1\n",
       "Name: installer, Length: 2145, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.installer.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep top 5 `installer` and set the rest to `other`, including missing values.<br>\n",
    "Using only the main 5 `installer` and reverting the rest to `other` is to reduce computational cost and mitigate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "installer  status_group           \n",
       "commu      functional                   724\n",
       "           functional needs repair       32\n",
       "           non functional               304\n",
       "danida     functional                   542\n",
       "           functional needs repair       83\n",
       "           non functional               425\n",
       "dwe        functional                  9433\n",
       "           functional needs repair     1622\n",
       "           non functional              6347\n",
       "gov        functional                   535\n",
       "           functional needs repair      256\n",
       "           non functional              1034\n",
       "other      functional                 20721\n",
       "           functional needs repair     2187\n",
       "           non functional             13949\n",
       "rwe        functional                   304\n",
       "           functional needs repair      137\n",
       "           non functional               765\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_installer(row):\n",
    "    if row['installer']=='DWE':\n",
    "        return 'dwe'\n",
    "    elif row['installer']=='Government':\n",
    "        return 'gov'\n",
    "    elif row['installer']=='RWE':\n",
    "        return 'rwe'\n",
    "    elif row['installer']=='Commu':\n",
    "        return 'commu'\n",
    "    elif row['installer']=='DANIDA':\n",
    "        return 'danida'\n",
    "    else:\n",
    "        return 'other'  \n",
    "\n",
    "df['installer'] = df.apply(lambda row: update_installer(row), axis=1)\n",
    "\n",
    "df.groupby(['installer','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### subvillage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Madukani     508\n",
       "Shuleni      506\n",
       "Majengo      502\n",
       "Kati         373\n",
       "Mtakuja      262\n",
       "            ... \n",
       "Kasunga        1\n",
       "Seketule       1\n",
       "Itegetela      1\n",
       "Mulungu A      1\n",
       "Nyamusta       1\n",
       "Name: subvillage, Length: 19287, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.subvillage.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 19287 unique `subvillage`, of which the largest group is only 508. As the total dataset only has around 59400 values, about a third of the data is unique. It is thus unlikely to be a meaningful feature, and will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code', 'num_private', 'subvillage']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('subvillage')\n",
    "df.drop('subvillage',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### public_meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     51011\n",
       "False     5055\n",
       "Name: public_meeting, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.public_meeting.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "public_meeting  status_group           \n",
       "False           functional                  2173\n",
       "                functional needs repair      442\n",
       "                non functional              2440\n",
       "True            functional                 28408\n",
       "                functional needs repair     3719\n",
       "                non functional             18884\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['public_meeting','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `public_meeting` to binary predictor and impute with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "public_meeting  status_group           \n",
       "0.0             functional                  2173\n",
       "                functional needs repair      442\n",
       "                non functional              2440\n",
       "1.0             functional                 28408\n",
       "                functional needs repair     3719\n",
       "                non functional             18884\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_public_meeting(row):\n",
    "    if row['public_meeting']==True:\n",
    "        return 1\n",
    "    elif row['public_meeting']==False:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df['public_meeting'] = df.apply(lambda row: convert_public_meeting(row), axis=1)\n",
    "df['public_meeting'].fillna(df['public_meeting'].mode().item(),inplace=True)\n",
    "df.groupby(['public_meeting','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### scheme_management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VWC                 36793\n",
       "WUG                  5206\n",
       "Water authority      3153\n",
       "WUA                  2883\n",
       "Water Board          2748\n",
       "Parastatal           1680\n",
       "Private operator     1063\n",
       "Company              1061\n",
       "Other                 766\n",
       "SWC                    97\n",
       "Trust                  72\n",
       "None                    1\n",
       "Name: scheme_management, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.scheme_management.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep top 5 `scheme_management` and set the rest to `other`, including missing values.<br>\n",
    "Using only the main 5 `scheme_management` and reverting the rest to `other` is to reduce computational cost and mitigate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scheme_management  status_group           \n",
       "other              functional                  4627\n",
       "                   functional needs repair      513\n",
       "                   non functional              3477\n",
       "vwc                functional                 18960\n",
       "                   functional needs repair     2334\n",
       "                   non functional             15499\n",
       "water_auth         functional                  1618\n",
       "                   functional needs repair      448\n",
       "                   non functional              1087\n",
       "water_bd           functional                  2053\n",
       "                   functional needs repair      111\n",
       "                   non functional               584\n",
       "wua                functional                  1995\n",
       "                   functional needs repair      239\n",
       "                   non functional               649\n",
       "wug                functional                  3006\n",
       "                   functional needs repair      672\n",
       "                   non functional              1528\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def update_scheme_management(row):\n",
    "    if row['scheme_management']=='VWC':\n",
    "        return 'vwc'\n",
    "    elif row['scheme_management']=='WUG':\n",
    "        return 'wug'\n",
    "    elif row['scheme_management']=='Water authority':\n",
    "        return 'water_auth'\n",
    "    elif row['scheme_management']=='WUA':\n",
    "        return 'wua'\n",
    "    elif row['scheme_management']=='Water Board':\n",
    "        return 'water_bd'\n",
    "    else:\n",
    "        return 'other'  \n",
    "    \n",
    "df['scheme_management'] = df.apply(lambda row: update_scheme_management(row), axis=1)\n",
    "df.groupby(['scheme_management','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### scheme_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "K                           682\n",
       "None                        644\n",
       "Borehole                    546\n",
       "Chalinze wate               405\n",
       "M                           400\n",
       "                           ... \n",
       "Kwam                          1\n",
       "Nabaiye pipe broken           1\n",
       "Kifumangao Water supply       1\n",
       "Fufulamsuri water supply      1\n",
       "Kapu chini water supply       1\n",
       "Name: scheme_name, Length: 2696, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.scheme_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2696 unique `scheme_name`, of which the largest group is only 682. Additionally, there are 28166 null values in this column. As the total dataset only has around 59400 values, nearly half of the data is either unique or missing. It is thus unlikely to be a meaningful feature, and will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_code', 'num_private', 'subvillage', 'scheme_name']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop.append('scheme_name')\n",
    "\n",
    "df.drop('scheme_name',axis=1,inplace=True)\n",
    "drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deal with columns containing null values.\n",
    "- #### permit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     38852\n",
       "False    17492\n",
       "Name: permit, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.permit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permit  status_group           \n",
       "False   functional                  9045\n",
       "        functional needs repair     1320\n",
       "        non functional              7127\n",
       "True    functional                 21541\n",
       "        functional needs repair     2697\n",
       "        non functional             14614\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['permit','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `permit` to binary predictor and impute with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permit  status_group           \n",
       "0.0     functional                  9045\n",
       "        functional needs repair     1320\n",
       "        non functional              7127\n",
       "1.0     functional                 21541\n",
       "        functional needs repair     2697\n",
       "        non functional             14614\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_permit(row):\n",
    "    if row['permit']==True:\n",
    "        return 1\n",
    "    elif row['permit']==False:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df['permit'] = df.apply(lambda row: convert_permit(row), axis=1)\n",
    "df['permit'].fillna(df['permit'].mode().item(),inplace=True)\n",
    "df.groupby(['permit','status_group']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having removed all null, ensure that there is no other invalid data $-$ 0 $-$ that can be immediately obvious for relevant columns such as `population`, `gps_height`, `amount_tsh` and `construction_year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh               41639\n",
       "date_recorded                0\n",
       "funder                       0\n",
       "gps_height               20438\n",
       "installer                    0\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "basin                        0\n",
       "region                       0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population               21381\n",
       "public_meeting            3334\n",
       "recorded_by                  0\n",
       "scheme_management            0\n",
       "permit                    3056\n",
       "construction_year        20709\n",
       "extraction_type              0\n",
       "extraction_type_group        0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "management_group             0\n",
       "payment                      0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quality_group                0\n",
       "quantity                     0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "source_type                  0\n",
       "source_class                 0\n",
       "waterpoint_type              0\n",
       "waterpoint_type_group        0\n",
       "status_group                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gps_height'].replace(0, np.nan, inplace=True)\n",
    "df['population'].replace(0, np.nan, inplace=True)\n",
    "df['amount_tsh'].replace(0, np.nan, inplace=True)\n",
    "df['construction_year'].replace(0, np.nan, inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gps_height` is likely to be location-dependent as it is the height of an area is likely to be similar.<br>\n",
    "`amount_tsh` is also likely to be location-dependent as the amount of water that can be drawn in the same area is likely to be similar.<br>\n",
    "`population` is also likely to be location-dependent as communities in the same area will be subject to similar living conditions.<br>\n",
    "Holding the above assumptions, we will assume that the three predictors are affected by `region` and `district_code`, which based on the name, indicate a general area.<br>\n",
    "Hence, `region` and `district_code` will also be used when imputing missing data with mean values for `gps_height`, `amount_tsh` and `population`.<br>\n",
    "\n",
    "#### There is no clear indication whether the other predictors imputed earlier are relevant to geographic area, and hence were not imputed with `region`/`district_code`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount_tsh'].fillna(df.groupby(['region', 'district_code'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "df['amount_tsh'].fillna(df.groupby(['region'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "df['amount_tsh'].fillna(df['amount_tsh'].mean(), inplace=True)\n",
    "df['gps_height'].fillna(df.groupby(['region', 'district_code'])['gps_height'].transform('mean'), inplace=True)\n",
    "df['gps_height'].fillna(df.groupby(['region'])['gps_height'].transform('mean'), inplace=True)\n",
    "df['gps_height'].fillna(df['gps_height'].mean(), inplace=True)\n",
    "df['population'].fillna(df.groupby(['region', 'district_code'])['population'].transform('mean'), inplace=True)\n",
    "df['population'].fillna(df.groupby(['region'])['population'].transform('mean'), inplace=True)\n",
    "df['population'].fillna(df['population'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`construction_year` (as a numeric predictor) is also imputed with mean value. We assume that there is no relation between region and construction year as it is unlikely construction within each geographic area occurs in the same period due to resource constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                          0\n",
       "amount_tsh                  0\n",
       "date_recorded               0\n",
       "funder                      0\n",
       "gps_height                  0\n",
       "installer                   0\n",
       "longitude                   0\n",
       "latitude                    0\n",
       "wpt_name                    0\n",
       "basin                       0\n",
       "region                      0\n",
       "district_code               0\n",
       "lga                         0\n",
       "ward                        0\n",
       "population                  0\n",
       "public_meeting           3334\n",
       "recorded_by                 0\n",
       "scheme_management           0\n",
       "permit                   3056\n",
       "construction_year           0\n",
       "extraction_type             0\n",
       "extraction_type_group       0\n",
       "extraction_type_class       0\n",
       "management                  0\n",
       "management_group            0\n",
       "payment                     0\n",
       "payment_type                0\n",
       "water_quality               0\n",
       "quality_group               0\n",
       "quantity                    0\n",
       "quantity_group              0\n",
       "source                      0\n",
       "source_type                 0\n",
       "source_class                0\n",
       "waterpoint_type             0\n",
       "waterpoint_type_group       0\n",
       "status_group                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['construction_year'].fillna(df['construction_year'].mean(),inplace=True)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`construction_year` provides the year that it is constructed and it is a good source for feature engineering. The longer a water point is operational, the more likely it is for the water point to be non functional or needs repair. <br> Convert `construction_year` and `date_recorded` into the number of years the waterpoint has been in operation for, and drop both features after as the `operational years` is likely to be a more useful predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
    "df['operational_years'] = df.date_recorded.dt.year - df.construction_year\n",
    "\n",
    "df.drop('date_recorded', axis=1, inplace=True)\n",
    "df.drop('construction_year', axis=1, inplace=True)\n",
    "drop.append('date_recorded')\n",
    "drop.append('construction_year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take the same pre-processing steps for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Government Of Tanzania    2215\n",
       "Danida                     793\n",
       "Hesawa                     580\n",
       "World Bank                 352\n",
       "Kkkt                       336\n",
       "                          ... \n",
       "Mount Meru Flowers           1\n",
       "H/w                          1\n",
       "Private Co                   1\n",
       "Agness                       1\n",
       "Jaic                         1\n",
       "Name: funder, Length: 980, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.funder.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_funder_test(row):\n",
    "    if row['funder']=='Government Of Tanzania':\n",
    "        return 'gov'\n",
    "    elif row['funder']=='Danida':\n",
    "        return 'danida'\n",
    "    elif row['funder']=='Hesawa':\n",
    "        return 'hesawa'\n",
    "    elif row['funder']=='World Bank':\n",
    "        return 'bank'\n",
    "    elif row['funder']=='Kkkt':\n",
    "        return 'kkkt'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "test_df['funder'] = test_df.apply(lambda row: update_funder(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DWE                               4349\n",
       "Government                         457\n",
       "RWE                                292\n",
       "Commu                              287\n",
       "DANIDA                             255\n",
       "                                  ... \n",
       "Tober and friends from Austral       1\n",
       "Regional water                       1\n",
       "DE &                                 1\n",
       "AIC                                  1\n",
       "Atlas Company                        1\n",
       "Name: installer, Length: 1091, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.installer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_installer_test(row):\n",
    "    if row['installer']=='DWE':\n",
    "        return 'dwe'\n",
    "    elif row['installer']=='Government':\n",
    "        return 'gov'\n",
    "    elif row['installer']=='RWE':\n",
    "        return 'rwe'\n",
    "    elif row['installer']=='Commu':\n",
    "        return 'commu'\n",
    "    elif row['installer']=='DANIDA':\n",
    "        return 'danida'\n",
    "    else:\n",
    "        return 'other'  \n",
    "\n",
    "test_df['installer'] = test_df.apply(lambda row: update_installer(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['public_meeting'] = test_df.apply(lambda row: convert_public_meeting(row), axis=1)\n",
    "test_df['public_meeting'].fillna(test_df['public_meeting'].mode().item(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VWC                 9124\n",
       "WUG                 1290\n",
       "Water authority      822\n",
       "Water Board          714\n",
       "WUA                  668\n",
       "Parastatal           444\n",
       "Company              280\n",
       "Private operator     263\n",
       "Other                230\n",
       "SWC                   26\n",
       "Trust                 20\n",
       "Name: scheme_management, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.scheme_management.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scheme_management_test(row):\n",
    "    if row['scheme_management']=='VWC':\n",
    "        return 'vwc'\n",
    "    elif row['scheme_management']=='WUG':\n",
    "        return 'wug'\n",
    "    elif row['scheme_management']=='Water authority':\n",
    "        return 'water_auth'\n",
    "    elif row['scheme_management']=='Water Board':\n",
    "        return 'water_bd'\n",
    "    elif row['scheme_management']=='WUA':\n",
    "        return 'wua'\n",
    "    else:\n",
    "        return 'other'  \n",
    "\n",
    "test_df['scheme_management'] = test_df.apply(lambda row: update_scheme_management(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `permit` to binary predictor and impute with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['permit'] = test_df.apply(lambda row: convert_permit(row), axis=1)\n",
    "test_df['permit'].fillna(test_df['permit'].mode().item(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having removed all null, ensure that there is no other invalid data $-$ 0 $-$ that can be immediately obvious for relevant columns such as `population`, `gps_height`, `amount_tsh` and `construction_year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "amount_tsh               10410\n",
       "date_recorded                0\n",
       "funder                       0\n",
       "gps_height                5211\n",
       "installer                    0\n",
       "longitude                    0\n",
       "latitude                     0\n",
       "wpt_name                     0\n",
       "num_private                  0\n",
       "basin                        0\n",
       "subvillage                  99\n",
       "region                       0\n",
       "region_code                  0\n",
       "district_code                0\n",
       "lga                          0\n",
       "ward                         0\n",
       "population                5453\n",
       "public_meeting             821\n",
       "recorded_by                  0\n",
       "scheme_management            0\n",
       "scheme_name               7092\n",
       "permit                     737\n",
       "construction_year         5260\n",
       "extraction_type              0\n",
       "extraction_type_group        0\n",
       "extraction_type_class        0\n",
       "management                   0\n",
       "management_group             0\n",
       "payment                      0\n",
       "payment_type                 0\n",
       "water_quality                0\n",
       "quality_group                0\n",
       "quantity                     0\n",
       "quantity_group               0\n",
       "source                       0\n",
       "source_type                  0\n",
       "source_class                 0\n",
       "waterpoint_type              0\n",
       "waterpoint_type_group        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['gps_height'].replace(0, np.nan, inplace=True)\n",
    "test_df['population'].replace(0, np.nan, inplace=True)\n",
    "test_df['amount_tsh'].replace(0, np.nan, inplace=True)\n",
    "test_df['construction_year'].replace(0, np.nan, inplace=True)\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gps_height` is likely to be location-dependent as it is the height of an area is likely to be similar.<br>\n",
    "`amount_tsh` is also likely to be location-dependent as the amount of water that can be drawn in the same area is likely to be similar.<br>\n",
    "`population` is also likely to be location-dependent as communities in the same area will be subject to similar living conditions.<br>\n",
    "Holding the above assumptions, we will assume that the three predictors are affected by `region` and `district_code`, which based on the name, indicate a general area.<br>\n",
    "Hence, `region` and `district_code` will also be used when imputing missing data with mean values for `gps_height`, `amount_tsh` and `population`.<br>\n",
    "\n",
    "#### There is no clear indication whether the other predictors imputed earlier are relevant to geographic area, and hence were not imputed with `region`/`district_code`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['amount_tsh'].fillna(test_df.groupby(['region', 'district_code'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "test_df['amount_tsh'].fillna(test_df.groupby(['region'])['amount_tsh'].transform('mean'), inplace=True)\n",
    "test_df['amount_tsh'].fillna(test_df['amount_tsh'].mean(), inplace=True)\n",
    "test_df['gps_height'].fillna(test_df.groupby(['region', 'district_code'])['gps_height'].transform('mean'), inplace=True)\n",
    "test_df['gps_height'].fillna(test_df.groupby(['region'])['gps_height'].transform('mean'), inplace=True)\n",
    "test_df['gps_height'].fillna(test_df['gps_height'].mean(), inplace=True)\n",
    "test_df['population'].fillna(test_df.groupby(['region', 'district_code'])['population'].transform('mean'), inplace=True)\n",
    "test_df['population'].fillna(test_df.groupby(['region'])['population'].transform('mean'), inplace=True)\n",
    "test_df['population'].fillna(test_df['population'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`construction_year` (as a numeric predictor) is also imputed with mean value. We assume that there is no relation between region and construction year as it is unlikely construction within each geographic area occurs in the same period due to resource constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['construction_year'].fillna(test_df['construction_year'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`construction_year` provides the year that it is constructed and it is a good source for feature engineering. The longer a water point is operational, the more likely it is for the water point to be non functional or needs repair. <br> Convert `construction_year` and `date_recorded` into the number of years the waterpoint has been in operation for, and drop both features after as the `operational years` is likely to be a more useful predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['date_recorded'] = pd.to_datetime(test_df['date_recorded'])\n",
    "test_df['operational_years'] = test_df.date_recorded.dt.year - test_df.construction_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in drop:\n",
    "    test_df.drop(i, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df).to_csv(\"clean.csv\", index=False)\n",
    "pd.DataFrame(test_df).to_csv(\"clean_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building (First Submission) - NN\n",
    "\n",
    "### Acknowledgements\n",
    "Changing normal datatypes to tensors: \n",
    "https://towardsdatascience.com/deep-learning-on-dataframes-with-pytorch-66b21be54ef6\n",
    "https://stackoverflow.com/questions/44617871/how-to-convert-a-list-of-strings-into-a-tensor-in-pytorch\n",
    "\n",
    "pytorch nn model\n",
    "https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "from numpy import vstack\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encode predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59400, 36)\n",
      "[0 2 1]\n"
     ]
    }
   ],
   "source": [
    "#SG encoder is declared so that it can be used to inverse transform the predicted result\n",
    "sg_encoder = LabelEncoder()\n",
    "df = pd.read_csv('clean.csv')\n",
    "\n",
    "# Label encode all predictors for the training data\n",
    "for col in df.columns:\n",
    "    if df.dtypes[col] == \"object\" and col != 'status_group':\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "    if col == 'status_group':\n",
    "        df['status_group'] = sg_encoder.fit_transform(df['status_group'])\n",
    "\n",
    "cols_at_end = ['status_group']\n",
    "df = df[[c for c in df if c not in cols_at_end] \n",
    "        + [c for c in cols_at_end if c in df]]\n",
    "\n",
    "#Store it into a temporary csv\n",
    "pd.DataFrame(df).to_csv(\"clean_nn1.csv\")\n",
    "print(df.shape)\n",
    "\n",
    "print(df.status_group.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>basin</th>\n",
       "      <th>region</th>\n",
       "      <th>...</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>operational_years</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1390.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>37399</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>374.652174</td>\n",
       "      <td>4</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>37195</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>686.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>14572</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>100.454545</td>\n",
       "      <td>4</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>37285</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>1392.735151</td>\n",
       "      <td>4</td>\n",
       "      <td>1057.545585</td>\n",
       "      <td>4</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>35529</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.185314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59395</th>\n",
       "      <td>60739</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1210.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>37.169807</td>\n",
       "      <td>-3.253847</td>\n",
       "      <td>513</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59396</th>\n",
       "      <td>27263</td>\n",
       "      <td>4700.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>35.249991</td>\n",
       "      <td>-9.070629</td>\n",
       "      <td>24074</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59397</th>\n",
       "      <td>37057</td>\n",
       "      <td>1392.735151</td>\n",
       "      <td>4</td>\n",
       "      <td>1057.545585</td>\n",
       "      <td>4</td>\n",
       "      <td>34.017087</td>\n",
       "      <td>-8.750434</td>\n",
       "      <td>27926</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14.185314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59398</th>\n",
       "      <td>31282</td>\n",
       "      <td>1392.735151</td>\n",
       "      <td>4</td>\n",
       "      <td>1057.545585</td>\n",
       "      <td>4</td>\n",
       "      <td>35.861315</td>\n",
       "      <td>-6.378573</td>\n",
       "      <td>29693</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14.185314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59399</th>\n",
       "      <td>26348</td>\n",
       "      <td>410.592885</td>\n",
       "      <td>0</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>38.104048</td>\n",
       "      <td>-6.747464</td>\n",
       "      <td>18700</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59400 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id   amount_tsh  funder   gps_height  installer  longitude  \\\n",
       "0      69572  6000.000000       4  1390.000000          4  34.938093   \n",
       "1       8776   374.652174       4  1399.000000          4  34.698766   \n",
       "2      34310    25.000000       4   686.000000          4  37.460664   \n",
       "3      67743   100.454545       4   263.000000          4  38.486161   \n",
       "4      19728  1392.735151       4  1057.545585          4  31.130847   \n",
       "...      ...          ...     ...          ...        ...        ...   \n",
       "59395  60739    10.000000       4  1210.000000          4  37.169807   \n",
       "59396  27263  4700.000000       4  1212.000000          4  35.249991   \n",
       "59397  37057  1392.735151       4  1057.545585          4  34.017087   \n",
       "59398  31282  1392.735151       4  1057.545585          4  35.861315   \n",
       "59399  26348   410.592885       0   191.000000          4  38.104048   \n",
       "\n",
       "        latitude  wpt_name  basin  region  ...  quality_group  quantity  \\\n",
       "0      -9.856322     37399      1       3  ...              2         1   \n",
       "1      -2.147466     37195      4       9  ...              2         2   \n",
       "2      -3.821329     14572      5       8  ...              2         1   \n",
       "3     -11.155298     37285      7      12  ...              2         0   \n",
       "4      -1.825359     35529      4       4  ...              2         3   \n",
       "...          ...       ...    ...     ...  ...            ...       ...   \n",
       "59395  -3.253847       513      5       6  ...              2         1   \n",
       "59396  -9.070629     24074      6       3  ...              2         1   \n",
       "59397  -8.750434     27926      6      10  ...              1         1   \n",
       "59398  -6.378573     29693      6       2  ...              2         2   \n",
       "59399  -6.747464     18700      8      11  ...              4         1   \n",
       "\n",
       "       quantity_group  source  source_type  source_class  waterpoint_type  \\\n",
       "0                   1       8            6             0                1   \n",
       "1                   2       5            3             1                1   \n",
       "2                   1       0            1             1                2   \n",
       "3                   0       3            0             0                2   \n",
       "4                   3       5            3             1                1   \n",
       "...               ...     ...          ...           ...              ...   \n",
       "59395               1       8            6             0                1   \n",
       "59396               1       6            4             1                1   \n",
       "59397               1       3            0             0                4   \n",
       "59398               2       7            5             0                4   \n",
       "59399               1       7            5             0                4   \n",
       "\n",
       "       waterpoint_type_group  operational_years  status_group  \n",
       "0                          1          12.000000             0  \n",
       "1                          1           3.000000             0  \n",
       "2                          1           4.000000             0  \n",
       "3                          1          27.000000             2  \n",
       "4                          1          14.185314             0  \n",
       "...                      ...                ...           ...  \n",
       "59395                      1          14.000000             0  \n",
       "59396                      1          15.000000             0  \n",
       "59397                      3          14.185314             0  \n",
       "59398                      3          14.185314             0  \n",
       "59399                      3           9.000000             0  \n",
       "\n",
       "[59400 rows x 36 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14850, 35)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('clean_test.csv')\n",
    "\n",
    "# Label encode all predictors\n",
    "for col in df.columns:\n",
    "    if df.dtypes[col] == \"object\" and col != 'status_group':\n",
    "        df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "#Store it into a temporary csv\n",
    "print(df.shape)\n",
    "pd.DataFrame(df).to_csv(\"clean_test_nn1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        # load the csv file as a dataframe\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        #Drop the unused columns. Unnamed: 0 is generated after saving the dataset.\n",
    "        df = df.drop('Unnamed: 0', axis=1)\n",
    "        df = df.drop('id', axis=1)\n",
    "        \n",
    "        #Assign x to all input values\n",
    "        self.X = df.values[:, :-1]\n",
    "        \n",
    "        #Assign y to all target values\n",
    "        self.y = df.values[:, -1]\n",
    "        \n",
    "        # ensure input data is floats\n",
    "        self.X = self.X.astype('float32')        \n",
    " \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    " \n",
    "    # get indexes for train and test rows\n",
    "    def get_splits(self, n_test=0.33):\n",
    "        # determine sizes\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        # calculate the split\n",
    "        return random_split(self, [train_size, test_size])\n",
    " \n",
    "# model definition\n",
    "class MLP(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        #Determine the input and output of each layer. Could also be passed as params for optimization\n",
    "        layers = [300,200,100]\n",
    "        total_layers = []\n",
    "        input_size = n_inputs\n",
    "        \n",
    "        for i in layers:\n",
    "            total_layers.append(nn.Linear(input_size, i))\n",
    "            total_layers.append(nn.ReLU(inplace=True))\n",
    "            total_layers.append(nn.BatchNorm1d(i))\n",
    "            total_layers.append(nn.Dropout(0.2))\n",
    "            input_size = i\n",
    "        \n",
    "        total_layers.append(nn.Linear(layers[-1], 3))\n",
    "\n",
    "        self.layers = nn.Sequential(*total_layers)\n",
    "\n",
    "\n",
    " \n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        X = self.layers(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVTestDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(self, path):\n",
    "        # load the csv file as a dataframe\n",
    "        df = read_csv(path)\n",
    "\n",
    "        # Drop unused columns\n",
    "        df = df.drop('id', axis=1)\n",
    "        df = df.drop('Unnamed: 0', axis=1)\n",
    "        if 'Unnamed: 0.1' in df.columns:\n",
    "            df = df.drop('Unnamed: 0.1', axis=1)\n",
    "        print('CSVTestDataset =', df.shape)\n",
    "        print(df.columns)\n",
    "        \n",
    "        #Assign x all input values\n",
    "        self.X = df.values[:, :]\n",
    "        # ensure input data is floats\n",
    "        self.X = self.X.astype('float32')\n",
    " \n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx]]\n",
    " \n",
    "    # returns all inputs from test dataset\n",
    "    def get_test(self):\n",
    "        return self.X;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   prepare the dataset\n",
    "def prepare_data(path):\n",
    "    # load the dataset\n",
    "    dataset = CSVDataset(path)\n",
    "    # calculate split\n",
    "    train, test = dataset.get_splits()\n",
    "    # prepare data loaders\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    return train_dl, test_dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'clean_nn1.csv'\n",
    "train_dl, test_dl = prepare_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper train/fit function\n",
    "\n",
    "def train(model, parameterization, train_dl):\n",
    "    \n",
    "    #Gradient descent optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=parameterization[\"lr\"], momentum=parameterization[\"momentum\"])\n",
    "    \n",
    "    #Use cross entropy loss function\n",
    "    criterion = CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, targets) in enumerate(train_dl, 0):\n",
    "\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # compute the model output\n",
    "            yhat = model(inputs)\n",
    "            \n",
    "            # calculate loss\n",
    "            loss = criterion(yhat, targets.long())\n",
    "\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            \n",
    "            # update model weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "        \n",
    "    return model\n",
    "\n",
    "            \n",
    "## helper function to evaluate the accuracy for the tested model\n",
    "def evaluate(model, test_dl):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        yhat = model(inputs)\n",
    "        _, predicted = torch.max(yhat, axis=1)\n",
    "\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "\n",
    "        # round to class values\n",
    "        yhat = yhat.round()\n",
    "\n",
    "        # store predictions\n",
    "        predictions.append(yhat)\n",
    "        \n",
    "        # transform 1d data and store eg. [0,1,2] => [[1,0,0] [0,1,0] [0,0,1]]\n",
    "        actual = actual.astype(int)\n",
    "        act = np.zeros((actual.size, actual.max()+1))\n",
    "        act[np.arange(actual.size),actual] = 1\n",
    "        actuals.append(act)\n",
    "\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "\n",
    "    # transform result to a numpy array of results eg. [0,1,2]\n",
    "    actuals = np.argmax(actuals, axis=1)\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Determine accuracy\n",
    "    acc = np.sum(predictions == actuals) / actuals.shape[0]\n",
    "    print('Accuracy of model:' , np.sum(predictions == actuals)/ actuals.shape[0])\n",
    "\n",
    "    return acc\n",
    "\n",
    "# make a class prediction for one row of data\n",
    "def _predict(data, model):\n",
    "    predictions = list()\n",
    "    for i, inputs in enumerate(data):\n",
    "        yhat = model(inputs)\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        predictions.append(yhat)\n",
    "\n",
    "    # Get prediction numpy arr with 3 columns\n",
    "    prediction_list = vstack(predictions)\n",
    "    \n",
    "    # Get prediction results eg [0,1,2]\n",
    "    results = np.argmax(prediction_list, axis=1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001E9124A2F20>\n",
      "Accuracy of model: 0.5411182532394654\n"
     ]
    }
   ],
   "source": [
    "# The code below is to test if my model is working properly.\n",
    "model = MLP(34)\n",
    "print(model.parameters())\n",
    "# Small step size for sgd\n",
    "trained_model = train(model, {\"lr\": 1e-6, \"momentum\": 0.5}, train_dl)\n",
    "acc = evaluate(trained_model,test_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVTestDataset = (14850, 34)\n",
      "Index(['amount_tsh', 'funder', 'gps_height', 'installer', 'longitude',\n",
      "       'latitude', 'wpt_name', 'basin', 'region', 'district_code', 'lga',\n",
      "       'ward', 'population', 'public_meeting', 'recorded_by',\n",
      "       'scheme_management', 'permit', 'extraction_type',\n",
      "       'extraction_type_group', 'extraction_type_class', 'management',\n",
      "       'management_group', 'payment', 'payment_type', 'water_quality',\n",
      "       'quality_group', 'quantity', 'quantity_group', 'source', 'source_type',\n",
      "       'source_class', 'waterpoint_type', 'waterpoint_type_group',\n",
      "       'operational_years'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get test dataset from the csv file.\n",
    "test_dataset = CSVTestDataset('clean_test_nn1.csv')\n",
    "\n",
    "# Get self.x of CSVTestDataset\n",
    "test_df = test_dataset.get_test()\n",
    "\n",
    "# Pass test_df into dataloader\n",
    "test_df = DataLoader(test_df, batch_size=10, shuffle=False)\n",
    "\n",
    "# Predict results\n",
    "test_results = _predict(test_df, trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "['functional' 'functional' 'functional' ... 'functional' 'functional'\n",
      " 'functional']\n"
     ]
    }
   ],
   "source": [
    "#Check data prediction\n",
    "print(test_results)\n",
    "np.unique(test_results)\n",
    "results_numpy = sg_encoder.inverse_transform(test_results)\n",
    "print(results_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataframe\n",
    "test_data = pd.read_csv('clean_test_nn1.csv')\n",
    "\n",
    "# Create dataframe with predictions and id\n",
    "submission_df = pd.DataFrame(results_numpy, columns=['status_group'])\n",
    "submission_df['id'] = test_data.id\n",
    "submission_df = submission_df[['id','status_group']]\n",
    "\n",
    "# Create new csv\n",
    "pd.DataFrame(submission_df).to_csv(\"nnmodel_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
